{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Evaluations\n",
    "\n",
    "We construct an end-to-end RAG pipeline: \n",
    "* Parse unstructured data from PDFs leveraging the raw-text extraction approach\n",
    "* Employ OpenAI’s text-embedding-3-large model to index and retrieve relevant data chunks. \n",
    "* In the generation phase, we incorporate the Chain-of-Thought approach to handle arithmetic-intensive tasks.\n",
    "\n",
    " Based on this end-to-end pipeline, we evaluate 8 LLMs spanning various model sizes and architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the project root directory\n",
    "root_dir = Path(os.path.abspath(\"\")).resolve().parents[1]\n",
    "sys.path.append(str(root_dir))\n",
    "# Change the working directory to the project root\n",
    "os.chdir(root_dir)\n",
    "\n",
    "res_dir = f\"experiment/e2e/res/\"\n",
    "if not os.path.exists(res_dir):\n",
    "    os.makedirs(res_dir)\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our paper, we use the powerful `text-embedding-3-large-model` model with AzureOpenAI-API . But you need to set up with your own api-key, endpoint and deploy-model in the config_file [uda/utils/access_config.py](../../uda/utils/access_config.py). \n",
    "\n",
    "If you want to use the API from **other alternative platforms** please change the codes in [uda/utils/retrieve.py (line-80)](../../uda/utils/retrieve.py#L81). \n",
    "\n",
    "For convenient demonstration, we choose the `colbert` retriever here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental Configurations\n",
    "\n",
    "# Available retrieval model_name: \"bm25\", \"all-MiniLM-L6-v2\", \"all-mpnet-base-v2\", \"openai\", \"colbert\"\n",
    "# We choose bm25 for convenience\n",
    "RT_MODEL = \"colbert\" \n",
    "\n",
    "DATASET_NAME_LIST = [\"fin\", \"feta\", \"tat\",\"paper_text\", \"nq\", \"paper_tab\"]\n",
    "LOCAL_LLM_DICT = {\n",
    "    \"meno-tiny\": \"bond005/meno-tiny-0.1\",\n",
    "    \"qwen2.5-1.5B\": \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    \"qwen2.5-3B\": \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "    \"falcon-e-3B\": \"tiiuae/Falcon-E-3B-Instruct\"\n",
    "}\n",
    "LLM_LIST = [\"meno-tiny\", \"qwen2.5-1.5B\", \"qwen2.5-3B\", \"falcon-e-3B\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our implementation, the **AzureOpenAI-API** serves as the interface for accessing GPT models. Users should set up the gpt-service with their own api-key and endpoint in the config_file [uda/utils/access_config.py](../../uda/utils/access_config.py). These configurations will be used in the `call_gpt()` function in the following codes.\n",
    "\n",
    "\n",
    "If you want to use **other alternative platforms**, the `call_gpt()` can be replaced by the corresponding model-calling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Start fin on meno-tiny ===\n",
      "2025-07-29 14:43:09 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:43:10,143 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:43:13 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:43:15] #> Note: Output directory .ragatouille/colbert/indexes/fin_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 14:43:15] #> Will delete 10 files already at .ragatouille/colbert/indexes/fin_vector_db in 20 seconds...\n",
      "[Jul 29, 14:43:38] [0] \t\t #> Encoding 50 passages..\n",
      "[Jul 29, 14:43:38] [0] \t\t avg_doclen_est = 3.819999933242798 \t len(local_sample) = 50\n",
      "[Jul 29, 14:43:38] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/fin_vector_db/plan.json ..\n",
      "Warning: number of training points (182) is less than the minimum recommended (1280)\n",
      "used 4 iterations (0.0398s) to cluster 182 items into 128 clusters\n",
      "[Jul 29, 14:43:39] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Jul 29, 14:43:39] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.016, 0.013, 0.02, 0.007, 0.025, 0.009, 0.018, 0.011, 0.03, 0.019, 0.01, 0.014, 0.013, 0.014, 0.016, 0.013, 0.014, 0.013, 0.028, 0.026, 0.018, 0.03, 0.018, 0.018, 0.014, 0.031, 0.012, 0.005, 0.014, 0.019, 0.024, 0.02, 0.011, 0.012, 0.014, 0.025, 0.013, 0.017, 0.012, 0.022, 0.008, 0.018, 0.02, 0.03, 0.017, 0.022, 0.019, 0.013, 0.022, 0.027, 0.025, 0.019, 0.013, 0.007, 0.014, 0.019, 0.017, 0.024, 0.022, 0.026, 0.012, 0.01, 0.014, 0.029, 0.014, 0.018, 0.018, 0.017, 0.009, 0.013, 0.025, 0.011, 0.014, 0.018, 0.022, 0.033, 0.033, 0.015, 0.026, 0.03, 0.027, 0.019, 0.005, 0.019, 0.023, 0.023, 0.008, 0.012, 0.013, 0.02, 0.018, 0.022, 0.019, 0.021, 0.019, 0.01, 0.017, 0.018, 0.021, 0.023, 0.016, 0.021, 0.016, 0.016, 0.008, 0.019, 0.026, 0.028, 0.023, 0.012, 0.012, 0.008, 0.018, 0.024, 0.006, 0.019, 0.021, 0.017, 0.019, 0.009, 0.008, 0.019, 0.014, 0.018, 0.019, 0.016, 0.029, 0.024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:43:39] [0] \t\t #> Encoding 50 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 36.64it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1745.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:43:39] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:43:39] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:43:39] len(emb2pid) = 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 120645.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:43:39] #> Saved optimized IVF to .ragatouille/colbert/indexes/fin_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:43:45] #> Loading codec...\n",
      "[Jul 29, 14:43:45] #> Loading IVF...\n",
      "[Jul 29, 14:43:45] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4279.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:43:45] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1093.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what percentage of total long-term assets under supervision are comprised of fixed income in 2015?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  7017,  1997,  2561,  2146,  1011,  2744,  7045,\n",
      "         2104, 10429,  2024, 11539,  1997,  4964,  3318,  1999,  2325,  1029,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:43:45 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'what percentage of total long-term assets under supervision are comprised of fixed income in 2015?', 'response': '10.00%', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_79.pdf-3', 'answers': {'str_answer': '57%', 'exe_answer': 0.57484}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:43:51] #> Loading codec...\n",
      "[Jul 29, 14:43:51] #> Loading IVF...\n",
      "[Jul 29, 14:43:51] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5562.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:43:51] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1416.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what percentage of total long-term assets under supervision are comprised of fixed income in 2016?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  7017,  1997,  2561,  2146,  1011,  2744,  7045,\n",
      "         2104, 10429,  2024, 11539,  1997,  4964,  3318,  1999,  2355,  1029,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:43:51 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'what percentage of total long-term assets under supervision are comprised of fixed income in 2016?', 'response': '100.00%', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_79.pdf-1', 'answers': {'str_answer': '59%', 'exe_answer': 0.588}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:43:57] #> Loading codec...\n",
      "[Jul 29, 14:43:57] #> Loading IVF...\n",
      "[Jul 29, 14:43:57] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6636.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:43:57] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1611.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what percentage of total loans receivable gross in 2016 were loans backed by commercial real estate?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  7017,  1997,  2561, 10940, 28667,  7416, 12423,\n",
      "         7977,  1999,  2355,  2020, 10940,  6153,  2011,  3293,  2613,  3776,\n",
      "         1029,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:43:57 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'what percentage of total loans receivable gross in 2016 were loans backed by commercial real estate?', 'response': '14.3%', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_161.pdf-1', 'answers': {'str_answer': '9%', 'exe_answer': 0.09488}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:44:03] #> Loading codec...\n",
      "[Jul 29, 14:44:03] #> Loading IVF...\n",
      "[Jul 29, 14:44:03] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5833.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:44:03] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1586.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what percentage of future minimum rental payments are due in 2018?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  7017,  1997,  2925,  6263, 12635, 10504,  2024,\n",
      "         2349,  1999,  2760,  1029,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:44:03 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'what percentage of future minimum rental payments are due in 2018?', 'response': '100.0%', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_183.pdf-3', 'answers': {'str_answer': '15%', 'exe_answer': 0.14529}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:44:09] #> Loading codec...\n",
      "[Jul 29, 14:44:09] #> Loading IVF...\n",
      "[Jul 29, 14:44:09] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6288.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:44:09] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1628.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: in millions , for 2016 , 2015 , and 2014 what was the total amount of common share repurchases?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1999,  8817,  1010,  2005,  2355,  1010,  2325,  1010,\n",
      "         1998,  2297,  2054,  2001,  1996,  2561,  3815,  1997,  2691,  3745,\n",
      "        16360,  3126, 26300,  2015,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:44:09 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'in millions , for 2016 , 2015 , and 2014 what was the total amount of common share repurchases?', 'response': '1.25', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_186.pdf-2', 'answers': {'str_answer': '90.1', 'exe_answer': 90.5}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:44:14] #> Loading codec...\n",
      "[Jul 29, 14:44:14] #> Loading IVF...\n",
      "[Jul 29, 14:44:14] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6647.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:44:14] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1588.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: of the total aus net inflows/ ( outflows ) for 2014 were fixed income asset inflows in connection with our acquisition of deutsche asset & wealth management 2019s stable value business greater than the liquidity products inflows in connection with our acquisition of rbs asset management 2019s money market funds?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([67]), tensor([  101,     1,  1997,  1996,  2561, 17151,  5658,  1999, 12314,  2015,\n",
      "         1013,  1006,  2041, 12314,  2015,  1007,  2005,  2297,  2020,  4964,\n",
      "         3318, 11412,  1999, 12314,  2015,  1999,  4434,  2007,  2256,  7654,\n",
      "         1997, 11605, 11412,  1004,  7177,  2968, 10476,  2015,  6540,  3643,\n",
      "         2449,  3618,  2084,  1996,  6381,  3012,  3688,  1999, 12314,  2015,\n",
      "         1999,  4434,  2007,  2256,  7654,  1997, 21144,  2015, 11412,  2968,\n",
      "        10476,  2015,  2769,  3006,  5029,  1029,   102], device='cuda:0')\n",
      "#> Output Mask: torch.Size([67]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       device='cuda:0')\n",
      "\n",
      "2025-07-29 14:44:14 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'of the total aus net inflows/ ( outflows ) for 2014 were fixed income asset inflows in connection with our acquisition of deutsche asset & wealth management 2019s stable value business greater than the liquidity products inflows in connection with our acquisition of rbs asset management 2019s money market funds?', 'response': '100.00%', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_79.pdf-4', 'answers': {'str_answer': 'yes', 'exe_answer': 'yes'}}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:44:17] #> Note: Output directory .ragatouille/colbert/indexes/fin_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 14:44:17] #> Will delete 10 files already at .ragatouille/colbert/indexes/fin_vector_db in 20 seconds...\n",
      "[Jul 29, 14:44:40] [0] \t\t #> Encoding 52 passages..\n",
      "[Jul 29, 14:44:40] [0] \t\t avg_doclen_est = 3.826923131942749 \t len(local_sample) = 52\n",
      "[Jul 29, 14:44:40] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/fin_vector_db/plan.json ..\n",
      "Warning: number of training points (190) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.001s) to cluster 190 items into 128 clusters\n",
      "[0.022, 0.027, 0.017, 0.018, 0.025, 0.029, 0.018, 0.023, 0.018, 0.016, 0.018, 0.026, 0.022, 0.016, 0.026, 0.03, 0.018, 0.02, 0.022, 0.032, 0.047, 0.017, 0.009, 0.03, 0.019, 0.025, 0.025, 0.027, 0.016, 0.017, 0.019, 0.033, 0.024, 0.012, 0.021, 0.034, 0.022, 0.023, 0.016, 0.019, 0.022, 0.022, 0.022, 0.015, 0.04, 0.029, 0.018, 0.034, 0.01, 0.019, 0.022, 0.032, 0.015, 0.036, 0.014, 0.034, 0.02, 0.015, 0.03, 0.028, 0.017, 0.017, 0.03, 0.034, 0.012, 0.026, 0.013, 0.02, 0.016, 0.019, 0.019, 0.02, 0.017, 0.015, 0.014, 0.025, 0.029, 0.025, 0.027, 0.028, 0.047, 0.021, 0.019, 0.027, 0.028, 0.016, 0.026, 0.028, 0.018, 0.013, 0.017, 0.025, 0.03, 0.021, 0.035, 0.038, 0.051, 0.023, 0.018, 0.028, 0.024, 0.026, 0.011, 0.028, 0.03, 0.015, 0.023, 0.02, 0.024, 0.024, 0.022, 0.019, 0.037, 0.023, 0.012, 0.033, 0.023, 0.019, 0.02, 0.015, 0.025, 0.027, 0.03, 0.027, 0.027, 0.033, 0.038, 0.033]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:44:40] [0] \t\t #> Encoding 52 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 80.07it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2768.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:44:40] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:44:40] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:44:40] len(emb2pid) = 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 166833.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:44:40] #> Saved optimized IVF to .ragatouille/colbert/indexes/fin_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:44:46] #> Loading codec...\n",
      "[Jul 29, 14:44:46] #> Loading IVF...\n",
      "[Jul 29, 14:44:46] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6043.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:44:46] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1728.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what was the percentage change in the 5 year annual performance of the peer group stock from 2010 to 2011, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 1996, 7017, 2689, 1999, 1996, 1019, 2095, 3296,\n",
      "        2836, 1997, 1996, 8152, 2177, 4518, 2013, 2230, 2000, 2249,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:44:46 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'what was the percentage change in the 5 year annual performance of the peer group stock from 2010 to 2011', 'response': '-0.04%', 'doc': 'JKHY_2015', 'q_uid': 'JKHY/2015/page_20.pdf-2', 'answers': {'str_answer': '8.3%', 'exe_answer': 0.08276}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:44:52] #> Loading codec...\n",
      "[Jul 29, 14:44:52] #> Loading IVF...\n",
      "[Jul 29, 14:44:52] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6864.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:44:52] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1838.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: in 2010 , what was the cumulative total return of the s&p 500?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1999,  2230,  1010,  2054,  2001,  1996, 23260,  2561,\n",
      "         2709,  1997,  1996,  1055,  1004,  1052,  3156,  1029,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:44:52 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'in 2010 , what was the cumulative total return of the s&p 500?', 'response': '-0.04', 'doc': 'JKHY_2015', 'q_uid': 'JKHY/2015/page_20.pdf-3', 'answers': {'str_answer': '30.69', 'exe_answer': 30.69}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:44:58] #> Loading codec...\n",
      "[Jul 29, 14:44:58] #> Loading IVF...\n",
      "[Jul 29, 14:44:58] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5059.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:44:58] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1825.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: for the 2010 , what was the cumulative total return on jkhy?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2005,  1996,  2230,  1010,  2054,  2001,  1996, 23260,\n",
      "         2561,  2709,  2006,  1046, 10023,  2100,  1029,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:44:58 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'for the 2010 , what was the cumulative total return on jkhy?', 'response': '-0.04', 'doc': 'JKHY_2015', 'q_uid': 'JKHY/2015/page_20.pdf-1', 'answers': {'str_answer': '27.44', 'exe_answer': 27.44}}\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ABC_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DG_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/JPM_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/IP_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/GRMN_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/IP_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/EMN_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/PNC_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ZBH_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RL_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/APTV_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ORLY_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MMM_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SLG_2012.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MSI_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MAR_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MRO_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RL_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/JKHY_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HUM_2014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DVN_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SNPS_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MRO_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AAPL_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/C_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/V_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AAPL_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ORLY_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/EL_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RE_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ORLY_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HIG_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DRE_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AMAT_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HOLX_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DISH_2014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SLG_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SLG_2002.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/VNO_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/IP_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DISCA_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AOS_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/FRT_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ILMN_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MSI_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/STZ_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/VRTX_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AWK_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/LMT_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ETFC_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/UPS_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ORLY_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HUM_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/IPG_2003.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ETFC_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/CCI_2004.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/EMN_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MRO_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AES_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DRE_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ADI_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MA_2018.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RSG_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/UNP_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/JPM_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ADI_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/NCLH_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/KMI_2014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/BDX_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SLB_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AES_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/UPS_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/PNC_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AAPL_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/GPN_2014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DG_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/PKG_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/BKNG_2018.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HII_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/FRT_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HII_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/VLO_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RE_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RCL_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ABMD_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MMM_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/BLL_2012.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/JPM_2018.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AAPL_2004.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/BDX_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MSI_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SPGI_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AON_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/GRMN_2004.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/CDW_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/EMN_2018.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DG_2005.pdf\n",
      "=== Start fin on qwen2.5-1.5B ===\n",
      "2025-07-29 14:44:58 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:44:59,226 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:45:00 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:45:02] #> Note: Output directory .ragatouille/colbert/indexes/fin_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 14:45:02] #> Will delete 10 files already at .ragatouille/colbert/indexes/fin_vector_db in 20 seconds...\n",
      "[Jul 29, 14:45:25] [0] \t\t #> Encoding 50 passages..\n",
      "[Jul 29, 14:45:25] [0] \t\t avg_doclen_est = 3.819999933242798 \t len(local_sample) = 50\n",
      "[Jul 29, 14:45:25] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/fin_vector_db/plan.json ..\n",
      "Warning: number of training points (182) is less than the minimum recommended (1280)\n",
      "used 4 iterations (0.0009s) to cluster 182 items into 128 clusters\n",
      "[0.016, 0.013, 0.02, 0.007, 0.025, 0.009, 0.018, 0.011, 0.03, 0.019, 0.01, 0.014, 0.013, 0.014, 0.016, 0.013, 0.014, 0.013, 0.028, 0.026, 0.018, 0.03, 0.018, 0.018, 0.014, 0.031, 0.012, 0.005, 0.014, 0.019, 0.024, 0.02, 0.011, 0.012, 0.014, 0.025, 0.013, 0.017, 0.012, 0.022, 0.008, 0.018, 0.02, 0.03, 0.017, 0.022, 0.019, 0.013, 0.022, 0.027, 0.025, 0.019, 0.013, 0.007, 0.014, 0.019, 0.017, 0.024, 0.022, 0.026, 0.012, 0.01, 0.014, 0.029, 0.014, 0.018, 0.018, 0.017, 0.009, 0.013, 0.025, 0.011, 0.014, 0.018, 0.022, 0.033, 0.033, 0.015, 0.026, 0.03, 0.027, 0.019, 0.005, 0.019, 0.023, 0.023, 0.008, 0.012, 0.013, 0.02, 0.018, 0.022, 0.019, 0.021, 0.019, 0.01, 0.017, 0.018, 0.021, 0.023, 0.016, 0.021, 0.016, 0.016, 0.008, 0.019, 0.026, 0.028, 0.023, 0.012, 0.012, 0.008, 0.018, 0.024, 0.006, 0.019, 0.021, 0.017, 0.019, 0.009, 0.008, 0.019, 0.014, 0.018, 0.019, 0.016, 0.029, 0.024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:45:25] [0] \t\t #> Encoding 50 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 78.41it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2166.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:45:25] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:45:25] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:45:25] len(emb2pid) = 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 121739.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:45:25] #> Saved optimized IVF to .ragatouille/colbert/indexes/fin_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:45:31] #> Loading codec...\n",
      "[Jul 29, 14:45:31] #> Loading IVF...\n",
      "[Jul 29, 14:45:31] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6932.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:45:31] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1793.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what percentage of total long-term assets under supervision are comprised of fixed income in 2015?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  7017,  1997,  2561,  2146,  1011,  2744,  7045,\n",
      "         2104, 10429,  2024, 11539,  1997,  4964,  3318,  1999,  2325,  1029,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:45:31 CallLLM\n",
      "{'model': 'qwen2.5-1.5B', 'question': 'what percentage of total long-term assets under supervision are comprised of fixed income in 2015?', 'response': '34.7%', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_79.pdf-3', 'answers': {'str_answer': '57%', 'exe_answer': 0.57484}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:45:38] #> Loading codec...\n",
      "[Jul 29, 14:45:38] #> Loading IVF...\n",
      "[Jul 29, 14:45:38] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5152.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:45:38] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1209.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what percentage of total long-term assets under supervision are comprised of fixed income in 2016?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  7017,  1997,  2561,  2146,  1011,  2744,  7045,\n",
      "         2104, 10429,  2024, 11539,  1997,  4964,  3318,  1999,  2355,  1029,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:45:38 CallLLM\n",
      "{'model': 'qwen2.5-1.5B', 'question': 'what percentage of total long-term assets under supervision are comprised of fixed income in 2016?', 'response': '34%', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_79.pdf-1', 'answers': {'str_answer': '59%', 'exe_answer': 0.588}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:45:44] #> Loading codec...\n",
      "[Jul 29, 14:45:44] #> Loading IVF...\n",
      "[Jul 29, 14:45:44] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6533.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:45:44] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1893.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what percentage of total loans receivable gross in 2016 were loans backed by commercial real estate?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  7017,  1997,  2561, 10940, 28667,  7416, 12423,\n",
      "         7977,  1999,  2355,  2020, 10940,  6153,  2011,  3293,  2613,  3776,\n",
      "         1029,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:45:44 CallLLM\n",
      "{'model': 'qwen2.5-1.5B', 'question': 'what percentage of total loans receivable gross in 2016 were loans backed by commercial real estate?', 'response': '34%', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_161.pdf-1', 'answers': {'str_answer': '9%', 'exe_answer': 0.09488}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:45:49] #> Loading codec...\n",
      "[Jul 29, 14:45:49] #> Loading IVF...\n",
      "[Jul 29, 14:45:49] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6335.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:45:49] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1808.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what percentage of future minimum rental payments are due in 2018?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  7017,  1997,  2925,  6263, 12635, 10504,  2024,\n",
      "         2349,  1999,  2760,  1029,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:45:49 CallLLM\n",
      "{'model': 'qwen2.5-1.5B', 'question': 'what percentage of future minimum rental payments are due in 2018?', 'response': '33%', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_183.pdf-3', 'answers': {'str_answer': '15%', 'exe_answer': 0.14529}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:45:55] #> Loading codec...\n",
      "[Jul 29, 14:45:55] #> Loading IVF...\n",
      "[Jul 29, 14:45:55] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5737.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:45:55] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1839.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: in millions , for 2016 , 2015 , and 2014 what was the total amount of common share repurchases?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1999,  8817,  1010,  2005,  2355,  1010,  2325,  1010,\n",
      "         1998,  2297,  2054,  2001,  1996,  2561,  3815,  1997,  2691,  3745,\n",
      "        16360,  3126, 26300,  2015,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:45:55 CallLLM\n",
      "{'model': 'qwen2.5-1.5B', 'question': 'in millions , for 2016 , 2015 , and 2014 what was the total amount of common share repurchases?', 'response': '3.79', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_186.pdf-2', 'answers': {'str_answer': '90.1', 'exe_answer': 90.5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:46:01] #> Loading codec...\n",
      "[Jul 29, 14:46:01] #> Loading IVF...\n",
      "[Jul 29, 14:46:01] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5440.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:46:01] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1847.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: of the total aus net inflows/ ( outflows ) for 2014 were fixed income asset inflows in connection with our acquisition of deutsche asset & wealth management 2019s stable value business greater than the liquidity products inflows in connection with our acquisition of rbs asset management 2019s money market funds?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([67]), tensor([  101,     1,  1997,  1996,  2561, 17151,  5658,  1999, 12314,  2015,\n",
      "         1013,  1006,  2041, 12314,  2015,  1007,  2005,  2297,  2020,  4964,\n",
      "         3318, 11412,  1999, 12314,  2015,  1999,  4434,  2007,  2256,  7654,\n",
      "         1997, 11605, 11412,  1004,  7177,  2968, 10476,  2015,  6540,  3643,\n",
      "         2449,  3618,  2084,  1996,  6381,  3012,  3688,  1999, 12314,  2015,\n",
      "         1999,  4434,  2007,  2256,  7654,  1997, 21144,  2015, 11412,  2968,\n",
      "        10476,  2015,  2769,  3006,  5029,  1029,   102], device='cuda:0')\n",
      "#> Output Mask: torch.Size([67]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       device='cuda:0')\n",
      "\n",
      "2025-07-29 14:46:01 CallLLM\n",
      "{'model': 'qwen2.5-1.5B', 'question': 'of the total aus net inflows/ ( outflows ) for 2014 were fixed income asset inflows in connection with our acquisition of deutsche asset & wealth management 2019s stable value business greater than the liquidity products inflows in connection with our acquisition of rbs asset management 2019s money market funds?', 'response': 'No', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_79.pdf-4', 'answers': {'str_answer': 'yes', 'exe_answer': 'yes'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:46:04] #> Note: Output directory .ragatouille/colbert/indexes/fin_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 14:46:04] #> Will delete 10 files already at .ragatouille/colbert/indexes/fin_vector_db in 20 seconds...\n",
      "[Jul 29, 14:46:27] [0] \t\t #> Encoding 52 passages..\n",
      "[Jul 29, 14:46:27] [0] \t\t avg_doclen_est = 3.826923131942749 \t len(local_sample) = 52\n",
      "[Jul 29, 14:46:27] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/fin_vector_db/plan.json ..\n",
      "Warning: number of training points (190) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.001s) to cluster 190 items into 128 clusters\n",
      "[0.022, 0.027, 0.017, 0.018, 0.025, 0.029, 0.018, 0.023, 0.018, 0.016, 0.018, 0.026, 0.022, 0.016, 0.026, 0.03, 0.018, 0.02, 0.022, 0.032, 0.047, 0.017, 0.009, 0.03, 0.019, 0.025, 0.025, 0.027, 0.016, 0.017, 0.019, 0.033, 0.024, 0.012, 0.021, 0.034, 0.022, 0.023, 0.016, 0.019, 0.022, 0.022, 0.022, 0.015, 0.04, 0.029, 0.018, 0.034, 0.01, 0.019, 0.022, 0.032, 0.015, 0.036, 0.014, 0.034, 0.02, 0.015, 0.03, 0.028, 0.017, 0.017, 0.03, 0.034, 0.012, 0.026, 0.013, 0.02, 0.016, 0.019, 0.019, 0.02, 0.017, 0.015, 0.014, 0.025, 0.029, 0.025, 0.027, 0.028, 0.047, 0.021, 0.019, 0.027, 0.028, 0.016, 0.026, 0.028, 0.018, 0.013, 0.017, 0.025, 0.03, 0.021, 0.035, 0.038, 0.051, 0.023, 0.018, 0.028, 0.024, 0.026, 0.011, 0.028, 0.03, 0.015, 0.023, 0.02, 0.024, 0.024, 0.022, 0.019, 0.037, 0.023, 0.012, 0.033, 0.023, 0.019, 0.02, 0.015, 0.025, 0.027, 0.03, 0.027, 0.027, 0.033, 0.038, 0.033]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:46:27] [0] \t\t #> Encoding 52 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 74.00it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2123.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:46:27] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:46:27] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:46:27] len(emb2pid) = 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 172239.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:46:27] #> Saved optimized IVF to .ragatouille/colbert/indexes/fin_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:46:32] #> Loading codec...\n",
      "[Jul 29, 14:46:32] #> Loading IVF...\n",
      "[Jul 29, 14:46:32] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6472.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:46:32] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1574.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what was the percentage change in the 5 year annual performance of the peer group stock from 2010 to 2011, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 1996, 7017, 2689, 1999, 1996, 1019, 2095, 3296,\n",
      "        2836, 1997, 1996, 8152, 2177, 4518, 2013, 2230, 2000, 2249,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:46:33 CallLLM\n",
      "{'model': 'qwen2.5-1.5B', 'question': 'what was the percentage change in the 5 year annual performance of the peer group stock from 2010 to 2011', 'response': '-3.4%', 'doc': 'JKHY_2015', 'q_uid': 'JKHY/2015/page_20.pdf-2', 'answers': {'str_answer': '8.3%', 'exe_answer': 0.08276}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:46:38] #> Loading codec...\n",
      "[Jul 29, 14:46:38] #> Loading IVF...\n",
      "[Jul 29, 14:46:38] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 9279.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:46:38] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1679.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: in 2010 , what was the cumulative total return of the s&p 500?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1999,  2230,  1010,  2054,  2001,  1996, 23260,  2561,\n",
      "         2709,  1997,  1996,  1055,  1004,  1052,  3156,  1029,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:46:38 CallLLM\n",
      "{'model': 'qwen2.5-1.5B', 'question': 'in 2010 , what was the cumulative total return of the s&p 500?', 'response': '-3.4%', 'doc': 'JKHY_2015', 'q_uid': 'JKHY/2015/page_20.pdf-3', 'answers': {'str_answer': '30.69', 'exe_answer': 30.69}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:46:44] #> Loading codec...\n",
      "[Jul 29, 14:46:44] #> Loading IVF...\n",
      "[Jul 29, 14:46:44] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6432.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:46:44] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1639.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: for the 2010 , what was the cumulative total return on jkhy?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2005,  1996,  2230,  1010,  2054,  2001,  1996, 23260,\n",
      "         2561,  2709,  2006,  1046, 10023,  2100,  1029,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:46:44 CallLLM\n",
      "{'model': 'qwen2.5-1.5B', 'question': 'for the 2010 , what was the cumulative total return on jkhy?', 'response': '-34.7%', 'doc': 'JKHY_2015', 'q_uid': 'JKHY/2015/page_20.pdf-1', 'answers': {'str_answer': '27.44', 'exe_answer': 27.44}}\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ABC_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DG_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/JPM_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/IP_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/GRMN_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/IP_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/EMN_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/PNC_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ZBH_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RL_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/APTV_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ORLY_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MMM_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SLG_2012.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MSI_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MAR_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MRO_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RL_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/JKHY_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HUM_2014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DVN_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SNPS_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MRO_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AAPL_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/C_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/V_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AAPL_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ORLY_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/EL_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RE_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ORLY_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HIG_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DRE_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AMAT_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HOLX_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DISH_2014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SLG_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SLG_2002.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/VNO_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/IP_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DISCA_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AOS_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/FRT_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ILMN_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MSI_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/STZ_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/VRTX_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AWK_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/LMT_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ETFC_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/UPS_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ORLY_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HUM_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/IPG_2003.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ETFC_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/CCI_2004.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/EMN_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MRO_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AES_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DRE_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ADI_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MA_2018.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RSG_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/UNP_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/JPM_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ADI_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/NCLH_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/KMI_2014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/BDX_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SLB_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AES_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/UPS_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/PNC_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AAPL_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/GPN_2014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DG_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/PKG_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/BKNG_2018.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HII_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/FRT_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HII_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/VLO_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RE_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RCL_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ABMD_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MMM_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/BLL_2012.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/JPM_2018.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AAPL_2004.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/BDX_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MSI_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SPGI_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AON_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/GRMN_2004.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/CDW_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/EMN_2018.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DG_2005.pdf\n",
      "=== Start fin on qwen2.5-3B ===\n",
      "2025-07-29 14:46:44 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [02:27<00:00, 73.76s/it]\n",
      "2025-07-29 14:49:12,403 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:07<00:00,  3.64s/it]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:49:25 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:49:27] #> Note: Output directory .ragatouille/colbert/indexes/fin_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 14:49:27] #> Will delete 10 files already at .ragatouille/colbert/indexes/fin_vector_db in 20 seconds...\n",
      "[Jul 29, 14:49:50] [0] \t\t #> Encoding 50 passages..\n",
      "[Jul 29, 14:49:50] [0] \t\t avg_doclen_est = 3.819999933242798 \t len(local_sample) = 50\n",
      "[Jul 29, 14:49:50] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/fin_vector_db/plan.json ..\n",
      "Warning: number of training points (182) is less than the minimum recommended (1280)\n",
      "used 4 iterations (0.0145s) to cluster 182 items into 128 clusters\n",
      "[0.016, 0.013, 0.02, 0.007, 0.025, 0.009, 0.018, 0.011, 0.03, 0.019, 0.01, 0.014, 0.013, 0.014, 0.016, 0.013, 0.014, 0.013, 0.028, 0.026, 0.018, 0.03, 0.018, 0.018, 0.014, 0.031, 0.012, 0.005, 0.014, 0.019, 0.024, 0.02, 0.011, 0.012, 0.014, 0.025, 0.013, 0.017, 0.012, 0.022, 0.008, 0.018, 0.02, 0.03, 0.017, 0.022, 0.019, 0.013, 0.022, 0.027, 0.025, 0.019, 0.013, 0.007, 0.014, 0.019, 0.017, 0.024, 0.022, 0.026, 0.012, 0.01, 0.014, 0.029, 0.014, 0.018, 0.018, 0.017, 0.009, 0.013, 0.025, 0.011, 0.014, 0.018, 0.022, 0.033, 0.033, 0.015, 0.026, 0.03, 0.027, 0.019, 0.005, 0.019, 0.023, 0.023, 0.008, 0.012, 0.013, 0.02, 0.018, 0.022, 0.019, 0.021, 0.019, 0.01, 0.017, 0.018, 0.021, 0.023, 0.016, 0.021, 0.016, 0.016, 0.008, 0.019, 0.026, 0.028, 0.023, 0.012, 0.012, 0.008, 0.018, 0.024, 0.006, 0.019, 0.021, 0.017, 0.019, 0.009, 0.008, 0.019, 0.014, 0.018, 0.019, 0.016, 0.029, 0.024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:49:51] [0] \t\t #> Encoding 50 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 57.25it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1570.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:49:51] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:49:51] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:49:51] len(emb2pid) = 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 120374.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:49:51] #> Saved optimized IVF to .ragatouille/colbert/indexes/fin_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:49:56] #> Loading codec...\n",
      "[Jul 29, 14:49:56] #> Loading IVF...\n",
      "[Jul 29, 14:49:56] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7269.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:49:56] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1699.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what percentage of total long-term assets under supervision are comprised of fixed income in 2015?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  7017,  1997,  2561,  2146,  1011,  2744,  7045,\n",
      "         2104, 10429,  2024, 11539,  1997,  4964,  3318,  1999,  2325,  1029,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:49:56 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'what percentage of total long-term assets under supervision are comprised of fixed income in 2015?', 'response': 'The provided text does not contain enough information to calculate the percentage of total long-term assets under supervision that are comprised of fixed income in 2015.\\n The answer is: Not Provided', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_79.pdf-3', 'answers': {'str_answer': '57%', 'exe_answer': 0.57484}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:50:03] #> Loading codec...\n",
      "[Jul 29, 14:50:03] #> Loading IVF...\n",
      "[Jul 29, 14:50:03] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5349.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:50:03] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1560.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what percentage of total long-term assets under supervision are comprised of fixed income in 2016?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  7017,  1997,  2561,  2146,  1011,  2744,  7045,\n",
      "         2104, 10429,  2024, 11539,  1997,  4964,  3318,  1999,  2355,  1029,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:50:03 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'what percentage of total long-term assets under supervision are comprised of fixed income in 2016?', 'response': 'The provided information does not contain enough data to calculate the percentage of total long-term assets under supervision that are comprised of fixed income in 2016.\\n The answer is: Not Provided', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_79.pdf-1', 'answers': {'str_answer': '59%', 'exe_answer': 0.588}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:50:10] #> Loading codec...\n",
      "[Jul 29, 14:50:10] #> Loading IVF...\n",
      "[Jul 29, 14:50:10] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6921.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:50:10] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1798.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what percentage of total loans receivable gross in 2016 were loans backed by commercial real estate?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  7017,  1997,  2561, 10940, 28667,  7416, 12423,\n",
      "         7977,  1999,  2355,  2020, 10940,  6153,  2011,  3293,  2613,  3776,\n",
      "         1029,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:50:10 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'what percentage of total loans receivable gross in 2016 were loans backed by commercial real estate?', 'response': 'The provided text does not contain enough information to calculate the requested percentage.\\n The answer is: Not enough information', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_161.pdf-1', 'answers': {'str_answer': '9%', 'exe_answer': 0.09488}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:50:18] #> Loading codec...\n",
      "[Jul 29, 14:50:18] #> Loading IVF...\n",
      "[Jul 29, 14:50:18] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5391.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:50:18] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1533.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what percentage of future minimum rental payments are due in 2018?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  7017,  1997,  2925,  6263, 12635, 10504,  2024,\n",
      "         2349,  1999,  2760,  1029,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:50:18 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'what percentage of future minimum rental payments are due in 2018?', 'response': 'No information provided for calculating the percentage of future minimum rental payments due in 2018.\\n The answer is: N/A', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_183.pdf-3', 'answers': {'str_answer': '15%', 'exe_answer': 0.14529}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:50:25] #> Loading codec...\n",
      "[Jul 29, 14:50:25] #> Loading IVF...\n",
      "[Jul 29, 14:50:25] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6241.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:50:25] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1126.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: in millions , for 2016 , 2015 , and 2014 what was the total amount of common share repurchases?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1999,  8817,  1010,  2005,  2355,  1010,  2325,  1010,\n",
      "         1998,  2297,  2054,  2001,  1996,  2561,  3815,  1997,  2691,  3745,\n",
      "        16360,  3126, 26300,  2015,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:50:25 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'in millions , for 2016 , 2015 , and 2014 what was the total amount of common share repurchases?', 'response': 'There is no information provided about common share repurchases for the years 2016, 2015, and 2014.\\n The answer is: 0', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_186.pdf-2', 'answers': {'str_answer': '90.1', 'exe_answer': 90.5}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:50:32] #> Loading codec...\n",
      "[Jul 29, 14:50:32] #> Loading IVF...\n",
      "[Jul 29, 14:50:32] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6150.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:50:32] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1836.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: of the total aus net inflows/ ( outflows ) for 2014 were fixed income asset inflows in connection with our acquisition of deutsche asset & wealth management 2019s stable value business greater than the liquidity products inflows in connection with our acquisition of rbs asset management 2019s money market funds?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([67]), tensor([  101,     1,  1997,  1996,  2561, 17151,  5658,  1999, 12314,  2015,\n",
      "         1013,  1006,  2041, 12314,  2015,  1007,  2005,  2297,  2020,  4964,\n",
      "         3318, 11412,  1999, 12314,  2015,  1999,  4434,  2007,  2256,  7654,\n",
      "         1997, 11605, 11412,  1004,  7177,  2968, 10476,  2015,  6540,  3643,\n",
      "         2449,  3618,  2084,  1996,  6381,  3012,  3688,  1999, 12314,  2015,\n",
      "         1999,  4434,  2007,  2256,  7654,  1997, 21144,  2015, 11412,  2968,\n",
      "        10476,  2015,  2769,  3006,  5029,  1029,   102], device='cuda:0')\n",
      "#> Output Mask: torch.Size([67]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       device='cuda:0')\n",
      "\n",
      "2025-07-29 14:50:32 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'of the total aus net inflows/ ( outflows ) for 2014 were fixed income asset inflows in connection with our acquisition of deutsche asset & wealth management 2019s stable value business greater than the liquidity products inflows in connection with our acquisition of rbs asset management 2019s money market funds?', 'response': 'The provided text does not contain enough information to answer the question about which inflow was greater between fixed income assets and liquidity products. There is no data on specific inflows or their values.\\n The answer is: Not Provided', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_79.pdf-4', 'answers': {'str_answer': 'yes', 'exe_answer': 'yes'}}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:50:35] #> Note: Output directory .ragatouille/colbert/indexes/fin_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 14:50:35] #> Will delete 10 files already at .ragatouille/colbert/indexes/fin_vector_db in 20 seconds...\n",
      "[Jul 29, 14:50:58] [0] \t\t #> Encoding 52 passages..\n",
      "[Jul 29, 14:50:58] [0] \t\t avg_doclen_est = 3.826923131942749 \t len(local_sample) = 52\n",
      "[Jul 29, 14:50:58] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/fin_vector_db/plan.json ..\n",
      "Warning: number of training points (190) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0009s) to cluster 190 items into 128 clusters\n",
      "[0.022, 0.027, 0.017, 0.018, 0.025, 0.029, 0.018, 0.023, 0.018, 0.016, 0.018, 0.026, 0.022, 0.016, 0.026, 0.03, 0.018, 0.02, 0.022, 0.032, 0.047, 0.017, 0.009, 0.03, 0.019, 0.025, 0.025, 0.027, 0.016, 0.017, 0.019, 0.033, 0.024, 0.012, 0.021, 0.034, 0.022, 0.023, 0.016, 0.019, 0.022, 0.022, 0.022, 0.015, 0.04, 0.029, 0.018, 0.034, 0.01, 0.019, 0.022, 0.032, 0.015, 0.036, 0.014, 0.034, 0.02, 0.015, 0.03, 0.028, 0.017, 0.017, 0.03, 0.034, 0.012, 0.026, 0.013, 0.02, 0.016, 0.019, 0.019, 0.02, 0.017, 0.015, 0.014, 0.025, 0.029, 0.025, 0.027, 0.028, 0.047, 0.021, 0.019, 0.027, 0.028, 0.016, 0.026, 0.028, 0.018, 0.013, 0.017, 0.025, 0.03, 0.021, 0.035, 0.038, 0.051, 0.023, 0.018, 0.028, 0.024, 0.026, 0.011, 0.028, 0.03, 0.015, 0.023, 0.02, 0.024, 0.024, 0.022, 0.019, 0.037, 0.023, 0.012, 0.033, 0.023, 0.019, 0.02, 0.015, 0.025, 0.027, 0.03, 0.027, 0.027, 0.033, 0.038, 0.033]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:50:58] [0] \t\t #> Encoding 52 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 75.24it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2507.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:50:58] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:50:58] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:50:58] len(emb2pid) = 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 106142.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:50:58] #> Saved optimized IVF to .ragatouille/colbert/indexes/fin_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:51:04] #> Loading codec...\n",
      "[Jul 29, 14:51:04] #> Loading IVF...\n",
      "[Jul 29, 14:51:04] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6543.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:51:04] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1825.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what was the percentage change in the 5 year annual performance of the peer group stock from 2010 to 2011, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 1996, 7017, 2689, 1999, 1996, 1019, 2095, 3296,\n",
      "        2836, 1997, 1996, 8152, 2177, 4518, 2013, 2230, 2000, 2249,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:51:04 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'what was the percentage change in the 5 year annual performance of the peer group stock from 2010 to 2011', 'response': 'There is no data provided for the 5-year annual performance of the peer group stock from 2010 to 2011.\\n The answer is: N/A', 'doc': 'JKHY_2015', 'q_uid': 'JKHY/2015/page_20.pdf-2', 'answers': {'str_answer': '8.3%', 'exe_answer': 0.08276}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:51:10] #> Loading codec...\n",
      "[Jul 29, 14:51:10] #> Loading IVF...\n",
      "[Jul 29, 14:51:10] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6168.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:51:10] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1651.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: in 2010 , what was the cumulative total return of the s&p 500?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1999,  2230,  1010,  2054,  2001,  1996, 23260,  2561,\n",
      "         2709,  1997,  1996,  1055,  1004,  1052,  3156,  1029,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:51:10 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'in 2010 , what was the cumulative total return of the s&p 500?', 'response': 'The answer is: 9.6%', 'doc': 'JKHY_2015', 'q_uid': 'JKHY/2015/page_20.pdf-3', 'answers': {'str_answer': '30.69', 'exe_answer': 30.69}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:51:16] #> Loading codec...\n",
      "[Jul 29, 14:51:16] #> Loading IVF...\n",
      "[Jul 29, 14:51:16] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4928.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:51:16] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1298.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: for the 2010 , what was the cumulative total return on jkhy?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2005,  1996,  2230,  1010,  2054,  2001,  1996, 23260,\n",
      "         2561,  2709,  2006,  1046, 10023,  2100,  1029,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:51:16 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'for the 2010 , what was the cumulative total return on jkhy?', 'response': 'No data provided for 2010 cumulative total return on JKHY.\\n The answer is: N/A', 'doc': 'JKHY_2015', 'q_uid': 'JKHY/2015/page_20.pdf-1', 'answers': {'str_answer': '27.44', 'exe_answer': 27.44}}\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ABC_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DG_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/JPM_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/IP_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/GRMN_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/IP_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/EMN_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/PNC_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ZBH_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RL_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/APTV_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ORLY_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MMM_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SLG_2012.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MSI_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MAR_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MRO_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RL_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/JKHY_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HUM_2014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DVN_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SNPS_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MRO_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AAPL_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/C_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/V_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AAPL_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ORLY_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/EL_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RE_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ORLY_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HIG_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DRE_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AMAT_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HOLX_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DISH_2014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SLG_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SLG_2002.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/VNO_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/IP_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DISCA_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AOS_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/FRT_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ILMN_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MSI_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/STZ_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/VRTX_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AWK_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/LMT_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ETFC_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/UPS_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ORLY_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HUM_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/IPG_2003.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ETFC_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/CCI_2004.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/EMN_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MRO_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AES_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DRE_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ADI_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MA_2018.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RSG_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/UNP_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/JPM_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ADI_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/NCLH_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/KMI_2014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/BDX_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SLB_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AES_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/UPS_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/PNC_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AAPL_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/GPN_2014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DG_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/PKG_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/BKNG_2018.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HII_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/FRT_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HII_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/VLO_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RE_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RCL_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ABMD_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MMM_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/BLL_2012.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/JPM_2018.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AAPL_2004.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/BDX_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MSI_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SPGI_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AON_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/GRMN_2004.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/CDW_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/EMN_2018.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DG_2005.pdf\n",
      "=== Start fin on falcon-e-3B ===\n",
      "2025-07-29 14:51:17 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:51:45,827 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:51:50 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:51:52] #> Note: Output directory .ragatouille/colbert/indexes/fin_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 14:51:52] #> Will delete 10 files already at .ragatouille/colbert/indexes/fin_vector_db in 20 seconds...\n",
      "[Jul 29, 14:52:15] [0] \t\t #> Encoding 50 passages..\n",
      "[Jul 29, 14:52:15] [0] \t\t avg_doclen_est = 3.819999933242798 \t len(local_sample) = 50\n",
      "[Jul 29, 14:52:15] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/fin_vector_db/plan.json ..\n",
      "Warning: number of training points (182) is less than the minimum recommended (1280)\n",
      "used 4 iterations (0.0009s) to cluster 182 items into 128 clusters\n",
      "[0.016, 0.013, 0.02, 0.007, 0.025, 0.009, 0.018, 0.011, 0.03, 0.019, 0.01, 0.014, 0.013, 0.014, 0.016, 0.013, 0.014, 0.013, 0.028, 0.026, 0.018, 0.03, 0.018, 0.018, 0.014, 0.031, 0.012, 0.005, 0.014, 0.019, 0.024, 0.02, 0.011, 0.012, 0.014, 0.025, 0.013, 0.017, 0.012, 0.022, 0.008, 0.018, 0.02, 0.03, 0.017, 0.022, 0.019, 0.013, 0.022, 0.027, 0.025, 0.019, 0.013, 0.007, 0.014, 0.019, 0.017, 0.024, 0.022, 0.026, 0.012, 0.01, 0.014, 0.029, 0.014, 0.018, 0.018, 0.017, 0.009, 0.013, 0.025, 0.011, 0.014, 0.018, 0.022, 0.033, 0.033, 0.015, 0.026, 0.03, 0.027, 0.019, 0.005, 0.019, 0.023, 0.023, 0.008, 0.012, 0.013, 0.02, 0.018, 0.022, 0.019, 0.021, 0.019, 0.01, 0.017, 0.018, 0.021, 0.023, 0.016, 0.021, 0.016, 0.016, 0.008, 0.019, 0.026, 0.028, 0.023, 0.012, 0.012, 0.008, 0.018, 0.024, 0.006, 0.019, 0.021, 0.017, 0.019, 0.009, 0.008, 0.019, 0.014, 0.018, 0.019, 0.016, 0.029, 0.024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:52:15] [0] \t\t #> Encoding 50 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 83.21it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2851.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:52:15] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:52:15] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:52:15] len(emb2pid) = 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 166626.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:52:15] #> Saved optimized IVF to .ragatouille/colbert/indexes/fin_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:52:21] #> Loading codec...\n",
      "[Jul 29, 14:52:21] #> Loading IVF...\n",
      "[Jul 29, 14:52:21] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5322.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:52:21] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1928.42it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what percentage of total long-term assets under supervision are comprised of fixed income in 2015?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  7017,  1997,  2561,  2146,  1011,  2744,  7045,\n",
      "         2104, 10429,  2024, 11539,  1997,  4964,  3318,  1999,  2325,  1029,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:52:21 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'what percentage of total long-term assets under supervision are comprised of fixed income in 2015?', 'response': 'The answer is: 37.4%.\\n The answer is: 37.4%.', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_79.pdf-3', 'answers': {'str_answer': '57%', 'exe_answer': 0.57484}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:52:34] #> Loading codec...\n",
      "[Jul 29, 14:52:34] #> Loading IVF...\n",
      "[Jul 29, 14:52:34] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5426.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:52:34] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1353.44it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what percentage of total long-term assets under supervision are comprised of fixed income in 2016?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  7017,  1997,  2561,  2146,  1011,  2744,  7045,\n",
      "         2104, 10429,  2024, 11539,  1997,  4964,  3318,  1999,  2355,  1029,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:52:34 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'what percentage of total long-term assets under supervision are comprised of fixed income in 2016?', 'response': 'The answer is: 37.5%.\\n The answer is: 37.5%.', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_79.pdf-1', 'answers': {'str_answer': '59%', 'exe_answer': 0.588}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:52:42] #> Loading codec...\n",
      "[Jul 29, 14:52:42] #> Loading IVF...\n",
      "[Jul 29, 14:52:42] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5461.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:52:42] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1540.32it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what percentage of total loans receivable gross in 2016 were loans backed by commercial real estate?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  7017,  1997,  2561, 10940, 28667,  7416, 12423,\n",
      "         7977,  1999,  2355,  2020, 10940,  6153,  2011,  3293,  2613,  3776,\n",
      "         1029,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:52:42 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'what percentage of total loans receivable gross in 2016 were loans backed by commercial real estate?', 'response': '47%\\n The answer is: 47%', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_161.pdf-1', 'answers': {'str_answer': '9%', 'exe_answer': 0.09488}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:52:49] #> Loading codec...\n",
      "[Jul 29, 14:52:49] #> Loading IVF...\n",
      "[Jul 29, 14:52:49] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4928.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:52:49] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1379.71it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what percentage of future minimum rental payments are due in 2018?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  7017,  1997,  2925,  6263, 12635, 10504,  2024,\n",
      "         2349,  1999,  2760,  1029,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:52:50 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'what percentage of future minimum rental payments are due in 2018?', 'response': 'The answer is: 30%.\\n The answer is: 30%.', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_183.pdf-3', 'answers': {'str_answer': '15%', 'exe_answer': 0.14529}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:52:57] #> Loading codec...\n",
      "[Jul 29, 14:52:57] #> Loading IVF...\n",
      "[Jul 29, 14:52:57] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5146.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:52:57] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 977.69it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: in millions , for 2016 , 2015 , and 2014 what was the total amount of common share repurchases?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1999,  8817,  1010,  2005,  2355,  1010,  2325,  1010,\n",
      "         1998,  2297,  2054,  2001,  1996,  2561,  3815,  1997,  2691,  3745,\n",
      "        16360,  3126, 26300,  2015,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:52:57 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'in millions , for 2016 , 2015 , and 2014 what was the total amount of common share repurchases?', 'response': 'The total amount of common share repurchases in 2016 was $300 million, in 2015 it was $200 million, and in 2014 it was $100 million.\\n The answer is: 300, 200, 100 (in millions)', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_186.pdf-2', 'answers': {'str_answer': '90.1', 'exe_answer': 90.5}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:53:08] #> Loading codec...\n",
      "[Jul 29, 14:53:08] #> Loading IVF...\n",
      "[Jul 29, 14:53:08] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4534.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:53:08] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1315.65it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: of the total aus net inflows/ ( outflows ) for 2014 were fixed income asset inflows in connection with our acquisition of deutsche asset & wealth management 2019s stable value business greater than the liquidity products inflows in connection with our acquisition of rbs asset management 2019s money market funds?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([67]), tensor([  101,     1,  1997,  1996,  2561, 17151,  5658,  1999, 12314,  2015,\n",
      "         1013,  1006,  2041, 12314,  2015,  1007,  2005,  2297,  2020,  4964,\n",
      "         3318, 11412,  1999, 12314,  2015,  1999,  4434,  2007,  2256,  7654,\n",
      "         1997, 11605, 11412,  1004,  7177,  2968, 10476,  2015,  6540,  3643,\n",
      "         2449,  3618,  2084,  1996,  6381,  3012,  3688,  1999, 12314,  2015,\n",
      "         1999,  4434,  2007,  2256,  7654,  1997, 21144,  2015, 11412,  2968,\n",
      "        10476,  2015,  2769,  3006,  5029,  1029,   102], device='cuda:0')\n",
      "#> Output Mask: torch.Size([67]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       device='cuda:0')\n",
      "\n",
      "2025-07-29 14:53:08 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'of the total aus net inflows/ ( outflows ) for 2014 were fixed income asset inflows in connection with our acquisition of deutsche asset & wealth management 2019s stable value business greater than the liquidity products inflows in connection with our acquisition of rbs asset management 2019s money market funds?', 'response': 'The answer is: 30%.', 'doc': 'GS_2016', 'q_uid': 'GS/2016/page_79.pdf-4', 'answers': {'str_answer': 'yes', 'exe_answer': 'yes'}}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:53:11] #> Note: Output directory .ragatouille/colbert/indexes/fin_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 14:53:11] #> Will delete 10 files already at .ragatouille/colbert/indexes/fin_vector_db in 20 seconds...\n",
      "[Jul 29, 14:53:34] [0] \t\t #> Encoding 52 passages..\n",
      "[Jul 29, 14:53:34] [0] \t\t avg_doclen_est = 3.826923131942749 \t len(local_sample) = 52\n",
      "[Jul 29, 14:53:34] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/fin_vector_db/plan.json ..\n",
      "Warning: number of training points (190) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.001s) to cluster 190 items into 128 clusters\n",
      "[0.022, 0.027, 0.017, 0.018, 0.025, 0.029, 0.018, 0.023, 0.018, 0.016, 0.018, 0.026, 0.022, 0.016, 0.026, 0.03, 0.018, 0.02, 0.022, 0.032, 0.047, 0.017, 0.009, 0.03, 0.019, 0.025, 0.025, 0.027, 0.016, 0.017, 0.019, 0.033, 0.024, 0.012, 0.021, 0.034, 0.022, 0.023, 0.016, 0.019, 0.022, 0.022, 0.022, 0.015, 0.04, 0.029, 0.018, 0.034, 0.01, 0.019, 0.022, 0.032, 0.015, 0.036, 0.014, 0.034, 0.02, 0.015, 0.03, 0.028, 0.017, 0.017, 0.03, 0.034, 0.012, 0.026, 0.013, 0.02, 0.016, 0.019, 0.019, 0.02, 0.017, 0.015, 0.014, 0.025, 0.029, 0.025, 0.027, 0.028, 0.047, 0.021, 0.019, 0.027, 0.028, 0.016, 0.026, 0.028, 0.018, 0.013, 0.017, 0.025, 0.03, 0.021, 0.035, 0.038, 0.051, 0.023, 0.018, 0.028, 0.024, 0.026, 0.011, 0.028, 0.03, 0.015, 0.023, 0.02, 0.024, 0.024, 0.022, 0.019, 0.037, 0.023, 0.012, 0.033, 0.023, 0.019, 0.02, 0.015, 0.025, 0.027, 0.03, 0.027, 0.027, 0.033, 0.038, 0.033]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:53:34] [0] \t\t #> Encoding 52 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 76.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2060.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:53:34] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:53:34] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:53:34] len(emb2pid) = 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 156067.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:53:34] #> Saved optimized IVF to .ragatouille/colbert/indexes/fin_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:53:40] #> Loading codec...\n",
      "[Jul 29, 14:53:40] #> Loading IVF...\n",
      "[Jul 29, 14:53:40] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5171.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:53:40] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1778.75it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what was the percentage change in the 5 year annual performance of the peer group stock from 2010 to 2011, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 1996, 7017, 2689, 1999, 1996, 1019, 2095, 3296,\n",
      "        2836, 1997, 1996, 8152, 2177, 4518, 2013, 2230, 2000, 2249,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:53:40 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'what was the percentage change in the 5 year annual performance of the peer group stock from 2010 to 2011', 'response': 'The percentage change in the 5 year annual performance of the peer group stock from 2010 to 2011 is -3.7%.\\n The answer is: -3.7%', 'doc': 'JKHY_2015', 'q_uid': 'JKHY/2015/page_20.pdf-2', 'answers': {'str_answer': '8.3%', 'exe_answer': 0.08276}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:53:49] #> Loading codec...\n",
      "[Jul 29, 14:53:49] #> Loading IVF...\n",
      "[Jul 29, 14:53:49] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5949.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:53:49] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1788.62it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: in 2010 , what was the cumulative total return of the s&p 500?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1999,  2230,  1010,  2054,  2001,  1996, 23260,  2561,\n",
      "         2709,  1997,  1996,  1055,  1004,  1052,  3156,  1029,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:53:49 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'in 2010 , what was the cumulative total return of the s&p 500?', 'response': 'The answer is: -4.7%', 'doc': 'JKHY_2015', 'q_uid': 'JKHY/2015/page_20.pdf-3', 'answers': {'str_answer': '30.69', 'exe_answer': 30.69}}\n",
      "Loading searcher for index fin_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:53:55] #> Loading codec...\n",
      "[Jul 29, 14:53:55] #> Loading IVF...\n",
      "[Jul 29, 14:53:55] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 3542.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:53:55] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1657.17it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: for the 2010 , what was the cumulative total return on jkhy?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2005,  1996,  2230,  1010,  2054,  2001,  1996, 23260,\n",
      "         2561,  2709,  2006,  1046, 10023,  2100,  1029,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:53:55 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'for the 2010 , what was the cumulative total return on jkhy?', 'response': 'The cumulative total return on jkhy in 2010 was -3.67%.\\n The answer is: -3.67%', 'doc': 'JKHY_2015', 'q_uid': 'JKHY/2015/page_20.pdf-1', 'answers': {'str_answer': '27.44', 'exe_answer': 27.44}}\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ABC_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DG_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/JPM_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/IP_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/GRMN_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/IP_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/EMN_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/PNC_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ZBH_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RL_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/APTV_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ORLY_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MMM_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SLG_2012.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MSI_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MAR_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MRO_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RL_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/JKHY_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HUM_2014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DVN_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SNPS_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MRO_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AAPL_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/C_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/V_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AAPL_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ORLY_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/EL_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RE_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ORLY_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HIG_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DRE_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AMAT_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HOLX_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DISH_2014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SLG_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SLG_2002.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/VNO_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/IP_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DISCA_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AOS_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/FRT_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ILMN_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MSI_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/STZ_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/VRTX_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AWK_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/LMT_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ETFC_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/UPS_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ORLY_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HUM_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/IPG_2003.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ETFC_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/CCI_2004.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/EMN_2006.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MRO_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AES_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DRE_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ADI_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MA_2018.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RSG_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/UNP_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/JPM_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ADI_2007.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/NCLH_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/KMI_2014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/BDX_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SLB_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AES_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/UPS_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/PNC_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AAPL_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/GPN_2014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DG_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/PKG_2011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/BKNG_2018.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HII_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/FRT_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/HII_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/VLO_2016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RE_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/RCL_2013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/ABMD_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MMM_2005.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/BLL_2012.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/JPM_2018.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AAPL_2004.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/BDX_2009.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/MSI_2008.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/SPGI_2017.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/AON_2010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/GRMN_2004.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/CDW_2015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/EMN_2018.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/fin_docs/DG_2005.pdf\n",
      "=== Finish fin ===\n",
      "\n",
      "=== Start feta on meno-tiny ===\n",
      "2025-07-29 14:53:58 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:53:58,929 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:54:02 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:54:04] #> Creating directory .ragatouille/colbert/indexes/feta_vector_db \n",
      "\n",
      "\n",
      "[Jul 29, 14:54:06] [0] \t\t #> Encoding 64 passages..\n",
      "[Jul 29, 14:54:06] [0] \t\t avg_doclen_est = 3.84375 \t len(local_sample) = 64\n",
      "[Jul 29, 14:54:06] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/feta_vector_db/plan.json ..\n",
      "Warning: number of training points (234) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0073s) to cluster 234 items into 128 clusters\n",
      "[0.01, 0.013, 0.006, 0.018, 0.005, 0.013, 0.007, 0.007, 0.016, 0.007, 0.011, 0.011, 0.022, 0.004, 0.009, 0.017, 0.005, 0.011, 0.01, 0.027, 0.009, 0.014, 0.007, 0.015, 0.018, 0.008, 0.017, 0.008, 0.01, 0.01, 0.014, 0.011, 0.013, 0.005, 0.009, 0.014, 0.007, 0.014, 0.014, 0.024, 0.014, 0.008, 0.016, 0.017, 0.014, 0.016, 0.012, 0.019, 0.017, 0.012, 0.017, 0.016, 0.009, 0.017, 0.006, 0.023, 0.01, 0.008, 0.005, 0.019, 0.019, 0.022, 0.017, 0.016, 0.017, 0.007, 0.022, 0.019, 0.016, 0.012, 0.012, 0.018, 0.009, 0.007, 0.008, 0.017, 0.018, 0.009, 0.013, 0.024, 0.028, 0.006, 0.005, 0.008, 0.016, 0.009, 0.017, 0.016, 0.012, 0.013, 0.01, 0.018, 0.008, 0.016, 0.013, 0.024, 0.031, 0.028, 0.015, 0.013, 0.002, 0.019, 0.014, 0.013, 0.015, 0.017, 0.008, 0.019, 0.015, 0.007, 0.01, 0.016, 0.017, 0.015, 0.017, 0.008, 0.008, 0.015, 0.013, 0.007, 0.018, 0.009, 0.01, 0.019, 0.019, 0.021, 0.029, 0.011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:54:07] [0] \t\t #> Encoding 64 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 46.14it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2624.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:54:07] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:54:07] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:54:07] len(emb2pid) = 246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 173240.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:54:07] #> Saved optimized IVF to .ragatouille/colbert/indexes/feta_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index feta_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:54:12] #> Loading codec...\n",
      "[Jul 29, 14:54:12] #> Loading IVF...\n",
      "[Jul 29, 14:54:12] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6990.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:54:12] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1781.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: Which season of Smallville performed the best during it's airing? , \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2029,  2161,  1997,  2235,  3077,  2864,  1996,  2190,\n",
      "         2076,  2009,  1005,  1055, 10499,  1029,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:54:12 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': \"Which season of Smallville performed the best during it's airing? \", 'response': \"The answer is: The third season of Smallville performed the best during it's airing.\", 'doc': 'Smallville', 'q_uid': 12844, 'answers': \"Over ten seasons the Smallville averaged, million viewers per episode, is with season two's highest rating of 6.3 million.\"}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:54:15] #> Note: Output directory .ragatouille/colbert/indexes/feta_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 14:54:15] #> Will delete 10 files already at .ragatouille/colbert/indexes/feta_vector_db in 20 seconds...\n",
      "[Jul 29, 14:54:38] [0] \t\t #> Encoding 68 passages..\n",
      "[Jul 29, 14:54:38] [0] \t\t avg_doclen_est = 3.838235378265381 \t len(local_sample) = 68\n",
      "[Jul 29, 14:54:38] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/feta_vector_db/plan.json ..\n",
      "Warning: number of training points (248) is less than the minimum recommended (2560)\n",
      "used 3 iterations (0.0009s) to cluster 248 items into 256 clusters\n",
      "[0.008, 0.005, 0.006, 0.003, 0.003, 0.01, 0.003, 0.004, 0.002, 0.001, 0.008, 0.001, 0.008, 0.005, 0.003, 0.012, 0.004, 0.008, 0.005, 0.006, 0.004, 0.007, 0.008, 0.008, 0.01, 0.005, 0.004, 0.012, 0.004, 0.005, 0.002, 0.006, 0.003, 0.004, 0.014, 0.007, 0.008, 0.006, 0.001, 0.002, 0.006, 0.005, 0.007, 0.017, 0.004, 0.004, 0.008, 0.009, 0.005, 0.007, 0.006, 0.002, 0.007, 0.002, 0.008, 0.007, 0.002, 0.01, 0.008, 0.003, 0.005, 0.003, 0.006, 0.011, 0.01, 0.008, 0.006, 0.005, 0.005, 0.011, 0.007, 0.008, 0.004, 0.002, 0.002, 0.001, 0.005, 0.011, 0.003, 0.006, 0.007, 0.006, 0.002, 0.009, 0.004, 0.005, 0.004, 0.004, 0.005, 0.006, 0.003, 0.005, 0.006, 0.01, 0.004, 0.006, 0.004, 0.009, 0.011, 0.006, 0.002, 0.002, 0.003, 0.006, 0.004, 0.005, 0.007, 0.007, 0.005, 0.013, 0.009, 0.001, 0.008, 0.009, 0.013, 0.007, 0.005, 0.004, 0.011, 0.006, 0.006, 0.005, 0.004, 0.003, 0.002, 0.007, 0.008, 0.007]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:54:38] [0] \t\t #> Encoding 68 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 48.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 930.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:54:38] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:54:38] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:54:38] len(emb2pid) = 261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 63674.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:54:38] #> Saved optimized IVF to .ragatouille/colbert/indexes/feta_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index feta_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:54:43] #> Loading codec...\n",
      "[Jul 29, 14:54:43] #> Loading IVF...\n",
      "[Jul 29, 14:54:43] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6141.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:54:43] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1619.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: In which film did Jennifer Jones star in 1995 and in which consequent film did she take on a role in 1956? , \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1999,  2029,  2143,  2106,  7673,  3557,  2732,  1999,\n",
      "         2786,  1998,  1999,  2029,  9530,  3366, 15417,  2143,  2106,  2016,\n",
      "         2202,  2006,  1037,  2535,  1999,  3838,  1029,   102,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:54:44 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'In which film did Jennifer Jones star in 1995 and in which consequent film did she take on a role in 1956? ', 'response': 'The answer is: In 1995 and in 1956.', 'doc': 'Jennifer Jones', 'q_uid': 19050, 'answers': 'Jennifer Jones starred in Good Morning, Miss Dove in 1955, followed by a role in The Man in the Gray Flannel Suit.'}\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Aaron Taylor-Johnson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Athletics at the 2016 Summer Olympics – Men's 400 metres.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Renewable energy in Germany.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of awards and nominations received by Nicki Minaj.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/LisaRaye McCoy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Teri Polo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hayden Panettiere.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Peter Sallis.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Tonight Show.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Spartan army.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Cricket World Cup awards.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/1916 Cumberland vs. Georgia Tech football game.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Victoria Justice.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Derek Theler.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/United States at the FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Femina Miss India.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Anna Faris.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mesut Özil.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Ashley Williams (actress).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lloyd's of London.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Chuck (TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jyotica Tangri.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Karyn White.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Group of Eight.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/T.J. Miller.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Paraguay at the FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Arthur (TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Bethany Joy Lenz.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Love & Hip Hop.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of highest-grossing Indian films in overseas markets.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Zachary Gordon.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/1972 Miami Dolphins season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Monica (singer).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Lion King (musical).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of Andhra Pradesh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Christa B. Allen.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/All India Institutes of Medical Sciences.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Sample-return mission.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Geography of Japan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Death Cab for Cutie.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Sarah Wayne Callies.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Josh Peck.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Total Drama All-Stars and Pahkitew Island.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Carly Chaikin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Six Flags Over Georgia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Gangnam Style.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hawthorn Football Club.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tears in Heaven.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Gary Holton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Victoria Hamilton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Speak Now.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/North Dakota State Bison football.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2014 Indian Super League season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of earthquakes in South Africa.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Elsa Pataky.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jaime Pressly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2016 Tour de France.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Skye McCole Bartusiak.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Better Call Saul episodes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/William Fichtner.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jennifer Landon.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2014 Tour de France.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of awards and nominations received by Bruno Mars.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of NASCAR drivers who have won in each of top three series.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Dylan Minnette.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Amy Jackson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of longest-serving mayors in the United States.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of FIFA World Cup winners.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Need You Now (Lady Antebellum song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/University of Miami.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Gavin MacLeod.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Karen David.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of Himachal Pradesh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lindsey Stirling.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Bentley Continental GT.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Charlie Hunnam.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Topher Grace.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Formula One driver records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Billy Elliot the Musical.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Premiership Rugby.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Speakers of the National Assembly of Guyana.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hawaii Five-0 (2010 TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/John Rhys-Davies.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Courtney Ford.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Claudia Wells.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Holy Roman Emperor.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Russell Wilson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/CSI: Miami.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tim Pigott-Smith.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Subaru Tribeca.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Religion in Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kurt Seyit ve Şura.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Khalid ibn al-Walid.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Qualified dividend.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Roberta Flack.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Maisie Williams.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mazda BT-50.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/You Belong with Me.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Joseph and the Amazing Technicolor Dreamcoat.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Ohio area codes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Wayne Brady.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Omaha, Nebraska.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of 2018 Indian Premier League personnel changes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Vivien Leigh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kathy Najimy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Haviland Morris.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tower Heist.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Rag'n'Bone Man.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Thomas Newman.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of longest-running U.S. primetime television series.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Katherine Helmond.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/John Bell (Scottish actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2004 World Series.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Legend of Korra.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Taissa Farmiga.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/NHL outdoor games.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2018 Indianapolis 500.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Local governance in Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Richard Ayoade.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Heather Tom.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kevin Peter Hall.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jeffrey Dean Morgan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Raid 2.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Safe & Sound (Taylor Swift song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Toyota manufacturing facilities.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lela Rochon.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jonathan Jackson (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Nicholle Tom.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Standard deviation.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Courteney Cox.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Will Yun Lee.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of number-one Billboard Christian Albums.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of German football champions.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Akkadian Empire.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Elinor Donahue.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Yankee Stadium.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of the longest-running West End shows.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kathryn Beaumont.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kokoda Track.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Larisa Oleynik.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of awards and nominations received by Michael Jackson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/American Ninja Warrior (season 9).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of governors of Bengal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Grace Kelly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Samsung Galaxy Note II.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Grade inflation.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Dave Bautista.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Oasis discography.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Long Day's Journey into Night.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/June Marlowe.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Reba (TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of UFC records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of awards and nominations received by Game of Thrones.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mike Birbiglia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mike & Molly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lucy Hale.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Thomas Fire.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Adrian Rawlins.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/We Are Never Ever Getting Back Together.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2018 Australian Grand Prix.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Major League Baseball progressive single-season home run leaders.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Perla Haney-Jardine.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Equal Employment Opportunity Commission.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jeffrey Donovan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Brett Favre.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Twenty One Pilots discography.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Fresh Prince of Bel-Air.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Rob Beckett.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Shailene Woodley.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Plitvice Lakes National Park.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Poseidon Adventure (1972 film).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Andra Day.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Robert Urich.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Momordica charantia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/René Auberjonois.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Social Security Wage Base.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Fluid ounce.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2016 Cleveland Browns season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Stadium Australia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Dennis Hopper.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Portugal. The Man.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of districts of Nepal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Colleen Ballinger.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Districts of Pakistan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Body mass index.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of West Bengal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Stanley Cup champions.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of career achievements by Wayne Gretzky.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Vancouver Grizzlies.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lily Collins.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Honda CBR600F.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Michael Clarke Duncan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/California State Assembly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lesley-Ann Brandt.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Ryder Cup records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/O'Shea Jackson Jr..pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/1990 AFL Grand Final.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Coins of the United States dollar.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Bianca Kajlich.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hilarie Burton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Oklahoma.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Foie gras.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Havana (Camila Cabello song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of best-selling albums in the United States.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Asa Butterfield.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/AirPort Time Capsule.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hannah John-Kamen.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Canadian islands by area.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jimi Jamison.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mischa Barton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Protectorate of Bohemia and Moravia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Game of the Year awards.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Adventures of Tintin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Married to the Mob.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hawaii.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Spartacus characters.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/South Armagh Sniper (1990–1997).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Purdue Boilermakers football.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Greta Garbo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/FIFA Club World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/London Calling (song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of Punjab (India).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Run the World (Girls).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of tallest buildings in India.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/I Look to You.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Uzo Aduba.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of longest films.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Crosby, Stills & Nash (album).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/John Harbaugh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Guardians of the Galaxy members.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Sri Lanka Test cricket records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Freddy Fender.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Merritt Patterson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/King of the Ring.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Best Thing I Never Had.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Shake It Off.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Scream & Shout.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Shirley Henderson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Prime Minister of Jamaica.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2018 Chicago Bears season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Elizabeth Mitchell.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kris Boyd.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Thomas F. Wilson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Peter Egan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Rose McGowan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/California Polytechnic State University.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jon Bon Jovi.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kelvin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Matthew Goode.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Renault Clio.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Ann B. Davis.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mercury Grand Marquis.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Koenigsegg Agera.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Arnold Schwarzenegger.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Rashida Jones.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mo Farah.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/South America.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jennifer Hudson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Michael Bublé discography.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Total Drama: Revenge of the Island.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Visa policy of China.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Bryan Robson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/1986 FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Joanna Moore.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Deepika Chikhalia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tom Hughes (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Devin Hester.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/William Moseley (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Ku Hye-sun.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tom Felton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Big Brovaz.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Miami Dolphins broadcasters.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/David Oyelowo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jacob Rees-Mogg.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Eleanor Tomlinson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Wonder Woman enemies.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Miles Heizer.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Yvonne Strahovski.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Nora Arnezeder.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Seal (musician).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Batman: Death of the Family.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/115th United States Congress.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Premier League clubs.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Grayson Russell.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Earl Hindman.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of NBA franchise post-season droughts.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of highest-grossing Indian films.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2017–18 FC Barcelona season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Gasoline gallon equivalent.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lose Yourself.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Deuterocanonical books.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Dheeraj Dhoopar.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jodie Whittaker.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Luke Arnold.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/My Mad Fat Diary.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Faerie Tale Theatre episodes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lionel Messi.pdf\n",
      "=== Start feta on qwen2.5-1.5B ===\n",
      "2025-07-29 14:54:44 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:54:45,154 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:54:49 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:54:52] #> Note: Output directory .ragatouille/colbert/indexes/feta_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 14:54:52] #> Will delete 10 files already at .ragatouille/colbert/indexes/feta_vector_db in 20 seconds...\n",
      "[Jul 29, 14:55:14] [0] \t\t #> Encoding 64 passages..\n",
      "[Jul 29, 14:55:14] [0] \t\t avg_doclen_est = 3.84375 \t len(local_sample) = 64\n",
      "[Jul 29, 14:55:14] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/feta_vector_db/plan.json ..\n",
      "Warning: number of training points (234) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0011s) to cluster 234 items into 128 clusters\n",
      "[0.01, 0.013, 0.006, 0.018, 0.005, 0.013, 0.007, 0.007, 0.016, 0.007, 0.011, 0.011, 0.022, 0.004, 0.009, 0.017, 0.005, 0.011, 0.01, 0.027, 0.009, 0.014, 0.007, 0.015, 0.018, 0.008, 0.017, 0.008, 0.01, 0.01, 0.014, 0.011, 0.013, 0.005, 0.009, 0.014, 0.007, 0.014, 0.014, 0.024, 0.014, 0.008, 0.016, 0.017, 0.014, 0.016, 0.012, 0.019, 0.017, 0.012, 0.017, 0.016, 0.009, 0.017, 0.006, 0.023, 0.01, 0.008, 0.005, 0.019, 0.019, 0.022, 0.017, 0.016, 0.017, 0.007, 0.022, 0.019, 0.016, 0.012, 0.012, 0.018, 0.009, 0.007, 0.008, 0.017, 0.018, 0.009, 0.013, 0.024, 0.028, 0.006, 0.005, 0.008, 0.016, 0.009, 0.017, 0.016, 0.012, 0.013, 0.01, 0.018, 0.008, 0.016, 0.013, 0.024, 0.031, 0.028, 0.015, 0.013, 0.002, 0.019, 0.014, 0.013, 0.015, 0.017, 0.008, 0.019, 0.015, 0.007, 0.01, 0.016, 0.017, 0.015, 0.017, 0.008, 0.008, 0.015, 0.013, 0.007, 0.018, 0.009, 0.01, 0.019, 0.019, 0.021, 0.029, 0.011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:55:14] [0] \t\t #> Encoding 64 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 78.39it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2552.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:55:14] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:55:14] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:55:14] len(emb2pid) = 246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 108131.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:55:14] #> Saved optimized IVF to .ragatouille/colbert/indexes/feta_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index feta_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:55:20] #> Loading codec...\n",
      "[Jul 29, 14:55:20] #> Loading IVF...\n",
      "[Jul 29, 14:55:20] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6204.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:55:20] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1579.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: Which season of Smallville performed the best during it's airing? , \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2029,  2161,  1997,  2235,  3077,  2864,  1996,  2190,\n",
      "         2076,  2009,  1005,  1055, 10499,  1029,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:55:20 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': \"Which season of Smallville performed the best during it's airing? \", 'response': 'The answer is: Season 5 performed the best during its airing.', 'doc': 'Smallville', 'q_uid': 12844, 'answers': \"Over ten seasons the Smallville averaged, million viewers per episode, is with season two's highest rating of 6.3 million.\"}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:55:23] #> Note: Output directory .ragatouille/colbert/indexes/feta_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 14:55:23] #> Will delete 10 files already at .ragatouille/colbert/indexes/feta_vector_db in 20 seconds...\n",
      "[Jul 29, 14:55:45] [0] \t\t #> Encoding 68 passages..\n",
      "[Jul 29, 14:55:46] [0] \t\t avg_doclen_est = 3.838235378265381 \t len(local_sample) = 68\n",
      "[Jul 29, 14:55:46] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/feta_vector_db/plan.json ..\n",
      "Warning: number of training points (248) is less than the minimum recommended (2560)\n",
      "used 3 iterations (0.0011s) to cluster 248 items into 256 clusters\n",
      "[0.008, 0.005, 0.006, 0.003, 0.003, 0.01, 0.003, 0.004, 0.002, 0.001, 0.008, 0.001, 0.008, 0.005, 0.003, 0.012, 0.004, 0.008, 0.005, 0.006, 0.004, 0.007, 0.008, 0.008, 0.01, 0.005, 0.004, 0.012, 0.004, 0.005, 0.002, 0.006, 0.003, 0.004, 0.014, 0.007, 0.008, 0.006, 0.001, 0.002, 0.006, 0.005, 0.007, 0.017, 0.004, 0.004, 0.008, 0.009, 0.005, 0.007, 0.006, 0.002, 0.007, 0.002, 0.008, 0.007, 0.002, 0.01, 0.008, 0.003, 0.005, 0.003, 0.006, 0.011, 0.01, 0.008, 0.006, 0.005, 0.005, 0.011, 0.007, 0.008, 0.004, 0.002, 0.002, 0.001, 0.005, 0.011, 0.003, 0.006, 0.007, 0.006, 0.002, 0.009, 0.004, 0.005, 0.004, 0.004, 0.005, 0.006, 0.003, 0.005, 0.006, 0.01, 0.004, 0.006, 0.004, 0.009, 0.011, 0.006, 0.002, 0.002, 0.003, 0.006, 0.004, 0.005, 0.007, 0.007, 0.005, 0.013, 0.009, 0.001, 0.008, 0.009, 0.013, 0.007, 0.005, 0.004, 0.011, 0.006, 0.006, 0.005, 0.004, 0.003, 0.002, 0.007, 0.008, 0.007]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:55:46] [0] \t\t #> Encoding 68 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 57.69it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2053.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:55:46] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:55:46] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:55:46] len(emb2pid) = 261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 140726.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:55:46] #> Saved optimized IVF to .ragatouille/colbert/indexes/feta_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index feta_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:55:51] #> Loading codec...\n",
      "[Jul 29, 14:55:51] #> Loading IVF...\n",
      "[Jul 29, 14:55:51] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6647.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:55:51] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1583.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: In which film did Jennifer Jones star in 1995 and in which consequent film did she take on a role in 1956? , \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1999,  2029,  2143,  2106,  7673,  3557,  2732,  1999,\n",
      "         2786,  1998,  1999,  2029,  9530,  3366, 15417,  2143,  2106,  2016,\n",
      "         2202,  2006,  1037,  2535,  1999,  3838,  1029,   102,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:55:51 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'In which film did Jennifer Jones star in 1995 and in which consequent film did she take on a role in 1956? ', 'response': 'The answer is: Jennifer Jones starred in On Golden Pond in 1995 and took on a role in The Manchurian Candidate in 1956.', 'doc': 'Jennifer Jones', 'q_uid': 19050, 'answers': 'Jennifer Jones starred in Good Morning, Miss Dove in 1955, followed by a role in The Man in the Gray Flannel Suit.'}\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Aaron Taylor-Johnson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Athletics at the 2016 Summer Olympics – Men's 400 metres.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Renewable energy in Germany.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of awards and nominations received by Nicki Minaj.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/LisaRaye McCoy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Teri Polo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hayden Panettiere.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Peter Sallis.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Tonight Show.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Spartan army.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Cricket World Cup awards.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/1916 Cumberland vs. Georgia Tech football game.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Victoria Justice.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Derek Theler.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/United States at the FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Femina Miss India.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Anna Faris.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mesut Özil.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Ashley Williams (actress).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lloyd's of London.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Chuck (TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jyotica Tangri.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Karyn White.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Group of Eight.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/T.J. Miller.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Paraguay at the FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Arthur (TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Bethany Joy Lenz.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Love & Hip Hop.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of highest-grossing Indian films in overseas markets.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Zachary Gordon.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/1972 Miami Dolphins season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Monica (singer).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Lion King (musical).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of Andhra Pradesh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Christa B. Allen.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/All India Institutes of Medical Sciences.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Sample-return mission.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Geography of Japan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Death Cab for Cutie.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Sarah Wayne Callies.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Josh Peck.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Total Drama All-Stars and Pahkitew Island.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Carly Chaikin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Six Flags Over Georgia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Gangnam Style.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hawthorn Football Club.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tears in Heaven.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Gary Holton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Victoria Hamilton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Speak Now.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/North Dakota State Bison football.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2014 Indian Super League season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of earthquakes in South Africa.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Elsa Pataky.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jaime Pressly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2016 Tour de France.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Skye McCole Bartusiak.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Better Call Saul episodes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/William Fichtner.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jennifer Landon.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2014 Tour de France.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of awards and nominations received by Bruno Mars.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of NASCAR drivers who have won in each of top three series.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Dylan Minnette.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Amy Jackson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of longest-serving mayors in the United States.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of FIFA World Cup winners.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Need You Now (Lady Antebellum song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/University of Miami.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Gavin MacLeod.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Karen David.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of Himachal Pradesh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lindsey Stirling.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Bentley Continental GT.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Charlie Hunnam.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Topher Grace.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Formula One driver records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Billy Elliot the Musical.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Premiership Rugby.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Speakers of the National Assembly of Guyana.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hawaii Five-0 (2010 TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/John Rhys-Davies.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Courtney Ford.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Claudia Wells.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Holy Roman Emperor.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Russell Wilson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/CSI: Miami.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tim Pigott-Smith.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Subaru Tribeca.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Religion in Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kurt Seyit ve Şura.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Khalid ibn al-Walid.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Qualified dividend.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Roberta Flack.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Maisie Williams.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mazda BT-50.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/You Belong with Me.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Joseph and the Amazing Technicolor Dreamcoat.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Ohio area codes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Wayne Brady.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Omaha, Nebraska.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of 2018 Indian Premier League personnel changes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Vivien Leigh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kathy Najimy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Haviland Morris.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tower Heist.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Rag'n'Bone Man.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Thomas Newman.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of longest-running U.S. primetime television series.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Katherine Helmond.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/John Bell (Scottish actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2004 World Series.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Legend of Korra.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Taissa Farmiga.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/NHL outdoor games.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2018 Indianapolis 500.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Local governance in Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Richard Ayoade.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Heather Tom.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kevin Peter Hall.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jeffrey Dean Morgan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Raid 2.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Safe & Sound (Taylor Swift song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Toyota manufacturing facilities.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lela Rochon.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jonathan Jackson (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Nicholle Tom.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Standard deviation.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Courteney Cox.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Will Yun Lee.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of number-one Billboard Christian Albums.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of German football champions.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Akkadian Empire.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Elinor Donahue.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Yankee Stadium.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of the longest-running West End shows.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kathryn Beaumont.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kokoda Track.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Larisa Oleynik.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of awards and nominations received by Michael Jackson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/American Ninja Warrior (season 9).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of governors of Bengal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Grace Kelly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Samsung Galaxy Note II.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Grade inflation.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Dave Bautista.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Oasis discography.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Long Day's Journey into Night.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/June Marlowe.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Reba (TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of UFC records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of awards and nominations received by Game of Thrones.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mike Birbiglia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mike & Molly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lucy Hale.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Thomas Fire.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Adrian Rawlins.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/We Are Never Ever Getting Back Together.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2018 Australian Grand Prix.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Major League Baseball progressive single-season home run leaders.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Perla Haney-Jardine.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Equal Employment Opportunity Commission.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jeffrey Donovan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Brett Favre.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Twenty One Pilots discography.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Fresh Prince of Bel-Air.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Rob Beckett.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Shailene Woodley.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Plitvice Lakes National Park.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Poseidon Adventure (1972 film).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Andra Day.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Robert Urich.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Momordica charantia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/René Auberjonois.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Social Security Wage Base.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Fluid ounce.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2016 Cleveland Browns season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Stadium Australia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Dennis Hopper.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Portugal. The Man.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of districts of Nepal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Colleen Ballinger.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Districts of Pakistan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Body mass index.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of West Bengal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Stanley Cup champions.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of career achievements by Wayne Gretzky.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Vancouver Grizzlies.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lily Collins.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Honda CBR600F.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Michael Clarke Duncan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/California State Assembly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lesley-Ann Brandt.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Ryder Cup records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/O'Shea Jackson Jr..pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/1990 AFL Grand Final.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Coins of the United States dollar.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Bianca Kajlich.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hilarie Burton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Oklahoma.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Foie gras.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Havana (Camila Cabello song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of best-selling albums in the United States.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Asa Butterfield.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/AirPort Time Capsule.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hannah John-Kamen.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Canadian islands by area.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jimi Jamison.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mischa Barton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Protectorate of Bohemia and Moravia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Game of the Year awards.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Adventures of Tintin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Married to the Mob.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hawaii.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Spartacus characters.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/South Armagh Sniper (1990–1997).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Purdue Boilermakers football.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Greta Garbo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/FIFA Club World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/London Calling (song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of Punjab (India).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Run the World (Girls).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of tallest buildings in India.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/I Look to You.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Uzo Aduba.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of longest films.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Crosby, Stills & Nash (album).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/John Harbaugh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Guardians of the Galaxy members.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Sri Lanka Test cricket records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Freddy Fender.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Merritt Patterson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/King of the Ring.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Best Thing I Never Had.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Shake It Off.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Scream & Shout.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Shirley Henderson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Prime Minister of Jamaica.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2018 Chicago Bears season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Elizabeth Mitchell.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kris Boyd.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Thomas F. Wilson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Peter Egan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Rose McGowan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/California Polytechnic State University.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jon Bon Jovi.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kelvin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Matthew Goode.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Renault Clio.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Ann B. Davis.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mercury Grand Marquis.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Koenigsegg Agera.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Arnold Schwarzenegger.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Rashida Jones.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mo Farah.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/South America.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jennifer Hudson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Michael Bublé discography.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Total Drama: Revenge of the Island.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Visa policy of China.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Bryan Robson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/1986 FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Joanna Moore.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Deepika Chikhalia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tom Hughes (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Devin Hester.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/William Moseley (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Ku Hye-sun.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tom Felton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Big Brovaz.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Miami Dolphins broadcasters.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/David Oyelowo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jacob Rees-Mogg.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Eleanor Tomlinson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Wonder Woman enemies.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Miles Heizer.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Yvonne Strahovski.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Nora Arnezeder.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Seal (musician).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Batman: Death of the Family.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/115th United States Congress.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Premier League clubs.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Grayson Russell.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Earl Hindman.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of NBA franchise post-season droughts.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of highest-grossing Indian films.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2017–18 FC Barcelona season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Gasoline gallon equivalent.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lose Yourself.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Deuterocanonical books.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Dheeraj Dhoopar.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jodie Whittaker.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Luke Arnold.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/My Mad Fat Diary.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Faerie Tale Theatre episodes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lionel Messi.pdf\n",
      "=== Start feta on qwen2.5-3B ===\n",
      "2025-07-29 14:55:52 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:55:52,702 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.22s/it]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:56:00 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:56:02] #> Note: Output directory .ragatouille/colbert/indexes/feta_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 14:56:02] #> Will delete 10 files already at .ragatouille/colbert/indexes/feta_vector_db in 20 seconds...\n",
      "[Jul 29, 14:56:25] [0] \t\t #> Encoding 64 passages..\n",
      "[Jul 29, 14:56:25] [0] \t\t avg_doclen_est = 3.84375 \t len(local_sample) = 64\n",
      "[Jul 29, 14:56:25] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/feta_vector_db/plan.json ..\n",
      "Warning: number of training points (234) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0011s) to cluster 234 items into 128 clusters\n",
      "[0.01, 0.013, 0.006, 0.018, 0.005, 0.013, 0.007, 0.007, 0.016, 0.007, 0.011, 0.011, 0.022, 0.004, 0.009, 0.017, 0.005, 0.011, 0.01, 0.027, 0.009, 0.014, 0.007, 0.015, 0.018, 0.008, 0.017, 0.008, 0.01, 0.01, 0.014, 0.011, 0.013, 0.005, 0.009, 0.014, 0.007, 0.014, 0.014, 0.024, 0.014, 0.008, 0.016, 0.017, 0.014, 0.016, 0.012, 0.019, 0.017, 0.012, 0.017, 0.016, 0.009, 0.017, 0.006, 0.023, 0.01, 0.008, 0.005, 0.019, 0.019, 0.022, 0.017, 0.016, 0.017, 0.007, 0.022, 0.019, 0.016, 0.012, 0.012, 0.018, 0.009, 0.007, 0.008, 0.017, 0.018, 0.009, 0.013, 0.024, 0.028, 0.006, 0.005, 0.008, 0.016, 0.009, 0.017, 0.016, 0.012, 0.013, 0.01, 0.018, 0.008, 0.016, 0.013, 0.024, 0.031, 0.028, 0.015, 0.013, 0.002, 0.019, 0.014, 0.013, 0.015, 0.017, 0.008, 0.019, 0.015, 0.007, 0.01, 0.016, 0.017, 0.015, 0.017, 0.008, 0.008, 0.015, 0.013, 0.007, 0.018, 0.009, 0.01, 0.019, 0.019, 0.021, 0.029, 0.011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:56:25] [0] \t\t #> Encoding 64 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 72.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1515.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:56:25] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:56:25] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:56:25] len(emb2pid) = 246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 133450.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:56:25] #> Saved optimized IVF to .ragatouille/colbert/indexes/feta_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index feta_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:56:31] #> Loading codec...\n",
      "[Jul 29, 14:56:31] #> Loading IVF...\n",
      "[Jul 29, 14:56:31] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 9776.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:56:31] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1100.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: Which season of Smallville performed the best during it's airing? , \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2029,  2161,  1997,  2235,  3077,  2864,  1996,  2190,\n",
      "         2076,  2009,  1005,  1055, 10499,  1029,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:56:31 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': \"Which season of Smallville performed the best during it's airing? \", 'response': 'The answer is: I need more information from the context to provide an accurate response. The given text does not contain any details about the performance of seasons of Smallville during their airings.', 'doc': 'Smallville', 'q_uid': 12844, 'answers': \"Over ten seasons the Smallville averaged, million viewers per episode, is with season two's highest rating of 6.3 million.\"}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:56:34] #> Note: Output directory .ragatouille/colbert/indexes/feta_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 14:56:34] #> Will delete 10 files already at .ragatouille/colbert/indexes/feta_vector_db in 20 seconds...\n",
      "[Jul 29, 14:56:57] [0] \t\t #> Encoding 68 passages..\n",
      "[Jul 29, 14:56:57] [0] \t\t avg_doclen_est = 3.838235378265381 \t len(local_sample) = 68\n",
      "[Jul 29, 14:56:57] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/feta_vector_db/plan.json ..\n",
      "Warning: number of training points (248) is less than the minimum recommended (2560)\n",
      "used 3 iterations (0.0011s) to cluster 248 items into 256 clusters\n",
      "[0.008, 0.005, 0.006, 0.003, 0.003, 0.01, 0.003, 0.004, 0.002, 0.001, 0.008, 0.001, 0.008, 0.005, 0.003, 0.012, 0.004, 0.008, 0.005, 0.006, 0.004, 0.007, 0.008, 0.008, 0.01, 0.005, 0.004, 0.012, 0.004, 0.005, 0.002, 0.006, 0.003, 0.004, 0.014, 0.007, 0.008, 0.006, 0.001, 0.002, 0.006, 0.005, 0.007, 0.017, 0.004, 0.004, 0.008, 0.009, 0.005, 0.007, 0.006, 0.002, 0.007, 0.002, 0.008, 0.007, 0.002, 0.01, 0.008, 0.003, 0.005, 0.003, 0.006, 0.011, 0.01, 0.008, 0.006, 0.005, 0.005, 0.011, 0.007, 0.008, 0.004, 0.002, 0.002, 0.001, 0.005, 0.011, 0.003, 0.006, 0.007, 0.006, 0.002, 0.009, 0.004, 0.005, 0.004, 0.004, 0.005, 0.006, 0.003, 0.005, 0.006, 0.01, 0.004, 0.006, 0.004, 0.009, 0.011, 0.006, 0.002, 0.002, 0.003, 0.006, 0.004, 0.005, 0.007, 0.007, 0.005, 0.013, 0.009, 0.001, 0.008, 0.009, 0.013, 0.007, 0.005, 0.004, 0.011, 0.006, 0.006, 0.005, 0.004, 0.003, 0.002, 0.007, 0.008, 0.007]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:56:57] [0] \t\t #> Encoding 68 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 57.87it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2016.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:56:57] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:56:57] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:56:57] len(emb2pid) = 261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 147027.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:56:57] #> Saved optimized IVF to .ragatouille/colbert/indexes/feta_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index feta_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:57:04] #> Loading codec...\n",
      "[Jul 29, 14:57:04] #> Loading IVF...\n",
      "[Jul 29, 14:57:04] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6615.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:57:04] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1685.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: In which film did Jennifer Jones star in 1995 and in which consequent film did she take on a role in 1956? , \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1999,  2029,  2143,  2106,  7673,  3557,  2732,  1999,\n",
      "         2786,  1998,  1999,  2029,  9530,  3366, 15417,  2143,  2106,  2016,\n",
      "         2202,  2006,  1037,  2535,  1999,  3838,  1029,   102,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:57:04 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'In which film did Jennifer Jones star in 1995 and in which consequent film did she take on a role in 1956? ', 'response': 'The answer is: In 1995, Jennifer Jones starred in Yentl and in 1956, she took on a role in Agnes of God.', 'doc': 'Jennifer Jones', 'q_uid': 19050, 'answers': 'Jennifer Jones starred in Good Morning, Miss Dove in 1955, followed by a role in The Man in the Gray Flannel Suit.'}\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Aaron Taylor-Johnson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Athletics at the 2016 Summer Olympics – Men's 400 metres.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Renewable energy in Germany.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of awards and nominations received by Nicki Minaj.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/LisaRaye McCoy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Teri Polo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hayden Panettiere.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Peter Sallis.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Tonight Show.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Spartan army.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Cricket World Cup awards.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/1916 Cumberland vs. Georgia Tech football game.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Victoria Justice.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Derek Theler.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/United States at the FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Femina Miss India.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Anna Faris.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mesut Özil.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Ashley Williams (actress).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lloyd's of London.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Chuck (TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jyotica Tangri.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Karyn White.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Group of Eight.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/T.J. Miller.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Paraguay at the FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Arthur (TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Bethany Joy Lenz.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Love & Hip Hop.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of highest-grossing Indian films in overseas markets.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Zachary Gordon.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/1972 Miami Dolphins season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Monica (singer).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Lion King (musical).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of Andhra Pradesh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Christa B. Allen.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/All India Institutes of Medical Sciences.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Sample-return mission.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Geography of Japan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Death Cab for Cutie.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Sarah Wayne Callies.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Josh Peck.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Total Drama All-Stars and Pahkitew Island.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Carly Chaikin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Six Flags Over Georgia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Gangnam Style.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hawthorn Football Club.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tears in Heaven.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Gary Holton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Victoria Hamilton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Speak Now.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/North Dakota State Bison football.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2014 Indian Super League season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of earthquakes in South Africa.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Elsa Pataky.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jaime Pressly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2016 Tour de France.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Skye McCole Bartusiak.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Better Call Saul episodes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/William Fichtner.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jennifer Landon.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2014 Tour de France.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of awards and nominations received by Bruno Mars.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of NASCAR drivers who have won in each of top three series.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Dylan Minnette.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Amy Jackson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of longest-serving mayors in the United States.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of FIFA World Cup winners.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Need You Now (Lady Antebellum song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/University of Miami.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Gavin MacLeod.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Karen David.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of Himachal Pradesh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lindsey Stirling.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Bentley Continental GT.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Charlie Hunnam.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Topher Grace.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Formula One driver records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Billy Elliot the Musical.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Premiership Rugby.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Speakers of the National Assembly of Guyana.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hawaii Five-0 (2010 TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/John Rhys-Davies.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Courtney Ford.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Claudia Wells.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Holy Roman Emperor.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Russell Wilson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/CSI: Miami.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tim Pigott-Smith.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Subaru Tribeca.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Religion in Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kurt Seyit ve Şura.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Khalid ibn al-Walid.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Qualified dividend.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Roberta Flack.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Maisie Williams.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mazda BT-50.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/You Belong with Me.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Joseph and the Amazing Technicolor Dreamcoat.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Ohio area codes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Wayne Brady.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Omaha, Nebraska.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of 2018 Indian Premier League personnel changes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Vivien Leigh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kathy Najimy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Haviland Morris.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tower Heist.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Rag'n'Bone Man.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Thomas Newman.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of longest-running U.S. primetime television series.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Katherine Helmond.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/John Bell (Scottish actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2004 World Series.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Legend of Korra.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Taissa Farmiga.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/NHL outdoor games.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2018 Indianapolis 500.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Local governance in Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Richard Ayoade.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Heather Tom.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kevin Peter Hall.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jeffrey Dean Morgan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Raid 2.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Safe & Sound (Taylor Swift song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Toyota manufacturing facilities.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lela Rochon.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jonathan Jackson (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Nicholle Tom.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Standard deviation.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Courteney Cox.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Will Yun Lee.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of number-one Billboard Christian Albums.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of German football champions.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Akkadian Empire.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Elinor Donahue.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Yankee Stadium.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of the longest-running West End shows.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kathryn Beaumont.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kokoda Track.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Larisa Oleynik.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of awards and nominations received by Michael Jackson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/American Ninja Warrior (season 9).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of governors of Bengal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Grace Kelly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Samsung Galaxy Note II.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Grade inflation.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Dave Bautista.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Oasis discography.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Long Day's Journey into Night.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/June Marlowe.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Reba (TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of UFC records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of awards and nominations received by Game of Thrones.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mike Birbiglia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mike & Molly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lucy Hale.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Thomas Fire.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Adrian Rawlins.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/We Are Never Ever Getting Back Together.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2018 Australian Grand Prix.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Major League Baseball progressive single-season home run leaders.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Perla Haney-Jardine.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Equal Employment Opportunity Commission.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jeffrey Donovan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Brett Favre.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Twenty One Pilots discography.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Fresh Prince of Bel-Air.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Rob Beckett.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Shailene Woodley.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Plitvice Lakes National Park.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Poseidon Adventure (1972 film).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Andra Day.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Robert Urich.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Momordica charantia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/René Auberjonois.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Social Security Wage Base.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Fluid ounce.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2016 Cleveland Browns season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Stadium Australia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Dennis Hopper.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Portugal. The Man.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of districts of Nepal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Colleen Ballinger.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Districts of Pakistan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Body mass index.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of West Bengal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Stanley Cup champions.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of career achievements by Wayne Gretzky.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Vancouver Grizzlies.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lily Collins.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Honda CBR600F.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Michael Clarke Duncan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/California State Assembly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lesley-Ann Brandt.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Ryder Cup records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/O'Shea Jackson Jr..pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/1990 AFL Grand Final.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Coins of the United States dollar.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Bianca Kajlich.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hilarie Burton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Oklahoma.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Foie gras.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Havana (Camila Cabello song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of best-selling albums in the United States.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Asa Butterfield.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/AirPort Time Capsule.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hannah John-Kamen.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Canadian islands by area.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jimi Jamison.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mischa Barton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Protectorate of Bohemia and Moravia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Game of the Year awards.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Adventures of Tintin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Married to the Mob.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hawaii.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Spartacus characters.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/South Armagh Sniper (1990–1997).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Purdue Boilermakers football.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Greta Garbo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/FIFA Club World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/London Calling (song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of Punjab (India).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Run the World (Girls).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of tallest buildings in India.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/I Look to You.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Uzo Aduba.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of longest films.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Crosby, Stills & Nash (album).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/John Harbaugh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Guardians of the Galaxy members.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Sri Lanka Test cricket records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Freddy Fender.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Merritt Patterson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/King of the Ring.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Best Thing I Never Had.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Shake It Off.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Scream & Shout.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Shirley Henderson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Prime Minister of Jamaica.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2018 Chicago Bears season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Elizabeth Mitchell.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kris Boyd.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Thomas F. Wilson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Peter Egan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Rose McGowan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/California Polytechnic State University.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jon Bon Jovi.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kelvin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Matthew Goode.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Renault Clio.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Ann B. Davis.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mercury Grand Marquis.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Koenigsegg Agera.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Arnold Schwarzenegger.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Rashida Jones.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mo Farah.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/South America.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jennifer Hudson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Michael Bublé discography.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Total Drama: Revenge of the Island.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Visa policy of China.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Bryan Robson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/1986 FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Joanna Moore.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Deepika Chikhalia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tom Hughes (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Devin Hester.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/William Moseley (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Ku Hye-sun.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tom Felton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Big Brovaz.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Miami Dolphins broadcasters.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/David Oyelowo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jacob Rees-Mogg.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Eleanor Tomlinson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Wonder Woman enemies.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Miles Heizer.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Yvonne Strahovski.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Nora Arnezeder.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Seal (musician).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Batman: Death of the Family.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/115th United States Congress.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Premier League clubs.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Grayson Russell.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Earl Hindman.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of NBA franchise post-season droughts.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of highest-grossing Indian films.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2017–18 FC Barcelona season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Gasoline gallon equivalent.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lose Yourself.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Deuterocanonical books.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Dheeraj Dhoopar.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jodie Whittaker.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Luke Arnold.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/My Mad Fat Diary.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Faerie Tale Theatre episodes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lionel Messi.pdf\n",
      "=== Start feta on falcon-e-3B ===\n",
      "2025-07-29 14:57:05 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:57:05,549 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:57:07 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:57:09] #> Note: Output directory .ragatouille/colbert/indexes/feta_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 14:57:09] #> Will delete 10 files already at .ragatouille/colbert/indexes/feta_vector_db in 20 seconds...\n",
      "[Jul 29, 14:57:32] [0] \t\t #> Encoding 64 passages..\n",
      "[Jul 29, 14:57:32] [0] \t\t avg_doclen_est = 3.84375 \t len(local_sample) = 64\n",
      "[Jul 29, 14:57:32] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/feta_vector_db/plan.json ..\n",
      "Warning: number of training points (234) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0009s) to cluster 234 items into 128 clusters\n",
      "[0.01, 0.013, 0.006, 0.018, 0.005, 0.013, 0.007, 0.007, 0.016, 0.007, 0.011, 0.011, 0.022, 0.004, 0.009, 0.017, 0.005, 0.011, 0.01, 0.027, 0.009, 0.014, 0.007, 0.015, 0.018, 0.008, 0.017, 0.008, 0.01, 0.01, 0.014, 0.011, 0.013, 0.005, 0.009, 0.014, 0.007, 0.014, 0.014, 0.024, 0.014, 0.008, 0.016, 0.017, 0.014, 0.016, 0.012, 0.019, 0.017, 0.012, 0.017, 0.016, 0.009, 0.017, 0.006, 0.023, 0.01, 0.008, 0.005, 0.019, 0.019, 0.022, 0.017, 0.016, 0.017, 0.007, 0.022, 0.019, 0.016, 0.012, 0.012, 0.018, 0.009, 0.007, 0.008, 0.017, 0.018, 0.009, 0.013, 0.024, 0.028, 0.006, 0.005, 0.008, 0.016, 0.009, 0.017, 0.016, 0.012, 0.013, 0.01, 0.018, 0.008, 0.016, 0.013, 0.024, 0.031, 0.028, 0.015, 0.013, 0.002, 0.019, 0.014, 0.013, 0.015, 0.017, 0.008, 0.019, 0.015, 0.007, 0.01, 0.016, 0.017, 0.015, 0.017, 0.008, 0.008, 0.015, 0.013, 0.007, 0.018, 0.009, 0.01, 0.019, 0.019, 0.021, 0.029, 0.011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:57:32] [0] \t\t #> Encoding 64 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 78.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2471.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:57:32] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:57:32] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:57:32] len(emb2pid) = 246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 166730.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:57:32] #> Saved optimized IVF to .ragatouille/colbert/indexes/feta_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index feta_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:57:38] #> Loading codec...\n",
      "[Jul 29, 14:57:38] #> Loading IVF...\n",
      "[Jul 29, 14:57:38] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6159.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:57:38] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1947.22it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: Which season of Smallville performed the best during it's airing? , \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2029,  2161,  1997,  2235,  3077,  2864,  1996,  2190,\n",
      "         2076,  2009,  1005,  1055, 10499,  1029,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:57:38 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': \"Which season of Smallville performed the best during it's airing? \", 'response': 'The answer is: The second season of Smallville performed the best during its airing.', 'doc': 'Smallville', 'q_uid': 12844, 'answers': \"Over ten seasons the Smallville averaged, million viewers per episode, is with season two's highest rating of 6.3 million.\"}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:57:41] #> Note: Output directory .ragatouille/colbert/indexes/feta_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 14:57:41] #> Will delete 10 files already at .ragatouille/colbert/indexes/feta_vector_db in 20 seconds...\n",
      "[Jul 29, 14:58:04] [0] \t\t #> Encoding 68 passages..\n",
      "[Jul 29, 14:58:04] [0] \t\t avg_doclen_est = 3.838235378265381 \t len(local_sample) = 68\n",
      "[Jul 29, 14:58:04] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/feta_vector_db/plan.json ..\n",
      "Warning: number of training points (248) is less than the minimum recommended (2560)\n",
      "used 3 iterations (0.0011s) to cluster 248 items into 256 clusters\n",
      "[0.008, 0.005, 0.006, 0.003, 0.003, 0.01, 0.003, 0.004, 0.002, 0.001, 0.008, 0.001, 0.008, 0.005, 0.003, 0.012, 0.004, 0.008, 0.005, 0.006, 0.004, 0.007, 0.008, 0.008, 0.01, 0.005, 0.004, 0.012, 0.004, 0.005, 0.002, 0.006, 0.003, 0.004, 0.014, 0.007, 0.008, 0.006, 0.001, 0.002, 0.006, 0.005, 0.007, 0.017, 0.004, 0.004, 0.008, 0.009, 0.005, 0.007, 0.006, 0.002, 0.007, 0.002, 0.008, 0.007, 0.002, 0.01, 0.008, 0.003, 0.005, 0.003, 0.006, 0.011, 0.01, 0.008, 0.006, 0.005, 0.005, 0.011, 0.007, 0.008, 0.004, 0.002, 0.002, 0.001, 0.005, 0.011, 0.003, 0.006, 0.007, 0.006, 0.002, 0.009, 0.004, 0.005, 0.004, 0.004, 0.005, 0.006, 0.003, 0.005, 0.006, 0.01, 0.004, 0.006, 0.004, 0.009, 0.011, 0.006, 0.002, 0.002, 0.003, 0.006, 0.004, 0.005, 0.007, 0.007, 0.005, 0.013, 0.009, 0.001, 0.008, 0.009, 0.013, 0.007, 0.005, 0.004, 0.011, 0.006, 0.006, 0.005, 0.004, 0.003, 0.002, 0.007, 0.008, 0.007]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:58:04] [0] \t\t #> Encoding 68 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 57.88it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1731.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:58:04] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:58:04] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:58:04] len(emb2pid) = 261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 148368.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:58:04] #> Saved optimized IVF to .ragatouille/colbert/indexes/feta_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index feta_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:58:10] #> Loading codec...\n",
      "[Jul 29, 14:58:10] #> Loading IVF...\n",
      "[Jul 29, 14:58:10] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6502.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:58:10] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1733.90it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: In which film did Jennifer Jones star in 1995 and in which consequent film did she take on a role in 1956? , \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1999,  2029,  2143,  2106,  7673,  3557,  2732,  1999,\n",
      "         2786,  1998,  1999,  2029,  9530,  3366, 15417,  2143,  2106,  2016,\n",
      "         2202,  2006,  1037,  2535,  1999,  3838,  1029,   102,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:58:10 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'In which film did Jennifer Jones star in 1995 and in which consequent film did she take on a role in 1956? ', 'response': 'The answer is: In 1995, Jennifer Jones starred in the film The Wedding Singer. She took on a role in the 1956 film The Woman in White.', 'doc': 'Jennifer Jones', 'q_uid': 19050, 'answers': 'Jennifer Jones starred in Good Morning, Miss Dove in 1955, followed by a role in The Man in the Gray Flannel Suit.'}\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Aaron Taylor-Johnson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Athletics at the 2016 Summer Olympics – Men's 400 metres.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Renewable energy in Germany.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of awards and nominations received by Nicki Minaj.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/LisaRaye McCoy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Teri Polo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hayden Panettiere.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Peter Sallis.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Tonight Show.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Spartan army.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Cricket World Cup awards.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/1916 Cumberland vs. Georgia Tech football game.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Victoria Justice.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Derek Theler.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/United States at the FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Femina Miss India.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Anna Faris.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mesut Özil.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Ashley Williams (actress).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lloyd's of London.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Chuck (TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jyotica Tangri.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Karyn White.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Group of Eight.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/T.J. Miller.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Paraguay at the FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Arthur (TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Bethany Joy Lenz.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Love & Hip Hop.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of highest-grossing Indian films in overseas markets.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Zachary Gordon.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/1972 Miami Dolphins season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Monica (singer).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Lion King (musical).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of Andhra Pradesh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Christa B. Allen.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/All India Institutes of Medical Sciences.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Sample-return mission.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Geography of Japan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Death Cab for Cutie.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Sarah Wayne Callies.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Josh Peck.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Total Drama All-Stars and Pahkitew Island.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Carly Chaikin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Six Flags Over Georgia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Gangnam Style.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hawthorn Football Club.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tears in Heaven.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Gary Holton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Victoria Hamilton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Speak Now.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/North Dakota State Bison football.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2014 Indian Super League season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of earthquakes in South Africa.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Elsa Pataky.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jaime Pressly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2016 Tour de France.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Skye McCole Bartusiak.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Better Call Saul episodes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/William Fichtner.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jennifer Landon.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2014 Tour de France.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of awards and nominations received by Bruno Mars.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of NASCAR drivers who have won in each of top three series.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Dylan Minnette.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Amy Jackson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of longest-serving mayors in the United States.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of FIFA World Cup winners.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Need You Now (Lady Antebellum song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/University of Miami.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Gavin MacLeod.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Karen David.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of Himachal Pradesh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lindsey Stirling.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Bentley Continental GT.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Charlie Hunnam.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Topher Grace.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Formula One driver records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Billy Elliot the Musical.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Premiership Rugby.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Speakers of the National Assembly of Guyana.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hawaii Five-0 (2010 TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/John Rhys-Davies.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Courtney Ford.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Claudia Wells.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Holy Roman Emperor.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Russell Wilson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/CSI: Miami.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tim Pigott-Smith.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Subaru Tribeca.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Religion in Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kurt Seyit ve Şura.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Khalid ibn al-Walid.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Qualified dividend.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Roberta Flack.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Maisie Williams.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mazda BT-50.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/You Belong with Me.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Joseph and the Amazing Technicolor Dreamcoat.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Ohio area codes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Wayne Brady.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Omaha, Nebraska.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of 2018 Indian Premier League personnel changes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Vivien Leigh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kathy Najimy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Haviland Morris.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tower Heist.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Rag'n'Bone Man.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Thomas Newman.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of longest-running U.S. primetime television series.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Katherine Helmond.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/John Bell (Scottish actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2004 World Series.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Legend of Korra.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Taissa Farmiga.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/NHL outdoor games.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2018 Indianapolis 500.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Local governance in Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Richard Ayoade.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Heather Tom.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kevin Peter Hall.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jeffrey Dean Morgan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Raid 2.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Safe & Sound (Taylor Swift song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Toyota manufacturing facilities.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lela Rochon.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jonathan Jackson (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Nicholle Tom.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Standard deviation.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Courteney Cox.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Will Yun Lee.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of number-one Billboard Christian Albums.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of German football champions.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Akkadian Empire.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Elinor Donahue.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Yankee Stadium.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of the longest-running West End shows.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kathryn Beaumont.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kokoda Track.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Larisa Oleynik.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of awards and nominations received by Michael Jackson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/American Ninja Warrior (season 9).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of governors of Bengal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Grace Kelly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Samsung Galaxy Note II.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Grade inflation.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Dave Bautista.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Oasis discography.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Long Day's Journey into Night.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/June Marlowe.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Reba (TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of UFC records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of awards and nominations received by Game of Thrones.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mike Birbiglia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mike & Molly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lucy Hale.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Thomas Fire.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Adrian Rawlins.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/We Are Never Ever Getting Back Together.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2018 Australian Grand Prix.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Major League Baseball progressive single-season home run leaders.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Perla Haney-Jardine.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Equal Employment Opportunity Commission.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jeffrey Donovan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Brett Favre.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Twenty One Pilots discography.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Fresh Prince of Bel-Air.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Rob Beckett.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Shailene Woodley.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Plitvice Lakes National Park.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Poseidon Adventure (1972 film).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Andra Day.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Robert Urich.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Momordica charantia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/René Auberjonois.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Social Security Wage Base.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Fluid ounce.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2016 Cleveland Browns season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Stadium Australia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Dennis Hopper.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Portugal. The Man.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of districts of Nepal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Colleen Ballinger.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Districts of Pakistan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Body mass index.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of West Bengal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Stanley Cup champions.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of career achievements by Wayne Gretzky.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Vancouver Grizzlies.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lily Collins.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Honda CBR600F.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Michael Clarke Duncan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/California State Assembly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lesley-Ann Brandt.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Ryder Cup records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/O'Shea Jackson Jr..pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/1990 AFL Grand Final.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Coins of the United States dollar.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Bianca Kajlich.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hilarie Burton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Oklahoma.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Foie gras.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Havana (Camila Cabello song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of best-selling albums in the United States.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Asa Butterfield.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/AirPort Time Capsule.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hannah John-Kamen.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Canadian islands by area.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jimi Jamison.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mischa Barton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Protectorate of Bohemia and Moravia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Game of the Year awards.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/The Adventures of Tintin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Married to the Mob.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Hawaii.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Spartacus characters.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/South Armagh Sniper (1990–1997).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Purdue Boilermakers football.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Greta Garbo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/FIFA Club World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/London Calling (song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Chief Ministers of Punjab (India).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Run the World (Girls).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of tallest buildings in India.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/I Look to You.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Uzo Aduba.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of longest films.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Crosby, Stills & Nash (album).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/John Harbaugh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Guardians of the Galaxy members.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Sri Lanka Test cricket records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Freddy Fender.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Merritt Patterson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/King of the Ring.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Best Thing I Never Had.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Shake It Off.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Scream & Shout.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Shirley Henderson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Prime Minister of Jamaica.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2018 Chicago Bears season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Elizabeth Mitchell.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kris Boyd.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Thomas F. Wilson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Peter Egan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Rose McGowan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/California Polytechnic State University.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jon Bon Jovi.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Kelvin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Matthew Goode.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Renault Clio.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Ann B. Davis.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mercury Grand Marquis.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Koenigsegg Agera.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Arnold Schwarzenegger.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Rashida Jones.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Mo Farah.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/South America.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jennifer Hudson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Michael Bublé discography.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Total Drama: Revenge of the Island.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Visa policy of China.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Bryan Robson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/1986 FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Joanna Moore.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Deepika Chikhalia.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tom Hughes (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Devin Hester.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/William Moseley (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Ku Hye-sun.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Tom Felton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Big Brovaz.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Miami Dolphins broadcasters.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/David Oyelowo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jacob Rees-Mogg.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Eleanor Tomlinson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Wonder Woman enemies.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Miles Heizer.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Yvonne Strahovski.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Nora Arnezeder.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Seal (musician).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Batman: Death of the Family.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/115th United States Congress.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Premier League clubs.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Grayson Russell.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Earl Hindman.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of NBA franchise post-season droughts.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of highest-grossing Indian films.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/2017–18 FC Barcelona season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Gasoline gallon equivalent.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lose Yourself.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Deuterocanonical books.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Dheeraj Dhoopar.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Jodie Whittaker.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Luke Arnold.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/My Mad Fat Diary.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/List of Faerie Tale Theatre episodes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_feta_docs/pdfs/Lionel Messi.pdf\n",
      "=== Finish feta ===\n",
      "\n",
      "=== Start tat on meno-tiny ===\n",
      "2025-07-29 14:58:14 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:58:14,766 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:58:18 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:58:20] #> Creating directory .ragatouille/colbert/indexes/tat_vector_db \n",
      "\n",
      "\n",
      "[Jul 29, 14:58:23] [0] \t\t #> Encoding 67 passages..\n",
      "[Jul 29, 14:58:23] [0] \t\t avg_doclen_est = 3.8358209133148193 \t len(local_sample) = 67\n",
      "[Jul 29, 14:58:23] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/tat_vector_db/plan.json ..\n",
      "Warning: number of training points (245) is less than the minimum recommended (2560)\n",
      "used 3 iterations (0.0014s) to cluster 245 items into 256 clusters\n",
      "[0.012, 0.012, 0.011, 0.018, 0.015, 0.014, 0.013, 0.009, 0.019, 0.014, 0.005, 0.017, 0.012, 0.012, 0.005, 0.007, 0.015, 0.007, 0.005, 0.022, 0.014, 0.005, 0.018, 0.004, 0.005, 0.013, 0.013, 0.011, 0.008, 0.021, 0.008, 0.017, 0.009, 0.015, 0.013, 0.03, 0.016, 0.009, 0.021, 0.012, 0.013, 0.01, 0.012, 0.009, 0.017, 0.02, 0.014, 0.018, 0.012, 0.014, 0.008, 0.005, 0.013, 0.019, 0.008, 0.033, 0.009, 0.02, 0.01, 0.015, 0.013, 0.004, 0.011, 0.014, 0.006, 0.012, 0.031, 0.005, 0.009, 0.012, 0.012, 0.024, 0.009, 0.007, 0.009, 0.007, 0.019, 0.021, 0.017, 0.016, 0.037, 0.019, 0.018, 0.012, 0.015, 0.005, 0.026, 0.003, 0.01, 0.008, 0.015, 0.005, 0.011, 0.018, 0.008, 0.016, 0.036, 0.015, 0.013, 0.008, 0.015, 0.014, 0.01, 0.013, 0.009, 0.009, 0.017, 0.006, 0.017, 0.008, 0.01, 0.016, 0.004, 0.012, 0.011, 0.01, 0.009, 0.005, 0.011, 0.004, 0.015, 0.014, 0.01, 0.003, 0.015, 0.017, 0.016, 0.007]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:58:23] [0] \t\t #> Encoding 67 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 57.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2213.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:58:23] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:58:23] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:58:23] len(emb2pid) = 257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 200100.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:58:23] #> Saved optimized IVF to .ragatouille/colbert/indexes/tat_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:58:29] #> Loading codec...\n",
      "[Jul 29, 14:58:29] #> Loading IVF...\n",
      "[Jul 29, 14:58:29] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7307.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:58:29] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1452.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the difference between  Richard E. Belluzzo's total compensation as compared to Laura Black?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  4489,  2090,  2957,  1041,  1012,\n",
      "         4330, 17040,  6844,  1005,  1055,  2561,  9430,  2004,  4102,  2000,\n",
      "         6874,  2304,  1029,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:58:29 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': \"What is the difference between  Richard E. Belluzzo's total compensation as compared to Laura Black?\", 'response': \"Laura Black's total compensation is 100,000 less than Richard E. Belluzzo's total compensation.\", 'doc': 'viavi-solutions-inc_2019', 'q_uid': 'f1b63dd3002720ebbffa8f36d852d351', 'answers': {'answer': 92500, 'answer_type': 'arithmetic', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:58:35] #> Loading codec...\n",
      "[Jul 29, 14:58:35] #> Loading IVF...\n",
      "[Jul 29, 14:58:35] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11650.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:58:35] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1258.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: How much did Donald Colvin earn in cash?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2129, 2172, 2106, 6221, 8902, 6371, 7796, 1999, 5356, 1029,\n",
      "         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:58:35 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'How much did Donald Colvin earn in cash?', 'response': 'Donald Colvin earned $100,000 in cash.', 'doc': 'viavi-solutions-inc_2019', 'q_uid': 'd1a4ba4e1af05c60efa468f953a4f8ca', 'answers': {'answer': ['97,500'], 'answer_type': 'span', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:58:41] #> Loading codec...\n",
      "[Jul 29, 14:58:41] #> Loading IVF...\n",
      "[Jul 29, 14:58:41] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5433.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:58:41] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1204.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the percentage difference of the total compensation between Timothy Campos and Tor Braham?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  7017,  4489,  1997,  1996,  2561,\n",
      "         9430,  2090, 10805, 26925,  1998, 17153, 11655,  3511,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:58:41 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'What is the percentage difference of the total compensation between Timothy Campos and Tor Braham?', 'response': 'The percentage difference of the total compensation between Timothy Campos and Tor Braham is 100.00.', 'doc': 'viavi-solutions-inc_2019', 'q_uid': '5cff0439063c6a496073ce4b55591d0b', 'answers': {'answer': 4.07, 'answer_type': 'arithmetic', 'scale': 'percent'}}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:58:44] #> Note: Output directory .ragatouille/colbert/indexes/tat_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 14:58:44] #> Will delete 10 files already at .ragatouille/colbert/indexes/tat_vector_db in 20 seconds...\n",
      "[Jul 29, 14:59:07] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 14:59:07] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 14:59:07] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/tat_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0009s) to cluster 201 items into 128 clusters\n",
      "[0.008, 0.004, 0.004, 0.006, 0.004, 0.006, 0.005, 0.005, 0.015, 0.01, 0.005, 0.003, 0.005, 0.006, 0.011, 0.013, 0.008, 0.007, 0.008, 0.003, 0.006, 0.013, 0.007, 0.005, 0.004, 0.009, 0.006, 0.007, 0.004, 0.002, 0.006, 0.009, 0.008, 0.016, 0.006, 0.007, 0.006, 0.015, 0.004, 0.008, 0.005, 0.004, 0.008, 0.012, 0.01, 0.003, 0.005, 0.009, 0.009, 0.006, 0.002, 0.006, 0.007, 0.007, 0.011, 0.013, 0.006, 0.004, 0.005, 0.003, 0.01, 0.004, 0.008, 0.014, 0.006, 0.004, 0.006, 0.01, 0.009, 0.006, 0.006, 0.003, 0.006, 0.007, 0.005, 0.011, 0.005, 0.008, 0.009, 0.01, 0.009, 0.009, 0.013, 0.004, 0.011, 0.008, 0.009, 0.008, 0.007, 0.007, 0.004, 0.005, 0.012, 0.009, 0.008, 0.009, 0.009, 0.014, 0.009, 0.008, 0.007, 0.012, 0.011, 0.005, 0.007, 0.006, 0.009, 0.006, 0.011, 0.005, 0.004, 0.006, 0.007, 0.013, 0.008, 0.01, 0.008, 0.01, 0.003, 0.007, 0.006, 0.007, 0.004, 0.007, 0.012, 0.013, 0.005, 0.01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:59:07] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 79.05it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2983.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:59:07] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:59:07] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:59:07] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 164734.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:59:07] #> Saved optimized IVF to .ragatouille/colbert/indexes/tat_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:59:13] #> Loading codec...\n",
      "[Jul 29, 14:59:13] #> Loading IVF...\n",
      "[Jul 29, 14:59:13] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7256.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:59:13] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1790.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What does cash and cash equivalents consist of?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2515, 5356, 1998, 5356, 5662, 2015, 8676, 1997, 1029,\n",
      "         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:59:13 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'What does cash and cash equivalents consist of?', 'response': 'Cash and cash equivalents consist of cash and cash equivalents.', 'doc': 'inpixon_2019', 'q_uid': 'c97f3158996e35cf911eec06d020badc', 'answers': {'answer': ['cash, checking accounts, money market accounts and temporary investments with maturities of three months or less when purchased.'], 'answer_type': 'span', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:59:19] #> Loading codec...\n",
      "[Jul 29, 14:59:19] #> Loading IVF...\n",
      "[Jul 29, 14:59:19] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5047.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:59:19] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1709.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What was the average Professional and legal fees for 2018 and 2019?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1996,  2779,  2658,  1998,  3423,  9883,\n",
      "         2005,  2760,  1998, 10476,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:59:19 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'What was the average Professional and legal fees for 2018 and 2019?', 'response': 'The average Professional and legal fees for 2018 and 2019 was $100,000.', 'doc': 'inpixon_2019', 'q_uid': 'd7d2b6427fb0f566a3ac2e90d842dd06', 'answers': {'answer': 393.5, 'answer_type': 'arithmetic', 'scale': 'thousand'}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:59:25] #> Loading codec...\n",
      "[Jul 29, 14:59:25] #> Loading IVF...\n",
      "[Jul 29, 14:59:25] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5065.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:59:25] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1495.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: How does the company account for options granted to employees?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2129, 2515, 1996, 2194, 4070, 2005, 7047, 4379, 2000, 5126,\n",
      "        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:59:25 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'How does the company account for options granted to employees?', 'response': 'The company uses the Black-Scholes model to account for options granted to employees.', 'doc': 'inpixon_2019', 'q_uid': 'fde5598a4f22f1775d27e488f367cdb7', 'answers': {'answer': ['by measuring the cost of services received in exchange for the award of equity instruments based upon the fair value of the award on the date of grant.'], 'answer_type': 'span', 'scale': ''}}\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/national-storage-reit_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cincinnati-bell-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/greencore-group-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/jabil-circuit-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cornerstone-ondemand-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/ichor-holdings-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/everbridge-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/network-1-technologies_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/xperi-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cts-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/Intu-Properties_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/siemens-ag_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/carpenter-technology-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/united-micro-electronics-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/on-semiconductor_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/consolidated-communications-holdings-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/Nextdc-Ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/black-knight-financial-services-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/brainstorm-cell-therapeutics_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/spirent-communications-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/proofpoint_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nordic-american-tankers-limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/par-technology-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/conagra-brands-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/stmicroelectronics_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/singapore-telecommunications-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/extreme-networks-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/logitech-international-sa_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cogent-communications-group-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/bce-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/westell-technologies-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/acura-pharmaceuticals-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/support-com_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nanthealth-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/travelzoo_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/square-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/allscripts-healthcare-solutions-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/agilysys-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/maxlinear-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/parkervision_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cisco-systems-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/methode-electronics-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/lam-research-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/international-business-machines-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/guidewire-software-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/globalscape-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/opentext-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/tyson-foods-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/csg-systems-international-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/unilever-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/mimecast-limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/mantech-international-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/netapp-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/godaddy-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/Woolworths-Limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/acacia-communications-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/freshpet-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/sykes-enterprises-incorporated_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/spirax-sarco-engineering-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/teradyne-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/resonant-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/taiwan-semiconductor-manufacturing-co-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/amcon-distributing-company_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/sealed-air-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/adtran-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/clearfield-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/quicklogic-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/frequency-electronics-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/leidos-holdings_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/te-connectivity-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/jack-henry-associates-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/mitek-systems_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/autodesk-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/chefs-wharehouse_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/protagenic-therapeutics-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/micron-technology-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/coherent-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/intel-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/avx-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nokia-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/zayo-group-holdings_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/ricebran-technologies_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/microchip-technology-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/sunpower-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/csp-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/tiger-brands-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cogeco-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/Auto-Trader_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/virnetx-holding-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/calamp-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/torm_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/first-solar-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/loral-space-communications-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/a10-networks-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/sunworks-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/fitbit-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/marks-and-spencer-group-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/kemet-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/marin-software-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/adobe-systems-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/altium-limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/immersion_2019.pdf\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 14:59:28] #> Note: Output directory .ragatouille/colbert/indexes/tat_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 14:59:28] #> Will delete 10 files already at .ragatouille/colbert/indexes/tat_vector_db in 20 seconds...\n",
      "[Jul 29, 14:59:50] [0] \t\t #> Encoding 78 passages..\n",
      "[Jul 29, 14:59:50] [0] \t\t avg_doclen_est = 3.846153736114502 \t len(local_sample) = 78\n",
      "[Jul 29, 14:59:50] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/tat_vector_db/plan.json ..\n",
      "Warning: number of training points (285) is less than the minimum recommended (2560)\n",
      "used 3 iterations (0.0071s) to cluster 285 items into 256 clusters\n",
      "[0.005, 0.006, 0.01, 0.018, 0.008, 0.007, 0.009, 0.012, 0.002, 0.005, 0.007, 0.01, 0.001, 0.018, 0.014, 0.011, 0.009, 0.009, 0.005, 0.016, 0.007, 0.003, 0.006, 0.013, 0.002, 0.007, 0.02, 0.004, 0.005, 0.021, 0.009, 0.007, 0.013, 0.005, 0.009, 0.011, 0.007, 0.015, 0.014, 0.008, 0.003, 0.013, 0.016, 0.01, 0.004, 0.007, 0.016, 0.014, 0.01, 0.014, 0.013, 0.003, 0.01, 0.016, 0.004, 0.011, 0.004, 0.006, 0.01, 0.009, 0.006, 0.006, 0.01, 0.009, 0.006, 0.005, 0.011, 0.013, 0.009, 0.014, 0.005, 0.015, 0.014, 0.009, 0.003, 0.002, 0.009, 0.008, 0.006, 0.011, 0.011, 0.006, 0.009, 0.01, 0.004, 0.005, 0.019, 0.005, 0.007, 0.012, 0.014, 0.018, 0.004, 0.018, 0.005, 0.005, 0.015, 0.012, 0.023, 0.004, 0.016, 0.003, 0.007, 0.006, 0.005, 0.001, 0.002, 0.014, 0.005, 0.021, 0.006, 0.012, 0.019, 0.008, 0.005, 0.006, 0.006, 0.008, 0.007, 0.003, 0.008, 0.008, 0.008, 0.005, 0.005, 0.007, 0.005, 0.003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:59:50] [0] \t\t #> Encoding 78 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 55.74it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1915.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:59:50] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 14:59:50] #> Building the emb2pid mapping..\n",
      "[Jul 29, 14:59:50] len(emb2pid) = 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 177009.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:59:50] #> Saved optimized IVF to .ragatouille/colbert/indexes/tat_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 14:59:56] #> Loading codec...\n",
      "[Jul 29, 14:59:56] #> Loading IVF...\n",
      "[Jul 29, 14:59:56] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4999.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 14:59:56] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1179.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the average Net income for Years Ended December 31, 2018 to 2019?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2779,  5658,  3318,  2005,  2086,\n",
      "         3092,  2285,  2861,  1010,  2760,  2000, 10476,  1029,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 14:59:56 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'What is the average Net income for Years Ended December 31, 2018 to 2019?', 'response': 'The average Net income for Years Ended December 31, 2018 to 2019 is 100.00.', 'doc': 'overseas-shipholding-group-inc_2019', 'q_uid': 'ed78c51011874fe47d3910ab9794cce6', 'answers': {'answer': 11082, 'answer_type': 'arithmetic', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:00:04] #> Loading codec...\n",
      "[Jul 29, 15:00:04] #> Loading IVF...\n",
      "[Jul 29, 15:00:04] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7884.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:00:04] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1804.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the average Interest before impact of interest rate caps for Years Ended December 31, 2018 to 2019?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2779,  3037,  2077,  4254,  1997,\n",
      "         3037,  3446,  9700,  2005,  2086,  3092,  2285,  2861,  1010,  2760,\n",
      "         2000, 10476,  1029,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:00:04 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'What is the average Interest before impact of interest rate caps for Years Ended December 31, 2018 to 2019?', 'response': 'The average Interest before impact of interest rate caps for Years Ended December 31, 2018 to 2019 is 0.', 'doc': 'overseas-shipholding-group-inc_2019', 'q_uid': '69977fcc3bdeb9ae684b21997c00ddab', 'answers': {'answer': 28171, 'answer_type': 'arithmetic', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:00:14] #> Loading codec...\n",
      "[Jul 29, 15:00:14] #> Loading IVF...\n",
      "[Jul 29, 15:00:14] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6355.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:00:14] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1184.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: In which year was Operating Leases greater than 100,000?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1999,  2029,  2095,  2001,  4082, 29597,  3618,  2084,\n",
      "         2531,  1010,  2199,  1029,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:00:14 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'In which year was Operating Leases greater than 100,000?', 'response': '2009', 'doc': 'overseas-shipholding-group-inc_2019', 'q_uid': 'ccc7a9080e0fea2e3181976dc634e30f', 'answers': {'answer': ['2022'], 'answer_type': 'span', 'scale': ''}}\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/telkonet-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/aci-worldwide-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/hc2-holdings-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/netgear-inc_2019.pdf\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:00:17] #> Note: Output directory .ragatouille/colbert/indexes/tat_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:00:17] #> Will delete 10 files already at .ragatouille/colbert/indexes/tat_vector_db in 20 seconds...\n",
      "[Jul 29, 15:00:40] [0] \t\t #> Encoding 65 passages..\n",
      "[Jul 29, 15:00:40] [0] \t\t avg_doclen_est = 3.8307693004608154 \t len(local_sample) = 65\n",
      "[Jul 29, 15:00:40] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/tat_vector_db/plan.json ..\n",
      "Warning: number of training points (237) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.001s) to cluster 237 items into 128 clusters\n",
      "[0.014, 0.004, 0.006, 0.006, 0.008, 0.008, 0.007, 0.008, 0.004, 0.009, 0.008, 0.012, 0.006, 0.016, 0.005, 0.007, 0.022, 0.01, 0.009, 0.015, 0.01, 0.01, 0.006, 0.01, 0.007, 0.012, 0.021, 0.005, 0.009, 0.009, 0.013, 0.004, 0.016, 0.008, 0.006, 0.014, 0.01, 0.007, 0.02, 0.014, 0.006, 0.012, 0.006, 0.009, 0.008, 0.005, 0.008, 0.013, 0.011, 0.009, 0.004, 0.011, 0.013, 0.013, 0.007, 0.011, 0.008, 0.01, 0.006, 0.006, 0.008, 0.009, 0.005, 0.013, 0.004, 0.009, 0.01, 0.011, 0.006, 0.019, 0.009, 0.015, 0.007, 0.005, 0.006, 0.013, 0.009, 0.015, 0.016, 0.013, 0.016, 0.013, 0.005, 0.011, 0.009, 0.009, 0.013, 0.008, 0.007, 0.009, 0.01, 0.008, 0.01, 0.01, 0.01, 0.008, 0.012, 0.006, 0.016, 0.006, 0.01, 0.009, 0.006, 0.005, 0.011, 0.007, 0.013, 0.008, 0.008, 0.019, 0.01, 0.007, 0.012, 0.016, 0.011, 0.013, 0.009, 0.008, 0.006, 0.007, 0.005, 0.004, 0.013, 0.007, 0.005, 0.006, 0.007, 0.013]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:00:40] [0] \t\t #> Encoding 65 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 59.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2434.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:00:40] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:00:40] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:00:40] len(emb2pid) = 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 142708.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:00:40] #> Saved optimized IVF to .ragatouille/colbert/indexes/tat_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:00:46] #> Loading codec...\n",
      "[Jul 29, 15:00:46] #> Loading IVF...\n",
      "[Jul 29, 15:00:46] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6700.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:00:46] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1626.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the symbol of the company's common stock that is listed on the Nasdaq Global Market?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  6454,  1997,  1996,  2194,  1005,\n",
      "         1055,  2691,  4518,  2008,  2003,  3205,  2006,  1996, 17235,  2850,\n",
      "         4160,  3795,  3006,  1029,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:00:46 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': \"What is the symbol of the company's common stock that is listed on the Nasdaq Global Market?\", 'response': 'The answer is: Nasdaq.', 'doc': 'lifeway-foods-inc_2019', 'q_uid': '871af62021e2bd9a6ff15f9b1ba26d79', 'answers': {'answer': ['LWAY'], 'answer_type': 'span', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:00:51] #> Loading codec...\n",
      "[Jul 29, 15:00:51] #> Loading IVF...\n",
      "[Jul 29, 15:00:51] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5675.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:00:51] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1663.09it/s]\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the change in the value of brand names between 2018 and 2019?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2689,  1999,  1996,  3643,  1997,\n",
      "         4435,  3415,  2090,  2760,  1998, 10476,  1029,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:00:51 CallLLM\n",
      "{'model': 'meno-tiny', 'question': 'What is the change in the value of brand names between 2018 and 2019?', 'response': 'There is no change in the value of brand names between 2018 and 2019.', 'doc': 'lifeway-foods-inc_2019', 'q_uid': 'ec84e524463dfd906ae9c37d739c610f', 'answers': {'answer': 0, 'answer_type': 'arithmetic', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:00:58] #> Loading codec...\n",
      "[Jul 29, 15:00:58] #> Loading IVF...\n",
      "[Jul 29, 15:00:58] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6523.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:00:58] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1628.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What was the low sale price per share for each quarters in 2018 in chronological order?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1996,  2659,  5096,  3976,  2566,  3745,\n",
      "         2005,  2169,  7728,  1999,  2760,  1999, 23472,  2344,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:00:58 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'What was the low sale price per share for each quarters in 2018 in chronological order?', 'response': 'The low sale price per share for each quarters in 2018 in chronological order is 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.', 'doc': 'lifeway-foods-inc_2019', 'q_uid': 'f4c8e2d0155ac338249d0fe6feba49ac', 'answers': {'answer': ['$ 5.99', '$ 4.79', '$ 2.66', '$ 1.88'], 'answer_type': 'multi-span', 'scale': ''}}\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/george-weston-limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/verizon-communications-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/zendesk_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/quotient-technology-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/optimizerx-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/metro-ag_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/atlassian-corp-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cubic-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/commvault-systems-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/neonode-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/macom-technology_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/greensky-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/rogers-communications-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nortonlifelock-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/shopify-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/pegasystems-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/microsoft-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/oracle-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/american-tower-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/accenture-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cal-maine-foods-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/tencent_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/alarmcom-holdings-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/activision-blizzard-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/teekay-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/insight-enterprises-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/maple-leaf-foods-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/golar-lng-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/zix-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/gsi-technology-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/tata-consultancy-services-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/finjan-holding-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/mobileiron-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nielsen-nv_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/gaslog-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/jack-in-the-box-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/avalara_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/luna-innovations-incorporated_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/centurylink-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/bt-group-plc_2019.pdf\n",
      "=== Start tat on qwen2.5-1.5B ===\n",
      "2025-07-29 15:01:03 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:01:03,735 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:01:07 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:01:09] #> Note: Output directory .ragatouille/colbert/indexes/tat_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:01:09] #> Will delete 10 files already at .ragatouille/colbert/indexes/tat_vector_db in 20 seconds...\n",
      "[Jul 29, 15:01:32] [0] \t\t #> Encoding 67 passages..\n",
      "[Jul 29, 15:01:32] [0] \t\t avg_doclen_est = 3.8358209133148193 \t len(local_sample) = 67\n",
      "[Jul 29, 15:01:32] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/tat_vector_db/plan.json ..\n",
      "Warning: number of training points (245) is less than the minimum recommended (2560)\n",
      "used 3 iterations (0.0011s) to cluster 245 items into 256 clusters\n",
      "[0.012, 0.012, 0.011, 0.018, 0.015, 0.014, 0.013, 0.009, 0.019, 0.014, 0.005, 0.017, 0.012, 0.012, 0.005, 0.007, 0.015, 0.007, 0.005, 0.022, 0.014, 0.005, 0.018, 0.004, 0.005, 0.013, 0.013, 0.011, 0.008, 0.021, 0.008, 0.017, 0.009, 0.015, 0.013, 0.03, 0.016, 0.009, 0.021, 0.012, 0.013, 0.01, 0.012, 0.009, 0.017, 0.02, 0.014, 0.018, 0.012, 0.014, 0.008, 0.005, 0.013, 0.019, 0.008, 0.033, 0.009, 0.02, 0.01, 0.015, 0.013, 0.004, 0.011, 0.014, 0.006, 0.012, 0.031, 0.005, 0.009, 0.012, 0.012, 0.024, 0.009, 0.007, 0.009, 0.007, 0.019, 0.021, 0.017, 0.016, 0.037, 0.019, 0.018, 0.012, 0.015, 0.005, 0.026, 0.003, 0.01, 0.008, 0.015, 0.005, 0.011, 0.018, 0.008, 0.016, 0.036, 0.015, 0.013, 0.008, 0.015, 0.014, 0.01, 0.013, 0.009, 0.009, 0.017, 0.006, 0.017, 0.008, 0.01, 0.016, 0.004, 0.012, 0.011, 0.01, 0.009, 0.005, 0.011, 0.004, 0.015, 0.014, 0.01, 0.003, 0.015, 0.017, 0.016, 0.007]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:01:32] [0] \t\t #> Encoding 67 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 59.81it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2121.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:01:32] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:01:32] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:01:32] len(emb2pid) = 257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 196980.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:01:32] #> Saved optimized IVF to .ragatouille/colbert/indexes/tat_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:01:38] #> Loading codec...\n",
      "[Jul 29, 15:01:38] #> Loading IVF...\n",
      "[Jul 29, 15:01:38] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5683.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:01:38] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1598.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the difference between  Richard E. Belluzzo's total compensation as compared to Laura Black?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  4489,  2090,  2957,  1041,  1012,\n",
      "         4330, 17040,  6844,  1005,  1055,  2561,  9430,  2004,  4102,  2000,\n",
      "         6874,  2304,  1029,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:01:38 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': \"What is the difference between  Richard E. Belluzzo's total compensation as compared to Laura Black?\", 'response': 'The answer is: 364,975.', 'doc': 'viavi-solutions-inc_2019', 'q_uid': 'f1b63dd3002720ebbffa8f36d852d351', 'answers': {'answer': 92500, 'answer_type': 'arithmetic', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:01:44] #> Loading codec...\n",
      "[Jul 29, 15:01:44] #> Loading IVF...\n",
      "[Jul 29, 15:01:44] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7503.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:01:44] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1761.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: How much did Donald Colvin earn in cash?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2129, 2172, 2106, 6221, 8902, 6371, 7796, 1999, 5356, 1029,\n",
      "         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:01:44 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'How much did Donald Colvin earn in cash?', 'response': 'Donald Colvin earned $37,649.00 in cash.', 'doc': 'viavi-solutions-inc_2019', 'q_uid': 'd1a4ba4e1af05c60efa468f953a4f8ca', 'answers': {'answer': ['97,500'], 'answer_type': 'span', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:01:50] #> Loading codec...\n",
      "[Jul 29, 15:01:50] #> Loading IVF...\n",
      "[Jul 29, 15:01:50] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5907.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:01:50] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1621.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the percentage difference of the total compensation between Timothy Campos and Tor Braham?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  7017,  4489,  1997,  1996,  2561,\n",
      "         9430,  2090, 10805, 26925,  1998, 17153, 11655,  3511,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:01:50 CallLLM\n",
      "{'model': 'qwen2.5-1.5B', 'question': 'What is the percentage difference of the total compensation between Timothy Campos and Tor Braham?', 'response': '34.6%', 'doc': 'viavi-solutions-inc_2019', 'q_uid': '5cff0439063c6a496073ce4b55591d0b', 'answers': {'answer': 4.07, 'answer_type': 'arithmetic', 'scale': 'percent'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:01:52] #> Note: Output directory .ragatouille/colbert/indexes/tat_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:01:52] #> Will delete 10 files already at .ragatouille/colbert/indexes/tat_vector_db in 20 seconds...\n",
      "[Jul 29, 15:02:15] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:02:15] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:02:15] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/tat_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0011s) to cluster 201 items into 128 clusters\n",
      "[0.008, 0.004, 0.004, 0.006, 0.004, 0.006, 0.005, 0.005, 0.015, 0.01, 0.005, 0.003, 0.005, 0.006, 0.011, 0.013, 0.008, 0.007, 0.008, 0.003, 0.006, 0.013, 0.007, 0.005, 0.004, 0.009, 0.006, 0.007, 0.004, 0.002, 0.006, 0.009, 0.008, 0.016, 0.006, 0.007, 0.006, 0.015, 0.004, 0.008, 0.005, 0.004, 0.008, 0.012, 0.01, 0.003, 0.005, 0.009, 0.009, 0.006, 0.002, 0.006, 0.007, 0.007, 0.011, 0.013, 0.006, 0.004, 0.005, 0.003, 0.01, 0.004, 0.008, 0.014, 0.006, 0.004, 0.006, 0.01, 0.009, 0.006, 0.006, 0.003, 0.006, 0.007, 0.005, 0.011, 0.005, 0.008, 0.009, 0.01, 0.009, 0.009, 0.013, 0.004, 0.011, 0.008, 0.009, 0.008, 0.007, 0.007, 0.004, 0.005, 0.012, 0.009, 0.008, 0.009, 0.009, 0.014, 0.009, 0.008, 0.007, 0.012, 0.011, 0.005, 0.007, 0.006, 0.009, 0.006, 0.011, 0.005, 0.004, 0.006, 0.007, 0.013, 0.008, 0.01, 0.008, 0.01, 0.003, 0.007, 0.006, 0.007, 0.004, 0.007, 0.012, 0.013, 0.005, 0.01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:02:15] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 79.31it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2861.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:02:15] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:02:15] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:02:15] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 167719.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:02:15] #> Saved optimized IVF to .ragatouille/colbert/indexes/tat_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:02:21] #> Loading codec...\n",
      "[Jul 29, 15:02:21] #> Loading IVF...\n",
      "[Jul 29, 15:02:21] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6808.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:02:21] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2066.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What does cash and cash equivalents consist of?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2515, 5356, 1998, 5356, 5662, 2015, 8676, 1997, 1029,\n",
      "         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:02:21 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'What does cash and cash equivalents consist of?', 'response': 'Cash and cash equivalents include cash on hand, demand deposits, and other highly liquid investments that can be converted into cash within three months.', 'doc': 'inpixon_2019', 'q_uid': 'c97f3158996e35cf911eec06d020badc', 'answers': {'answer': ['cash, checking accounts, money market accounts and temporary investments with maturities of three months or less when purchased.'], 'answer_type': 'span', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:02:27] #> Loading codec...\n",
      "[Jul 29, 15:02:27] #> Loading IVF...\n",
      "[Jul 29, 15:02:27] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5159.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:02:27] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1254.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What was the average Professional and legal fees for 2018 and 2019?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1996,  2779,  2658,  1998,  3423,  9883,\n",
      "         2005,  2760,  1998, 10476,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:02:27 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'What was the average Professional and legal fees for 2018 and 2019?', 'response': '$34,675.00', 'doc': 'inpixon_2019', 'q_uid': 'd7d2b6427fb0f566a3ac2e90d842dd06', 'answers': {'answer': 393.5, 'answer_type': 'arithmetic', 'scale': 'thousand'}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:02:33] #> Loading codec...\n",
      "[Jul 29, 15:02:33] #> Loading IVF...\n",
      "[Jul 29, 15:02:33] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6195.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:02:33] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1811.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: How does the company account for options granted to employees?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2129, 2515, 1996, 2194, 4070, 2005, 7047, 4379, 2000, 5126,\n",
      "        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:02:33 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'How does the company account for options granted to employees?', 'response': 'The company grants stock options to its employees as part of their compensation package. These options give employees the right to purchase shares at a predetermined price within a specified period.', 'doc': 'inpixon_2019', 'q_uid': 'fde5598a4f22f1775d27e488f367cdb7', 'answers': {'answer': ['by measuring the cost of services received in exchange for the award of equity instruments based upon the fair value of the award on the date of grant.'], 'answer_type': 'span', 'scale': ''}}\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/national-storage-reit_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cincinnati-bell-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/greencore-group-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/jabil-circuit-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cornerstone-ondemand-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/ichor-holdings-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/everbridge-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/network-1-technologies_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/xperi-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cts-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/Intu-Properties_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/siemens-ag_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/carpenter-technology-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/united-micro-electronics-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/on-semiconductor_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/consolidated-communications-holdings-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/Nextdc-Ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/black-knight-financial-services-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/brainstorm-cell-therapeutics_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/spirent-communications-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/proofpoint_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nordic-american-tankers-limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/par-technology-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/conagra-brands-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/stmicroelectronics_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/singapore-telecommunications-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/extreme-networks-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/logitech-international-sa_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cogent-communications-group-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/bce-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/westell-technologies-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/acura-pharmaceuticals-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/support-com_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nanthealth-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/travelzoo_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/square-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/allscripts-healthcare-solutions-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/agilysys-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/maxlinear-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/parkervision_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cisco-systems-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/methode-electronics-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/lam-research-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/international-business-machines-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/guidewire-software-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/globalscape-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/opentext-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/tyson-foods-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/csg-systems-international-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/unilever-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/mimecast-limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/mantech-international-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/netapp-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/godaddy-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/Woolworths-Limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/acacia-communications-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/freshpet-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/sykes-enterprises-incorporated_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/spirax-sarco-engineering-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/teradyne-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/resonant-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/taiwan-semiconductor-manufacturing-co-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/amcon-distributing-company_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/sealed-air-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/adtran-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/clearfield-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/quicklogic-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/frequency-electronics-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/leidos-holdings_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/te-connectivity-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/jack-henry-associates-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/mitek-systems_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/autodesk-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/chefs-wharehouse_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/protagenic-therapeutics-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/micron-technology-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/coherent-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/intel-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/avx-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nokia-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/zayo-group-holdings_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/ricebran-technologies_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/microchip-technology-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/sunpower-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/csp-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/tiger-brands-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cogeco-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/Auto-Trader_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/virnetx-holding-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/calamp-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/torm_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/first-solar-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/loral-space-communications-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/a10-networks-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/sunworks-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/fitbit-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/marks-and-spencer-group-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/kemet-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/marin-software-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/adobe-systems-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/altium-limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/immersion_2019.pdf\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:02:36] #> Note: Output directory .ragatouille/colbert/indexes/tat_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:02:36] #> Will delete 10 files already at .ragatouille/colbert/indexes/tat_vector_db in 20 seconds...\n",
      "[Jul 29, 15:02:59] [0] \t\t #> Encoding 78 passages..\n",
      "[Jul 29, 15:02:59] [0] \t\t avg_doclen_est = 3.846153736114502 \t len(local_sample) = 78\n",
      "[Jul 29, 15:02:59] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/tat_vector_db/plan.json ..\n",
      "Warning: number of training points (285) is less than the minimum recommended (2560)\n",
      "used 3 iterations (0.0009s) to cluster 285 items into 256 clusters\n",
      "[0.005, 0.006, 0.01, 0.018, 0.008, 0.007, 0.009, 0.012, 0.002, 0.005, 0.007, 0.01, 0.001, 0.018, 0.014, 0.011, 0.009, 0.009, 0.005, 0.016, 0.007, 0.003, 0.006, 0.013, 0.002, 0.007, 0.02, 0.004, 0.005, 0.021, 0.009, 0.007, 0.013, 0.005, 0.009, 0.011, 0.007, 0.015, 0.014, 0.008, 0.003, 0.013, 0.016, 0.01, 0.004, 0.007, 0.016, 0.014, 0.01, 0.014, 0.013, 0.003, 0.01, 0.016, 0.004, 0.011, 0.004, 0.006, 0.01, 0.009, 0.006, 0.006, 0.01, 0.009, 0.006, 0.005, 0.011, 0.013, 0.009, 0.014, 0.005, 0.015, 0.014, 0.009, 0.003, 0.002, 0.009, 0.008, 0.006, 0.011, 0.011, 0.006, 0.009, 0.01, 0.004, 0.005, 0.019, 0.005, 0.007, 0.012, 0.014, 0.018, 0.004, 0.018, 0.005, 0.005, 0.015, 0.012, 0.023, 0.004, 0.016, 0.003, 0.007, 0.006, 0.005, 0.001, 0.002, 0.014, 0.005, 0.021, 0.006, 0.012, 0.019, 0.008, 0.005, 0.006, 0.006, 0.008, 0.007, 0.003, 0.008, 0.008, 0.008, 0.005, 0.005, 0.007, 0.005, 0.003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:02:59] [0] \t\t #> Encoding 78 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 56.12it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1334.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:02:59] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:02:59] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:02:59] len(emb2pid) = 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 74333.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:02:59] #> Saved optimized IVF to .ragatouille/colbert/indexes/tat_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:03:06] #> Loading codec...\n",
      "[Jul 29, 15:03:06] #> Loading IVF...\n",
      "[Jul 29, 15:03:06] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11586.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:03:06] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1572.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the average Net income for Years Ended December 31, 2018 to 2019?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2779,  5658,  3318,  2005,  2086,\n",
      "         3092,  2285,  2861,  1010,  2760,  2000, 10476,  1029,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:03:06 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'What is the average Net income for Years Ended December 31, 2018 to 2019?', 'response': 'The answer is: 46.67', 'doc': 'overseas-shipholding-group-inc_2019', 'q_uid': 'ed78c51011874fe47d3910ab9794cce6', 'answers': {'answer': 11082, 'answer_type': 'arithmetic', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:03:12] #> Loading codec...\n",
      "[Jul 29, 15:03:12] #> Loading IVF...\n",
      "[Jul 29, 15:03:12] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6355.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:03:12] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1673.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the average Interest before impact of interest rate caps for Years Ended December 31, 2018 to 2019?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2779,  3037,  2077,  4254,  1997,\n",
      "         3037,  3446,  9700,  2005,  2086,  3092,  2285,  2861,  1010,  2760,\n",
      "         2000, 10476,  1029,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:03:12 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'What is the average Interest before impact of interest rate caps for Years Ended December 31, 2018 to 2019?', 'response': 'The answer is: 4.67%', 'doc': 'overseas-shipholding-group-inc_2019', 'q_uid': '69977fcc3bdeb9ae684b21997c00ddab', 'answers': {'answer': 28171, 'answer_type': 'arithmetic', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:03:18] #> Loading codec...\n",
      "[Jul 29, 15:03:18] #> Loading IVF...\n",
      "[Jul 29, 15:03:18] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6775.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:03:18] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1651.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: In which year was Operating Leases greater than 100,000?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1999,  2029,  2095,  2001,  4082, 29597,  3618,  2084,\n",
      "         2531,  1010,  2199,  1029,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:03:18 CallLLM\n",
      "{'model': 'qwen2.5-1.5B', 'question': 'In which year was Operating Leases greater than 100,000?', 'response': '2014', 'doc': 'overseas-shipholding-group-inc_2019', 'q_uid': 'ccc7a9080e0fea2e3181976dc634e30f', 'answers': {'answer': ['2022'], 'answer_type': 'span', 'scale': ''}}\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/telkonet-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/aci-worldwide-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/hc2-holdings-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/netgear-inc_2019.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:03:20] #> Note: Output directory .ragatouille/colbert/indexes/tat_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:03:20] #> Will delete 10 files already at .ragatouille/colbert/indexes/tat_vector_db in 20 seconds...\n",
      "[Jul 29, 15:03:43] [0] \t\t #> Encoding 65 passages..\n",
      "[Jul 29, 15:03:43] [0] \t\t avg_doclen_est = 3.8307693004608154 \t len(local_sample) = 65\n",
      "[Jul 29, 15:03:43] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/tat_vector_db/plan.json ..\n",
      "Warning: number of training points (237) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.001s) to cluster 237 items into 128 clusters\n",
      "[0.014, 0.004, 0.006, 0.006, 0.008, 0.008, 0.007, 0.008, 0.004, 0.009, 0.008, 0.012, 0.006, 0.016, 0.005, 0.007, 0.022, 0.01, 0.009, 0.015, 0.01, 0.01, 0.006, 0.01, 0.007, 0.012, 0.021, 0.005, 0.009, 0.009, 0.013, 0.004, 0.016, 0.008, 0.006, 0.014, 0.01, 0.007, 0.02, 0.014, 0.006, 0.012, 0.006, 0.009, 0.008, 0.005, 0.008, 0.013, 0.011, 0.009, 0.004, 0.011, 0.013, 0.013, 0.007, 0.011, 0.008, 0.01, 0.006, 0.006, 0.008, 0.009, 0.005, 0.013, 0.004, 0.009, 0.01, 0.011, 0.006, 0.019, 0.009, 0.015, 0.007, 0.005, 0.006, 0.013, 0.009, 0.015, 0.016, 0.013, 0.016, 0.013, 0.005, 0.011, 0.009, 0.009, 0.013, 0.008, 0.007, 0.009, 0.01, 0.008, 0.01, 0.01, 0.01, 0.008, 0.012, 0.006, 0.016, 0.006, 0.01, 0.009, 0.006, 0.005, 0.011, 0.007, 0.013, 0.008, 0.008, 0.019, 0.01, 0.007, 0.012, 0.016, 0.011, 0.013, 0.009, 0.008, 0.006, 0.007, 0.005, 0.004, 0.013, 0.007, 0.005, 0.006, 0.007, 0.013]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:03:43] [0] \t\t #> Encoding 65 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 57.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2489.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:03:43] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:03:43] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:03:43] len(emb2pid) = 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 164785.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:03:43] #> Saved optimized IVF to .ragatouille/colbert/indexes/tat_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:03:49] #> Loading codec...\n",
      "[Jul 29, 15:03:49] #> Loading IVF...\n",
      "[Jul 29, 15:03:49] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6668.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:03:49] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1759.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the symbol of the company's common stock that is listed on the Nasdaq Global Market?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  6454,  1997,  1996,  2194,  1005,\n",
      "         1055,  2691,  4518,  2008,  2003,  3205,  2006,  1996, 17235,  2850,\n",
      "         4160,  3795,  3006,  1029,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:03:49 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': \"What is the symbol of the company's common stock that is listed on the Nasdaq Global Market?\", 'response': 'The answer is: NASDAQ-100 ETF', 'doc': 'lifeway-foods-inc_2019', 'q_uid': '871af62021e2bd9a6ff15f9b1ba26d79', 'answers': {'answer': ['LWAY'], 'answer_type': 'span', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:03:55] #> Loading codec...\n",
      "[Jul 29, 15:03:55] #> Loading IVF...\n",
      "[Jul 29, 15:03:55] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4963.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:03:55] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1195.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the change in the value of brand names between 2018 and 2019?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2689,  1999,  1996,  3643,  1997,\n",
      "         4435,  3415,  2090,  2760,  1998, 10476,  1029,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:03:55 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'What is the change in the value of brand names between 2018 and 2019?', 'response': 'Brand name values increased from $374 million in 2018 to $465 million in 2019. This represents a 25% increase over two years.', 'doc': 'lifeway-foods-inc_2019', 'q_uid': 'ec84e524463dfd906ae9c37d739c610f', 'answers': {'answer': 0, 'answer_type': 'arithmetic', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:04:02] #> Loading codec...\n",
      "[Jul 29, 15:04:02] #> Loading IVF...\n",
      "[Jul 29, 15:04:02] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4922.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:04:02] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1232.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What was the low sale price per share for each quarters in 2018 in chronological order?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1996,  2659,  5096,  3976,  2566,  3745,\n",
      "         2005,  2169,  7728,  1999,  2760,  1999, 23472,  2344,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:04:02 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'What was the low sale price per share for each quarters in 2018 in chronological order?', 'response': 'The low sale price per share for Q4 2018 was $36.00.', 'doc': 'lifeway-foods-inc_2019', 'q_uid': 'f4c8e2d0155ac338249d0fe6feba49ac', 'answers': {'answer': ['$ 5.99', '$ 4.79', '$ 2.66', '$ 1.88'], 'answer_type': 'multi-span', 'scale': ''}}\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/george-weston-limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/verizon-communications-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/zendesk_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/quotient-technology-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/optimizerx-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/metro-ag_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/atlassian-corp-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cubic-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/commvault-systems-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/neonode-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/macom-technology_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/greensky-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/rogers-communications-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nortonlifelock-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/shopify-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/pegasystems-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/microsoft-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/oracle-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/american-tower-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/accenture-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cal-maine-foods-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/tencent_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/alarmcom-holdings-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/activision-blizzard-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/teekay-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/insight-enterprises-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/maple-leaf-foods-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/golar-lng-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/zix-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/gsi-technology-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/tata-consultancy-services-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/finjan-holding-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/mobileiron-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nielsen-nv_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/gaslog-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/jack-in-the-box-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/avalara_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/luna-innovations-incorporated_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/centurylink-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/bt-group-plc_2019.pdf\n",
      "=== Start tat on qwen2.5-3B ===\n",
      "2025-07-29 15:04:02 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:04:03,035 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.03s/it]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:04:09 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:04:13] #> Note: Output directory .ragatouille/colbert/indexes/tat_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:04:13] #> Will delete 10 files already at .ragatouille/colbert/indexes/tat_vector_db in 20 seconds...\n",
      "[Jul 29, 15:04:36] [0] \t\t #> Encoding 67 passages..\n",
      "[Jul 29, 15:04:36] [0] \t\t avg_doclen_est = 3.8358209133148193 \t len(local_sample) = 67\n",
      "[Jul 29, 15:04:36] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/tat_vector_db/plan.json ..\n",
      "Warning: number of training points (245) is less than the minimum recommended (2560)\n",
      "used 3 iterations (0.0008s) to cluster 245 items into 256 clusters\n",
      "[0.012, 0.012, 0.011, 0.018, 0.015, 0.014, 0.013, 0.009, 0.019, 0.014, 0.005, 0.017, 0.012, 0.012, 0.005, 0.007, 0.015, 0.007, 0.005, 0.022, 0.014, 0.005, 0.018, 0.004, 0.005, 0.013, 0.013, 0.011, 0.008, 0.021, 0.008, 0.017, 0.009, 0.015, 0.013, 0.03, 0.016, 0.009, 0.021, 0.012, 0.013, 0.01, 0.012, 0.009, 0.017, 0.02, 0.014, 0.018, 0.012, 0.014, 0.008, 0.005, 0.013, 0.019, 0.008, 0.033, 0.009, 0.02, 0.01, 0.015, 0.013, 0.004, 0.011, 0.014, 0.006, 0.012, 0.031, 0.005, 0.009, 0.012, 0.012, 0.024, 0.009, 0.007, 0.009, 0.007, 0.019, 0.021, 0.017, 0.016, 0.037, 0.019, 0.018, 0.012, 0.015, 0.005, 0.026, 0.003, 0.01, 0.008, 0.015, 0.005, 0.011, 0.018, 0.008, 0.016, 0.036, 0.015, 0.013, 0.008, 0.015, 0.014, 0.01, 0.013, 0.009, 0.009, 0.017, 0.006, 0.017, 0.008, 0.01, 0.016, 0.004, 0.012, 0.011, 0.01, 0.009, 0.005, 0.011, 0.004, 0.015, 0.014, 0.01, 0.003, 0.015, 0.017, 0.016, 0.007]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:04:36] [0] \t\t #> Encoding 67 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 58.10it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2502.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:04:36] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:04:36] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:04:36] len(emb2pid) = 257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 204522.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:04:36] #> Saved optimized IVF to .ragatouille/colbert/indexes/tat_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:04:42] #> Loading codec...\n",
      "[Jul 29, 15:04:42] #> Loading IVF...\n",
      "[Jul 29, 15:04:42] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5729.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:04:42] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1705.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the difference between  Richard E. Belluzzo's total compensation as compared to Laura Black?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  4489,  2090,  2957,  1041,  1012,\n",
      "         4330, 17040,  6844,  1005,  1055,  2561,  9430,  2004,  4102,  2000,\n",
      "         6874,  2304,  1029,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:04:42 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': \"What is the difference between  Richard E. Belluzzo's total compensation as compared to Laura Black?\", 'response': 'Insufficient information provided.\\n The answer is: Not enough information', 'doc': 'viavi-solutions-inc_2019', 'q_uid': 'f1b63dd3002720ebbffa8f36d852d351', 'answers': {'answer': 92500, 'answer_type': 'arithmetic', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:04:48] #> Loading codec...\n",
      "[Jul 29, 15:04:48] #> Loading IVF...\n",
      "[Jul 29, 15:04:48] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5223.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:04:48] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1778.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: How much did Donald Colvin earn in cash?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2129, 2172, 2106, 6221, 8902, 6371, 7796, 1999, 5356, 1029,\n",
      "         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:04:48 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'How much did Donald Colvin earn in cash?', 'response': \"The information about Donald Colvin's cash earnings is not provided in the given context.\\n The answer is: Not Available\", 'doc': 'viavi-solutions-inc_2019', 'q_uid': 'd1a4ba4e1af05c60efa468f953a4f8ca', 'answers': {'answer': ['97,500'], 'answer_type': 'span', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:04:55] #> Loading codec...\n",
      "[Jul 29, 15:04:55] #> Loading IVF...\n",
      "[Jul 29, 15:04:55] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7169.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:04:55] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1580.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the percentage difference of the total compensation between Timothy Campos and Tor Braham?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  7017,  4489,  1997,  1996,  2561,\n",
      "         9430,  2090, 10805, 26925,  1998, 17153, 11655,  3511,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:04:55 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'What is the percentage difference of the total compensation between Timothy Campos and Tor Braham?', 'response': 'Insufficient data provided.\\n The answer is: N/A', 'doc': 'viavi-solutions-inc_2019', 'q_uid': '5cff0439063c6a496073ce4b55591d0b', 'answers': {'answer': 4.07, 'answer_type': 'arithmetic', 'scale': 'percent'}}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:04:58] #> Note: Output directory .ragatouille/colbert/indexes/tat_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:04:58] #> Will delete 10 files already at .ragatouille/colbert/indexes/tat_vector_db in 20 seconds...\n",
      "[Jul 29, 15:05:21] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:05:21] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:05:21] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/tat_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0011s) to cluster 201 items into 128 clusters\n",
      "[0.008, 0.004, 0.004, 0.006, 0.004, 0.006, 0.005, 0.005, 0.015, 0.01, 0.005, 0.003, 0.005, 0.006, 0.011, 0.013, 0.008, 0.007, 0.008, 0.003, 0.006, 0.013, 0.007, 0.005, 0.004, 0.009, 0.006, 0.007, 0.004, 0.002, 0.006, 0.009, 0.008, 0.016, 0.006, 0.007, 0.006, 0.015, 0.004, 0.008, 0.005, 0.004, 0.008, 0.012, 0.01, 0.003, 0.005, 0.009, 0.009, 0.006, 0.002, 0.006, 0.007, 0.007, 0.011, 0.013, 0.006, 0.004, 0.005, 0.003, 0.01, 0.004, 0.008, 0.014, 0.006, 0.004, 0.006, 0.01, 0.009, 0.006, 0.006, 0.003, 0.006, 0.007, 0.005, 0.011, 0.005, 0.008, 0.009, 0.01, 0.009, 0.009, 0.013, 0.004, 0.011, 0.008, 0.009, 0.008, 0.007, 0.007, 0.004, 0.005, 0.012, 0.009, 0.008, 0.009, 0.009, 0.014, 0.009, 0.008, 0.007, 0.012, 0.011, 0.005, 0.007, 0.006, 0.009, 0.006, 0.011, 0.005, 0.004, 0.006, 0.007, 0.013, 0.008, 0.01, 0.008, 0.01, 0.003, 0.007, 0.006, 0.007, 0.004, 0.007, 0.012, 0.013, 0.005, 0.01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:05:21] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 50.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1539.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:05:21] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:05:21] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:05:21] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 142481.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:05:21] #> Saved optimized IVF to .ragatouille/colbert/indexes/tat_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:05:27] #> Loading codec...\n",
      "[Jul 29, 15:05:27] #> Loading IVF...\n",
      "[Jul 29, 15:05:27] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7013.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:05:27] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2073.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What does cash and cash equivalents consist of?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2515, 5356, 1998, 5356, 5662, 2015, 8676, 1997, 1029,\n",
      "         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:05:27 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'What does cash and cash equivalents consist of?', 'response': 'The context provided seems incomplete or incorrectly formatted for extracting specific information about cash and cash equivalents.\\n The answer is: Not enough information provided.', 'doc': 'inpixon_2019', 'q_uid': 'c97f3158996e35cf911eec06d020badc', 'answers': {'answer': ['cash, checking accounts, money market accounts and temporary investments with maturities of three months or less when purchased.'], 'answer_type': 'span', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:05:35] #> Loading codec...\n",
      "[Jul 29, 15:05:35] #> Loading IVF...\n",
      "[Jul 29, 15:05:35] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7133.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:05:35] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1773.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What was the average Professional and legal fees for 2018 and 2019?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1996,  2779,  2658,  1998,  3423,  9883,\n",
      "         2005,  2760,  1998, 10476,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:05:35 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'What was the average Professional and legal fees for 2018 and 2019?', 'response': 'There is no data provided about Professional and legal fees for 2018 and 2019 in the given context.\\n The answer is: Not Available', 'doc': 'inpixon_2019', 'q_uid': 'd7d2b6427fb0f566a3ac2e90d842dd06', 'answers': {'answer': 393.5, 'answer_type': 'arithmetic', 'scale': 'thousand'}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:05:44] #> Loading codec...\n",
      "[Jul 29, 15:05:44] #> Loading IVF...\n",
      "[Jul 29, 15:05:44] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6335.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:05:44] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1585.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: How does the company account for options granted to employees?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2129, 2515, 1996, 2194, 4070, 2005, 7047, 4379, 2000, 5126,\n",
      "        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:05:44 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'How does the company account for options granted to employees?', 'response': 'This information is not provided in the given context.\\n The answer is: Not specified', 'doc': 'inpixon_2019', 'q_uid': 'fde5598a4f22f1775d27e488f367cdb7', 'answers': {'answer': ['by measuring the cost of services received in exchange for the award of equity instruments based upon the fair value of the award on the date of grant.'], 'answer_type': 'span', 'scale': ''}}\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/national-storage-reit_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cincinnati-bell-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/greencore-group-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/jabil-circuit-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cornerstone-ondemand-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/ichor-holdings-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/everbridge-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/network-1-technologies_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/xperi-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cts-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/Intu-Properties_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/siemens-ag_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/carpenter-technology-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/united-micro-electronics-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/on-semiconductor_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/consolidated-communications-holdings-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/Nextdc-Ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/black-knight-financial-services-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/brainstorm-cell-therapeutics_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/spirent-communications-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/proofpoint_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nordic-american-tankers-limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/par-technology-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/conagra-brands-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/stmicroelectronics_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/singapore-telecommunications-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/extreme-networks-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/logitech-international-sa_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cogent-communications-group-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/bce-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/westell-technologies-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/acura-pharmaceuticals-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/support-com_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nanthealth-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/travelzoo_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/square-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/allscripts-healthcare-solutions-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/agilysys-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/maxlinear-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/parkervision_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cisco-systems-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/methode-electronics-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/lam-research-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/international-business-machines-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/guidewire-software-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/globalscape-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/opentext-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/tyson-foods-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/csg-systems-international-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/unilever-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/mimecast-limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/mantech-international-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/netapp-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/godaddy-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/Woolworths-Limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/acacia-communications-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/freshpet-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/sykes-enterprises-incorporated_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/spirax-sarco-engineering-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/teradyne-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/resonant-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/taiwan-semiconductor-manufacturing-co-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/amcon-distributing-company_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/sealed-air-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/adtran-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/clearfield-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/quicklogic-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/frequency-electronics-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/leidos-holdings_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/te-connectivity-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/jack-henry-associates-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/mitek-systems_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/autodesk-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/chefs-wharehouse_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/protagenic-therapeutics-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/micron-technology-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/coherent-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/intel-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/avx-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nokia-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/zayo-group-holdings_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/ricebran-technologies_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/microchip-technology-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/sunpower-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/csp-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/tiger-brands-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cogeco-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/Auto-Trader_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/virnetx-holding-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/calamp-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/torm_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/first-solar-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/loral-space-communications-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/a10-networks-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/sunworks-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/fitbit-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/marks-and-spencer-group-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/kemet-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/marin-software-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/adobe-systems-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/altium-limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/immersion_2019.pdf\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:05:47] #> Note: Output directory .ragatouille/colbert/indexes/tat_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:05:47] #> Will delete 10 files already at .ragatouille/colbert/indexes/tat_vector_db in 20 seconds...\n",
      "[Jul 29, 15:06:10] [0] \t\t #> Encoding 78 passages..\n",
      "[Jul 29, 15:06:10] [0] \t\t avg_doclen_est = 3.846153736114502 \t len(local_sample) = 78\n",
      "[Jul 29, 15:06:10] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/tat_vector_db/plan.json ..\n",
      "Warning: number of training points (285) is less than the minimum recommended (2560)\n",
      "used 3 iterations (0.0011s) to cluster 285 items into 256 clusters\n",
      "[0.005, 0.006, 0.01, 0.018, 0.008, 0.007, 0.009, 0.012, 0.002, 0.005, 0.007, 0.01, 0.001, 0.018, 0.014, 0.011, 0.009, 0.009, 0.005, 0.016, 0.007, 0.003, 0.006, 0.013, 0.002, 0.007, 0.02, 0.004, 0.005, 0.021, 0.009, 0.007, 0.013, 0.005, 0.009, 0.011, 0.007, 0.015, 0.014, 0.008, 0.003, 0.013, 0.016, 0.01, 0.004, 0.007, 0.016, 0.014, 0.01, 0.014, 0.013, 0.003, 0.01, 0.016, 0.004, 0.011, 0.004, 0.006, 0.01, 0.009, 0.006, 0.006, 0.01, 0.009, 0.006, 0.005, 0.011, 0.013, 0.009, 0.014, 0.005, 0.015, 0.014, 0.009, 0.003, 0.002, 0.009, 0.008, 0.006, 0.011, 0.011, 0.006, 0.009, 0.01, 0.004, 0.005, 0.019, 0.005, 0.007, 0.012, 0.014, 0.018, 0.004, 0.018, 0.005, 0.005, 0.015, 0.012, 0.023, 0.004, 0.016, 0.003, 0.007, 0.006, 0.005, 0.001, 0.002, 0.014, 0.005, 0.021, 0.006, 0.012, 0.019, 0.008, 0.005, 0.006, 0.006, 0.008, 0.007, 0.003, 0.008, 0.008, 0.008, 0.005, 0.005, 0.007, 0.005, 0.003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:06:10] [0] \t\t #> Encoding 78 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 59.09it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2381.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:06:10] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:06:10] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:06:10] len(emb2pid) = 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 141822.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:06:10] #> Saved optimized IVF to .ragatouille/colbert/indexes/tat_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:06:18] #> Loading codec...\n",
      "[Jul 29, 15:06:18] #> Loading IVF...\n",
      "[Jul 29, 15:06:18] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5841.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:06:18] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1721.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the average Net income for Years Ended December 31, 2018 to 2019?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2779,  5658,  3318,  2005,  2086,\n",
      "         3092,  2285,  2861,  1010,  2760,  2000, 10476,  1029,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:06:18 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'What is the average Net income for Years Ended December 31, 2018 to 2019?', 'response': 'There is no data provided for Net Income in the given context.\\n The answer is: Not Available', 'doc': 'overseas-shipholding-group-inc_2019', 'q_uid': 'ed78c51011874fe47d3910ab9794cce6', 'answers': {'answer': 11082, 'answer_type': 'arithmetic', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:06:25] #> Loading codec...\n",
      "[Jul 29, 15:06:25] #> Loading IVF...\n",
      "[Jul 29, 15:06:25] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5882.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:06:25] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1230.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the average Interest before impact of interest rate caps for Years Ended December 31, 2018 to 2019?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2779,  3037,  2077,  4254,  1997,\n",
      "         3037,  3446,  9700,  2005,  2086,  3092,  2285,  2861,  1010,  2760,\n",
      "         2000, 10476,  1029,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:06:25 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'What is the average Interest before impact of interest rate caps for Years Ended December 31, 2018 to 2019?', 'response': 'The answer is: 4.75', 'doc': 'overseas-shipholding-group-inc_2019', 'q_uid': '69977fcc3bdeb9ae684b21997c00ddab', 'answers': {'answer': 28171, 'answer_type': 'arithmetic', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:06:32] #> Loading codec...\n",
      "[Jul 29, 15:06:32] #> Loading IVF...\n",
      "[Jul 29, 15:06:32] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5302.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:06:32] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1886.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: In which year was Operating Leases greater than 100,000?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1999,  2029,  2095,  2001,  4082, 29597,  3618,  2084,\n",
      "         2531,  1010,  2199,  1029,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:06:32 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'In which year was Operating Leases greater than 100,000?', 'response': 'There is no information provided about Operating Leases being greater than 100,000 for any specific year.\\n The answer is: Not specified', 'doc': 'overseas-shipholding-group-inc_2019', 'q_uid': 'ccc7a9080e0fea2e3181976dc634e30f', 'answers': {'answer': ['2022'], 'answer_type': 'span', 'scale': ''}}\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/telkonet-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/aci-worldwide-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/hc2-holdings-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/netgear-inc_2019.pdf\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:06:35] #> Note: Output directory .ragatouille/colbert/indexes/tat_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:06:35] #> Will delete 10 files already at .ragatouille/colbert/indexes/tat_vector_db in 20 seconds...\n",
      "[Jul 29, 15:06:58] [0] \t\t #> Encoding 65 passages..\n",
      "[Jul 29, 15:06:58] [0] \t\t avg_doclen_est = 3.8307693004608154 \t len(local_sample) = 65\n",
      "[Jul 29, 15:06:58] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/tat_vector_db/plan.json ..\n",
      "Warning: number of training points (237) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.001s) to cluster 237 items into 128 clusters\n",
      "[0.014, 0.004, 0.006, 0.006, 0.008, 0.008, 0.007, 0.008, 0.004, 0.009, 0.008, 0.012, 0.006, 0.016, 0.005, 0.007, 0.022, 0.01, 0.009, 0.015, 0.01, 0.01, 0.006, 0.01, 0.007, 0.012, 0.021, 0.005, 0.009, 0.009, 0.013, 0.004, 0.016, 0.008, 0.006, 0.014, 0.01, 0.007, 0.02, 0.014, 0.006, 0.012, 0.006, 0.009, 0.008, 0.005, 0.008, 0.013, 0.011, 0.009, 0.004, 0.011, 0.013, 0.013, 0.007, 0.011, 0.008, 0.01, 0.006, 0.006, 0.008, 0.009, 0.005, 0.013, 0.004, 0.009, 0.01, 0.011, 0.006, 0.019, 0.009, 0.015, 0.007, 0.005, 0.006, 0.013, 0.009, 0.015, 0.016, 0.013, 0.016, 0.013, 0.005, 0.011, 0.009, 0.009, 0.013, 0.008, 0.007, 0.009, 0.01, 0.008, 0.01, 0.01, 0.01, 0.008, 0.012, 0.006, 0.016, 0.006, 0.01, 0.009, 0.006, 0.005, 0.011, 0.007, 0.013, 0.008, 0.008, 0.019, 0.01, 0.007, 0.012, 0.016, 0.011, 0.013, 0.009, 0.008, 0.006, 0.007, 0.005, 0.004, 0.013, 0.007, 0.005, 0.006, 0.007, 0.013]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:06:58] [0] \t\t #> Encoding 65 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 53.30it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2339.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:06:58] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:06:58] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:06:58] len(emb2pid) = 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 159783.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:06:58] #> Saved optimized IVF to .ragatouille/colbert/indexes/tat_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:07:04] #> Loading codec...\n",
      "[Jul 29, 15:07:04] #> Loading IVF...\n",
      "[Jul 29, 15:07:04] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4387.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:07:04] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1524.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the symbol of the company's common stock that is listed on the Nasdaq Global Market?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  6454,  1997,  1996,  2194,  1005,\n",
      "         1055,  2691,  4518,  2008,  2003,  3205,  2006,  1996, 17235,  2850,\n",
      "         4160,  3795,  3006,  1029,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:07:04 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': \"What is the symbol of the company's common stock that is listed on the Nasdaq Global Market?\", 'response': 'The answer is: XFFX', 'doc': 'lifeway-foods-inc_2019', 'q_uid': '871af62021e2bd9a6ff15f9b1ba26d79', 'answers': {'answer': ['LWAY'], 'answer_type': 'span', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:07:10] #> Loading codec...\n",
      "[Jul 29, 15:07:10] #> Loading IVF...\n",
      "[Jul 29, 15:07:10] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6413.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:07:10] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1790.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the change in the value of brand names between 2018 and 2019?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2689,  1999,  1996,  3643,  1997,\n",
      "         4435,  3415,  2090,  2760,  1998, 10476,  1029,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:07:10 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'What is the change in the value of brand names between 2018 and 2019?', 'response': '-30%\\n The answer is: -30%', 'doc': 'lifeway-foods-inc_2019', 'q_uid': 'ec84e524463dfd906ae9c37d739c610f', 'answers': {'answer': 0, 'answer_type': 'arithmetic', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:07:17] #> Loading codec...\n",
      "[Jul 29, 15:07:17] #> Loading IVF...\n",
      "[Jul 29, 15:07:17] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5356.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:07:17] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1120.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What was the low sale price per share for each quarters in 2018 in chronological order?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1996,  2659,  5096,  3976,  2566,  3745,\n",
      "         2005,  2169,  7728,  1999,  2760,  1999, 23472,  2344,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:07:17 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'What was the low sale price per share for each quarters in 2018 in chronological order?', 'response': 'There is no information provided about stock prices or quarterly sales in the given context.\\n The answer is: Not available', 'doc': 'lifeway-foods-inc_2019', 'q_uid': 'f4c8e2d0155ac338249d0fe6feba49ac', 'answers': {'answer': ['$ 5.99', '$ 4.79', '$ 2.66', '$ 1.88'], 'answer_type': 'multi-span', 'scale': ''}}\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/george-weston-limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/verizon-communications-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/zendesk_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/quotient-technology-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/optimizerx-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/metro-ag_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/atlassian-corp-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cubic-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/commvault-systems-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/neonode-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/macom-technology_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/greensky-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/rogers-communications-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nortonlifelock-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/shopify-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/pegasystems-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/microsoft-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/oracle-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/american-tower-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/accenture-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cal-maine-foods-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/tencent_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/alarmcom-holdings-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/activision-blizzard-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/teekay-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/insight-enterprises-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/maple-leaf-foods-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/golar-lng-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/zix-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/gsi-technology-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/tata-consultancy-services-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/finjan-holding-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/mobileiron-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nielsen-nv_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/gaslog-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/jack-in-the-box-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/avalara_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/luna-innovations-incorporated_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/centurylink-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/bt-group-plc_2019.pdf\n",
      "=== Start tat on falcon-e-3B ===\n",
      "2025-07-29 15:07:17 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:07:18,181 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:07:19 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:07:22] #> Note: Output directory .ragatouille/colbert/indexes/tat_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:07:22] #> Will delete 10 files already at .ragatouille/colbert/indexes/tat_vector_db in 20 seconds...\n",
      "[Jul 29, 15:07:44] [0] \t\t #> Encoding 67 passages..\n",
      "[Jul 29, 15:07:44] [0] \t\t avg_doclen_est = 3.8358209133148193 \t len(local_sample) = 67\n",
      "[Jul 29, 15:07:44] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/tat_vector_db/plan.json ..\n",
      "Warning: number of training points (245) is less than the minimum recommended (2560)\n",
      "used 3 iterations (0.001s) to cluster 245 items into 256 clusters\n",
      "[0.012, 0.012, 0.011, 0.018, 0.015, 0.014, 0.013, 0.009, 0.019, 0.014, 0.005, 0.017, 0.012, 0.012, 0.005, 0.007, 0.015, 0.007, 0.005, 0.022, 0.014, 0.005, 0.018, 0.004, 0.005, 0.013, 0.013, 0.011, 0.008, 0.021, 0.008, 0.017, 0.009, 0.015, 0.013, 0.03, 0.016, 0.009, 0.021, 0.012, 0.013, 0.01, 0.012, 0.009, 0.017, 0.02, 0.014, 0.018, 0.012, 0.014, 0.008, 0.005, 0.013, 0.019, 0.008, 0.033, 0.009, 0.02, 0.01, 0.015, 0.013, 0.004, 0.011, 0.014, 0.006, 0.012, 0.031, 0.005, 0.009, 0.012, 0.012, 0.024, 0.009, 0.007, 0.009, 0.007, 0.019, 0.021, 0.017, 0.016, 0.037, 0.019, 0.018, 0.012, 0.015, 0.005, 0.026, 0.003, 0.01, 0.008, 0.015, 0.005, 0.011, 0.018, 0.008, 0.016, 0.036, 0.015, 0.013, 0.008, 0.015, 0.014, 0.01, 0.013, 0.009, 0.009, 0.017, 0.006, 0.017, 0.008, 0.01, 0.016, 0.004, 0.012, 0.011, 0.01, 0.009, 0.005, 0.011, 0.004, 0.015, 0.014, 0.01, 0.003, 0.015, 0.017, 0.016, 0.007]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:07:44] [0] \t\t #> Encoding 67 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 53.09it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1957.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:07:44] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:07:44] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:07:44] len(emb2pid) = 257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 145198.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:07:44] #> Saved optimized IVF to .ragatouille/colbert/indexes/tat_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:07:51] #> Loading codec...\n",
      "[Jul 29, 15:07:51] #> Loading IVF...\n",
      "[Jul 29, 15:07:51] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6584.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:07:51] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1536.94it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the difference between  Richard E. Belluzzo's total compensation as compared to Laura Black?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  4489,  2090,  2957,  1041,  1012,\n",
      "         4330, 17040,  6844,  1005,  1055,  2561,  9430,  2004,  4102,  2000,\n",
      "         6874,  2304,  1029,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:07:51 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': \"What is the difference between  Richard E. Belluzzo's total compensation as compared to Laura Black?\", 'response': \"The difference between Richard E. Belluzzo's total compensation and Laura Black's total compensation is $100,000.\\n The answer is: 100,000.\", 'doc': 'viavi-solutions-inc_2019', 'q_uid': 'f1b63dd3002720ebbffa8f36d852d351', 'answers': {'answer': 92500, 'answer_type': 'arithmetic', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:08:01] #> Loading codec...\n",
      "[Jul 29, 15:08:01] #> Loading IVF...\n",
      "[Jul 29, 15:08:01] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6260.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:08:01] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1642.89it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: How much did Donald Colvin earn in cash?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2129, 2172, 2106, 6221, 8902, 6371, 7796, 1999, 5356, 1029,\n",
      "         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:08:01 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'How much did Donald Colvin earn in cash?', 'response': 'Donald Colvin earned $1000 in cash.\\n The answer is: 1000.', 'doc': 'viavi-solutions-inc_2019', 'q_uid': 'd1a4ba4e1af05c60efa468f953a4f8ca', 'answers': {'answer': ['97,500'], 'answer_type': 'span', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:08:10] #> Loading codec...\n",
      "[Jul 29, 15:08:10] #> Loading IVF...\n",
      "[Jul 29, 15:08:10] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6384.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:08:10] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 734.81it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the percentage difference of the total compensation between Timothy Campos and Tor Braham?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  7017,  4489,  1997,  1996,  2561,\n",
      "         9430,  2090, 10805, 26925,  1998, 17153, 11655,  3511,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:08:10 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'What is the percentage difference of the total compensation between Timothy Campos and Tor Braham?', 'response': \"Timothy Campos's total compensation is $30000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", 'doc': 'viavi-solutions-inc_2019', 'q_uid': '5cff0439063c6a496073ce4b55591d0b', 'answers': {'answer': 4.07, 'answer_type': 'arithmetic', 'scale': 'percent'}}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:08:31] #> Note: Output directory .ragatouille/colbert/indexes/tat_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:08:31] #> Will delete 10 files already at .ragatouille/colbert/indexes/tat_vector_db in 20 seconds...\n",
      "[Jul 29, 15:08:54] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:08:54] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:08:54] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/tat_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0014s) to cluster 201 items into 128 clusters\n",
      "[0.008, 0.004, 0.004, 0.006, 0.004, 0.006, 0.005, 0.005, 0.015, 0.01, 0.005, 0.003, 0.005, 0.006, 0.011, 0.013, 0.008, 0.007, 0.008, 0.003, 0.006, 0.013, 0.007, 0.005, 0.004, 0.009, 0.006, 0.007, 0.004, 0.002, 0.006, 0.009, 0.008, 0.016, 0.006, 0.007, 0.006, 0.015, 0.004, 0.008, 0.005, 0.004, 0.008, 0.012, 0.01, 0.003, 0.005, 0.009, 0.009, 0.006, 0.002, 0.006, 0.007, 0.007, 0.011, 0.013, 0.006, 0.004, 0.005, 0.003, 0.01, 0.004, 0.008, 0.014, 0.006, 0.004, 0.006, 0.01, 0.009, 0.006, 0.006, 0.003, 0.006, 0.007, 0.005, 0.011, 0.005, 0.008, 0.009, 0.01, 0.009, 0.009, 0.013, 0.004, 0.011, 0.008, 0.009, 0.008, 0.007, 0.007, 0.004, 0.005, 0.012, 0.009, 0.008, 0.009, 0.009, 0.014, 0.009, 0.008, 0.007, 0.012, 0.011, 0.005, 0.007, 0.006, 0.009, 0.006, 0.011, 0.005, 0.004, 0.006, 0.007, 0.013, 0.008, 0.01, 0.008, 0.01, 0.003, 0.007, 0.006, 0.007, 0.004, 0.007, 0.012, 0.013, 0.005, 0.01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:08:54] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 66.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2528.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:08:54] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:08:54] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:08:54] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 159025.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:08:54] #> Saved optimized IVF to .ragatouille/colbert/indexes/tat_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:09:01] #> Loading codec...\n",
      "[Jul 29, 15:09:01] #> Loading IVF...\n",
      "[Jul 29, 15:09:01] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5511.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:09:01] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1085.20it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What does cash and cash equivalents consist of?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2515, 5356, 1998, 5356, 5662, 2015, 8676, 1997, 1029,\n",
      "         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:09:01 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'What does cash and cash equivalents consist of?', 'response': 'Cash and cash equivalents consist of money market instruments that can be converted into known amounts of cash and are highly liquid.\\n The answer is: money market instruments that can be converted into known amounts of cash.', 'doc': 'inpixon_2019', 'q_uid': 'c97f3158996e35cf911eec06d020badc', 'answers': {'answer': ['cash, checking accounts, money market accounts and temporary investments with maturities of three months or less when purchased.'], 'answer_type': 'span', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:09:11] #> Loading codec...\n",
      "[Jul 29, 15:09:11] #> Loading IVF...\n",
      "[Jul 29, 15:09:11] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6232.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:09:11] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1573.85it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What was the average Professional and legal fees for 2018 and 2019?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1996,  2779,  2658,  1998,  3423,  9883,\n",
      "         2005,  2760,  1998, 10476,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:09:11 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'What was the average Professional and legal fees for 2018 and 2019?', 'response': 'The average Professional and legal fees for 2018 and 2019 is $300000.00.\\n The answer is: 300000.00', 'doc': 'inpixon_2019', 'q_uid': 'd7d2b6427fb0f566a3ac2e90d842dd06', 'answers': {'answer': 393.5, 'answer_type': 'arithmetic', 'scale': 'thousand'}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:09:21] #> Loading codec...\n",
      "[Jul 29, 15:09:21] #> Loading IVF...\n",
      "[Jul 29, 15:09:21] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4993.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:09:21] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1220.34it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: How does the company account for options granted to employees?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2129, 2515, 1996, 2194, 4070, 2005, 7047, 4379, 2000, 5126,\n",
      "        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:09:21 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'How does the company account for options granted to employees?', 'response': 'The company accounts for options granted to employees by recording them as equity instruments on the balance sheet.\\n The answer is: Equity instruments.', 'doc': 'inpixon_2019', 'q_uid': 'fde5598a4f22f1775d27e488f367cdb7', 'answers': {'answer': ['by measuring the cost of services received in exchange for the award of equity instruments based upon the fair value of the award on the date of grant.'], 'answer_type': 'span', 'scale': ''}}\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/national-storage-reit_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cincinnati-bell-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/greencore-group-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/jabil-circuit-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cornerstone-ondemand-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/ichor-holdings-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/everbridge-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/network-1-technologies_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/xperi-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cts-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/Intu-Properties_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/siemens-ag_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/carpenter-technology-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/united-micro-electronics-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/on-semiconductor_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/consolidated-communications-holdings-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/Nextdc-Ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/black-knight-financial-services-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/brainstorm-cell-therapeutics_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/spirent-communications-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/proofpoint_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nordic-american-tankers-limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/par-technology-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/conagra-brands-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/stmicroelectronics_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/singapore-telecommunications-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/extreme-networks-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/logitech-international-sa_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cogent-communications-group-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/bce-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/westell-technologies-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/acura-pharmaceuticals-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/support-com_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nanthealth-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/travelzoo_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/square-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/allscripts-healthcare-solutions-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/agilysys-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/maxlinear-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/parkervision_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cisco-systems-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/methode-electronics-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/lam-research-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/international-business-machines-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/guidewire-software-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/globalscape-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/opentext-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/tyson-foods-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/csg-systems-international-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/unilever-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/mimecast-limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/mantech-international-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/netapp-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/godaddy-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/Woolworths-Limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/acacia-communications-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/freshpet-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/sykes-enterprises-incorporated_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/spirax-sarco-engineering-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/teradyne-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/resonant-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/taiwan-semiconductor-manufacturing-co-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/amcon-distributing-company_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/sealed-air-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/adtran-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/clearfield-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/quicklogic-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/frequency-electronics-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/leidos-holdings_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/te-connectivity-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/jack-henry-associates-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/mitek-systems_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/autodesk-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/chefs-wharehouse_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/protagenic-therapeutics-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/micron-technology-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/coherent-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/intel-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/avx-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nokia-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/zayo-group-holdings_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/ricebran-technologies_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/microchip-technology-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/sunpower-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/csp-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/tiger-brands-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cogeco-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/Auto-Trader_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/virnetx-holding-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/calamp-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/torm_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/first-solar-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/loral-space-communications-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/a10-networks-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/sunworks-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/fitbit-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/marks-and-spencer-group-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/kemet-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/marin-software-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/adobe-systems-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/altium-limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/immersion_2019.pdf\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:09:27] #> Note: Output directory .ragatouille/colbert/indexes/tat_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:09:28] #> Will delete 10 files already at .ragatouille/colbert/indexes/tat_vector_db in 20 seconds...\n",
      "[Jul 29, 15:09:51] [0] \t\t #> Encoding 78 passages..\n",
      "[Jul 29, 15:09:51] [0] \t\t avg_doclen_est = 3.846153736114502 \t len(local_sample) = 78\n",
      "[Jul 29, 15:09:51] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/tat_vector_db/plan.json ..\n",
      "Warning: number of training points (285) is less than the minimum recommended (2560)\n",
      "used 3 iterations (0.001s) to cluster 285 items into 256 clusters\n",
      "[0.005, 0.006, 0.01, 0.018, 0.008, 0.007, 0.009, 0.012, 0.002, 0.005, 0.007, 0.01, 0.001, 0.018, 0.014, 0.011, 0.009, 0.009, 0.005, 0.016, 0.007, 0.003, 0.006, 0.013, 0.002, 0.007, 0.02, 0.004, 0.005, 0.021, 0.009, 0.007, 0.013, 0.005, 0.009, 0.011, 0.007, 0.015, 0.014, 0.008, 0.003, 0.013, 0.016, 0.01, 0.004, 0.007, 0.016, 0.014, 0.01, 0.014, 0.013, 0.003, 0.01, 0.016, 0.004, 0.011, 0.004, 0.006, 0.01, 0.009, 0.006, 0.006, 0.01, 0.009, 0.006, 0.005, 0.011, 0.013, 0.009, 0.014, 0.005, 0.015, 0.014, 0.009, 0.003, 0.002, 0.009, 0.008, 0.006, 0.011, 0.011, 0.006, 0.009, 0.01, 0.004, 0.005, 0.019, 0.005, 0.007, 0.012, 0.014, 0.018, 0.004, 0.018, 0.005, 0.005, 0.015, 0.012, 0.023, 0.004, 0.016, 0.003, 0.007, 0.006, 0.005, 0.001, 0.002, 0.014, 0.005, 0.021, 0.006, 0.012, 0.019, 0.008, 0.005, 0.006, 0.006, 0.008, 0.007, 0.003, 0.008, 0.008, 0.008, 0.005, 0.005, 0.007, 0.005, 0.003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:09:51] [0] \t\t #> Encoding 78 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 49.79it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1958.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:09:51] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:09:51] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:09:51] len(emb2pid) = 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 134587.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:09:51] #> Saved optimized IVF to .ragatouille/colbert/indexes/tat_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:09:57] #> Loading codec...\n",
      "[Jul 29, 15:09:57] #> Loading IVF...\n",
      "[Jul 29, 15:09:57] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6316.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:09:57] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1556.91it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the average Net income for Years Ended December 31, 2018 to 2019?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2779,  5658,  3318,  2005,  2086,\n",
      "         3092,  2285,  2861,  1010,  2760,  2000, 10476,  1029,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:09:57 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'What is the average Net income for Years Ended December 31, 2018 to 2019?', 'response': 'The average Net income for the years ended December 31, 2018 to 2019 is $450,000.\\n The answer is: 450,000.', 'doc': 'overseas-shipholding-group-inc_2019', 'q_uid': 'ed78c51011874fe47d3910ab9794cce6', 'answers': {'answer': 11082, 'answer_type': 'arithmetic', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:10:13] #> Loading codec...\n",
      "[Jul 29, 15:10:13] #> Loading IVF...\n",
      "[Jul 29, 15:10:13] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5190.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:10:13] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1206.65it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the average Interest before impact of interest rate caps for Years Ended December 31, 2018 to 2019?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2779,  3037,  2077,  4254,  1997,\n",
      "         3037,  3446,  9700,  2005,  2086,  3092,  2285,  2861,  1010,  2760,\n",
      "         2000, 10476,  1029,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:10:13 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'What is the average Interest before impact of interest rate caps for Years Ended December 31, 2018 to 2019?', 'response': 'The average interest before impact of interest rate caps for years ended December 31, 2018 to 2019 is 12.67%.\\n The answer is: 12.67%', 'doc': 'overseas-shipholding-group-inc_2019', 'q_uid': '69977fcc3bdeb9ae684b21997c00ddab', 'answers': {'answer': 28171, 'answer_type': 'arithmetic', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:10:27] #> Loading codec...\n",
      "[Jul 29, 15:10:27] #> Loading IVF...\n",
      "[Jul 29, 15:10:27] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4514.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:10:27] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1474.27it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: In which year was Operating Leases greater than 100,000?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1999,  2029,  2095,  2001,  4082, 29597,  3618,  2084,\n",
      "         2531,  1010,  2199,  1029,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:10:27 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'In which year was Operating Leases greater than 100,000?', 'response': 'The answer is: 2019.\\n The answer is: 2019.', 'doc': 'overseas-shipholding-group-inc_2019', 'q_uid': 'ccc7a9080e0fea2e3181976dc634e30f', 'answers': {'answer': ['2022'], 'answer_type': 'span', 'scale': ''}}\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/telkonet-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/aci-worldwide-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/hc2-holdings-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/netgear-inc_2019.pdf\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:10:32] #> Note: Output directory .ragatouille/colbert/indexes/tat_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:10:32] #> Will delete 10 files already at .ragatouille/colbert/indexes/tat_vector_db in 20 seconds...\n",
      "[Jul 29, 15:10:57] [0] \t\t #> Encoding 65 passages..\n",
      "[Jul 29, 15:10:57] [0] \t\t avg_doclen_est = 3.8307693004608154 \t len(local_sample) = 65\n",
      "[Jul 29, 15:10:57] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/tat_vector_db/plan.json ..\n",
      "Warning: number of training points (237) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0012s) to cluster 237 items into 128 clusters\n",
      "[0.014, 0.004, 0.006, 0.006, 0.008, 0.008, 0.007, 0.008, 0.004, 0.009, 0.008, 0.012, 0.006, 0.016, 0.005, 0.007, 0.022, 0.01, 0.009, 0.015, 0.01, 0.01, 0.006, 0.01, 0.007, 0.012, 0.021, 0.005, 0.009, 0.009, 0.013, 0.004, 0.016, 0.008, 0.006, 0.014, 0.01, 0.007, 0.02, 0.014, 0.006, 0.012, 0.006, 0.009, 0.008, 0.005, 0.008, 0.013, 0.011, 0.009, 0.004, 0.011, 0.013, 0.013, 0.007, 0.011, 0.008, 0.01, 0.006, 0.006, 0.008, 0.009, 0.005, 0.013, 0.004, 0.009, 0.01, 0.011, 0.006, 0.019, 0.009, 0.015, 0.007, 0.005, 0.006, 0.013, 0.009, 0.015, 0.016, 0.013, 0.016, 0.013, 0.005, 0.011, 0.009, 0.009, 0.013, 0.008, 0.007, 0.009, 0.01, 0.008, 0.01, 0.01, 0.01, 0.008, 0.012, 0.006, 0.016, 0.006, 0.01, 0.009, 0.006, 0.005, 0.011, 0.007, 0.013, 0.008, 0.008, 0.019, 0.01, 0.007, 0.012, 0.016, 0.011, 0.013, 0.009, 0.008, 0.006, 0.007, 0.005, 0.004, 0.013, 0.007, 0.005, 0.006, 0.007, 0.013]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:10:57] [0] \t\t #> Encoding 65 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 56.68it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2323.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:10:57] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:10:57] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:10:57] len(emb2pid) = 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 165957.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:10:57] #> Saved optimized IVF to .ragatouille/colbert/indexes/tat_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:11:07] #> Loading codec...\n",
      "[Jul 29, 15:11:07] #> Loading IVF...\n",
      "[Jul 29, 15:11:07] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6403.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:11:07] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1615.06it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the symbol of the company's common stock that is listed on the Nasdaq Global Market?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  6454,  1997,  1996,  2194,  1005,\n",
      "         1055,  2691,  4518,  2008,  2003,  3205,  2006,  1996, 17235,  2850,\n",
      "         4160,  3795,  3006,  1029,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:11:07 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': \"What is the symbol of the company's common stock that is listed on the Nasdaq Global Market?\", 'response': 'The symbol of the company\\'s common stock that is listed on the Nasdaq Global Market is \"AAPL\".\\n The answer is: AAPL', 'doc': 'lifeway-foods-inc_2019', 'q_uid': '871af62021e2bd9a6ff15f9b1ba26d79', 'answers': {'answer': ['LWAY'], 'answer_type': 'span', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:11:19] #> Loading codec...\n",
      "[Jul 29, 15:11:19] #> Loading IVF...\n",
      "[Jul 29, 15:11:19] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6668.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:11:19] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1699.47it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the change in the value of brand names between 2018 and 2019?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2689,  1999,  1996,  3643,  1997,\n",
      "         4435,  3415,  2090,  2760,  1998, 10476,  1029,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:11:19 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'What is the change in the value of brand names between 2018 and 2019?', 'response': 'The change in the value of brand names between 2018 and 2019 is -10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000', 'doc': 'lifeway-foods-inc_2019', 'q_uid': 'ec84e524463dfd906ae9c37d739c610f', 'answers': {'answer': 0, 'answer_type': 'arithmetic', 'scale': ''}}\n",
      "Loading searcher for index tat_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:11:45] #> Loading codec...\n",
      "[Jul 29, 15:11:45] #> Loading IVF...\n",
      "[Jul 29, 15:11:45] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7133.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:11:45] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1683.78it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What was the low sale price per share for each quarters in 2018 in chronological order?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1996,  2659,  5096,  3976,  2566,  3745,\n",
      "         2005,  2169,  7728,  1999,  2760,  1999, 23472,  2344,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:11:45 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'What was the low sale price per share for each quarters in 2018 in chronological order?', 'response': 'The low sale price per share for each quarter in 2018 in chronological order is as follows:\\n- Q1: $10.00\\n- Q2: $12.00\\n- Q3: $14.00\\n- Q4: $16.00\\n\\nThe answer is: Q1: $10.00, Q2: $12.00, Q3: $14.00, Q4: $16.00', 'doc': 'lifeway-foods-inc_2019', 'q_uid': 'f4c8e2d0155ac338249d0fe6feba49ac', 'answers': {'answer': ['$ 5.99', '$ 4.79', '$ 2.66', '$ 1.88'], 'answer_type': 'multi-span', 'scale': ''}}\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/george-weston-limited_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/verizon-communications-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/zendesk_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/quotient-technology-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/optimizerx-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/metro-ag_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/atlassian-corp-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cubic-corp_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/commvault-systems-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/neonode-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/macom-technology_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/greensky-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/rogers-communications-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nortonlifelock-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/shopify-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/pegasystems-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/microsoft-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/oracle-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/american-tower-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/accenture-plc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/cal-maine-foods-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/tencent_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/alarmcom-holdings-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/activision-blizzard-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/teekay-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/insight-enterprises-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/maple-leaf-foods-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/golar-lng-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/zix-corporation_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/gsi-technology-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/tata-consultancy-services-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/finjan-holding-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/mobileiron-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/nielsen-nv_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/gaslog-ltd_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/jack-in-the-box-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/avalara_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/luna-innovations-incorporated_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/centurylink-inc_2019.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/tat_docs/bt-group-plc_2019.pdf\n",
      "=== Finish tat ===\n",
      "\n",
      "=== Start paper_text on meno-tiny ===\n",
      "2025-07-29 15:11:55 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:11:55,446 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:11:59 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:12:01] #> Creating directory .ragatouille/colbert/indexes/paper_text_vector_db \n",
      "\n",
      "\n",
      "[Jul 29, 15:12:05] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:12:05] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:12:05] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_text_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.001s) to cluster 201 items into 128 clusters\n",
      "[0.011, 0.013, 0.003, 0.011, 0.015, 0.007, 0.007, 0.005, 0.033, 0.016, 0.011, 0.007, 0.011, 0.007, 0.009, 0.02, 0.01, 0.004, 0.006, 0.02, 0.013, 0.028, 0.009, 0.004, 0.014, 0.008, 0.006, 0.005, 0.012, 0.006, 0.008, 0.007, 0.006, 0.027, 0.011, 0.007, 0.018, 0.014, 0.012, 0.017, 0.004, 0.004, 0.006, 0.011, 0.009, 0.015, 0.012, 0.003, 0.025, 0.004, 0.009, 0.003, 0.013, 0.008, 0.024, 0.016, 0.008, 0.019, 0.014, 0.015, 0.017, 0.008, 0.008, 0.019, 0.005, 0.017, 0.006, 0.01, 0.013, 0.011, 0.006, 0.008, 0.01, 0.003, 0.008, 0.007, 0.02, 0.014, 0.013, 0.005, 0.007, 0.007, 0.008, 0.008, 0.004, 0.007, 0.004, 0.026, 0.006, 0.008, 0.012, 0.017, 0.009, 0.008, 0.005, 0.006, 0.004, 0.012, 0.005, 0.007, 0.012, 0.013, 0.015, 0.003, 0.017, 0.017, 0.01, 0.017, 0.013, 0.002, 0.011, 0.005, 0.018, 0.014, 0.007, 0.011, 0.005, 0.015, 0.006, 0.014, 0.004, 0.004, 0.007, 0.009, 0.007, 0.024, 0.004, 0.009]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:12:05] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 71.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2695.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:12:05] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:12:05] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:12:05] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 165598.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:12:05] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_text_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_text_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:12:13] #> Loading codec...\n",
      "[Jul 29, 15:12:13] #> Loading IVF...\n",
      "[Jul 29, 15:12:13] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4766.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:12:13] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1577.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: Do they perform error analysis?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2079, 2027, 4685, 7561, 4106, 1029,  102,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:12:13 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'Do they perform error analysis?', 'response': 'The answer is: No.', 'doc': '2001.03131', 'q_uid': '133eb4aa4394758be5f41744c60c99901b2bc01c', 'answers': [{'answer': 'No', 'type': 'boolean'}, {'answer': 'No', 'type': 'boolean'}]}\n",
      "Loading searcher for index paper_text_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:12:19] #> Loading codec...\n",
      "[Jul 29, 15:12:19] #> Loading IVF...\n",
      "[Jul 29, 15:12:19] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6223.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:12:19] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1781.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the Random Kitchen Sink approach?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2003, 1996, 6721, 3829, 7752, 3921, 1029,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:12:19 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'What is the Random Kitchen Sink approach?', 'response': 'The Random Kitchen Sink approach is a method of cooking that involves randomly selecting ingredients and cooking them together without following a specific recipe.', 'doc': '2001.03131', 'q_uid': 'a778b8204a415b295f73b93623d09599f242f202', 'answers': [{'answer': 'Random Kitchen Sink method uses a kernel function to map data vectors to a space where linear separation is possible.', 'type': 'abstractive'}, {'answer': 'explicitly maps data vectors to a space where linear separation is possible, RKS method provides an approximate kernel function via explicit mapping', 'type': 'extractive'}]}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:12:21] #> Note: Output directory .ragatouille/colbert/indexes/paper_text_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:12:21] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_text_vector_db in 20 seconds...\n",
      "[Jul 29, 15:12:44] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:12:44] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:12:44] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_text_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 4 iterations (0.0013s) to cluster 201 items into 128 clusters\n",
      "[0.011, 0.013, 0.003, 0.011, 0.015, 0.007, 0.007, 0.005, 0.033, 0.016, 0.011, 0.007, 0.011, 0.007, 0.009, 0.02, 0.01, 0.004, 0.006, 0.02, 0.013, 0.028, 0.009, 0.004, 0.014, 0.008, 0.006, 0.005, 0.012, 0.006, 0.008, 0.007, 0.006, 0.027, 0.011, 0.007, 0.018, 0.014, 0.012, 0.017, 0.004, 0.004, 0.006, 0.011, 0.009, 0.015, 0.012, 0.003, 0.025, 0.004, 0.009, 0.003, 0.013, 0.008, 0.024, 0.016, 0.008, 0.019, 0.014, 0.015, 0.017, 0.008, 0.008, 0.019, 0.005, 0.017, 0.006, 0.01, 0.013, 0.011, 0.006, 0.008, 0.01, 0.003, 0.008, 0.007, 0.02, 0.014, 0.013, 0.005, 0.007, 0.007, 0.008, 0.008, 0.004, 0.007, 0.004, 0.026, 0.006, 0.008, 0.012, 0.017, 0.009, 0.008, 0.005, 0.006, 0.004, 0.012, 0.005, 0.007, 0.012, 0.013, 0.015, 0.003, 0.017, 0.017, 0.01, 0.017, 0.013, 0.002, 0.011, 0.005, 0.018, 0.014, 0.007, 0.011, 0.005, 0.015, 0.006, 0.014, 0.004, 0.004, 0.007, 0.009, 0.007, 0.024, 0.004, 0.009]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:12:44] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 78.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2592.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:12:44] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:12:44] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:12:44] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 167405.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:12:44] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_text_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_text_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:12:51] #> Loading codec...\n",
      "[Jul 29, 15:12:51] #> Loading IVF...\n",
      "[Jul 29, 15:12:51] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6159.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:12:51] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1143.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: how are multiple answers from multiple reformulated questions aggregated?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2129, 2024, 3674, 6998, 2013, 3674, 5290, 8898, 3980, 9572,\n",
      "        2094, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:12:51 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'how are multiple answers from multiple reformulated questions aggregated?', 'response': 'The answer is: The aggregation of multiple answers from multiple reformulated questions is not specified in the given text.', 'doc': '1705.07830', 'q_uid': '33d2919f3400cd3c6fbb6960d74187ec80b41cd6', 'answers': [{'answer': 'The selection model selects the best answer from the set $\\\\lbrace a_i\\\\rbrace _{i=1}^N$ observed during the interaction by predicting the difference of the F1 score to the average F1 of all variants.', 'type': 'extractive'}]}\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11189.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.02906.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.07333.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1710.09753.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03788.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09587.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.06378.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.07512.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03762.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1612.09113.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08673.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.08370.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01673.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.12801.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.05437.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1706.00139.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.01433.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.11901.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01320.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.01400.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.06927.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08090.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.10367.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1607.00410.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.05963.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.07481.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03385.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1801.07804.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1503.00841.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.02962.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11047.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1610.04377.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.07228.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05360.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.02492.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03135.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.05241.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.02988.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03925.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.08899.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.01060.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.03902.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.11136.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.09314.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.09029.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.03627.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1710.06700.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.05828.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.11907.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.06813.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.06762.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.09722.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.03125.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.12738.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.07625.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08041.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.07814.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05855.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.02451.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1708.06185.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.02271.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.07791.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.11437.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01252.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.12795.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.01512.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.06424.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.06757.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.05284.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09067.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.01294.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.05036.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.00530.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.07218.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.03738.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.02233.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.10551.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.07976.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.09708.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.10012.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.04433.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.03014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.09684.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08306.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.00722.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03584.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.06701.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.11365.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01093.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06556.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11860.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.10084.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00124.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.00819.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.02070.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.02357.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.12642.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.04553.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.09637.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.06279.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.08559.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.08772.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.12579.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1706.06894.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.08098.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1604.00727.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.01576.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1708.00214.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.02815.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.06671.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08829.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.08188.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.02013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.00547.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.05574.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.04631.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.13109.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.01694.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.06083.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.08868.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1702.06777.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.04032.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.04085.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.09194.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.00854.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.01265.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.03438.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.02380.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.11942.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.05664.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08752.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.00330.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.05411.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.09301.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.04457.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.05711.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09534.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.02334.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.09951.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.03710.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.11180.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01046.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.00995.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.04917.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.06964.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.09633.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.05902.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.02761.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.01183.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.00968.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1702.03274.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09779.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1610.03112.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13717.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.05581.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.05608.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03059.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03634.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.07090.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.07863.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.04625.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06151.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.06200.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.11049.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13375.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1708.09609.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.07513.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1702.01517.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.11346.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.00194.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.03191.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.02083.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.10869.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.13072.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.06118.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.10113.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.06171.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.09586.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1803.05223.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.01341.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.04181.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.02908.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.01413.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.09588.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.06843.pdf\n",
      "=== Start paper_text on qwen2.5-1.5B ===\n",
      "2025-07-29 15:12:51 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:12:52,015 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:12:55 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:12:58] #> Note: Output directory .ragatouille/colbert/indexes/paper_text_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:12:58] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_text_vector_db in 20 seconds...\n",
      "[Jul 29, 15:13:20] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:13:20] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:13:20] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_text_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0015s) to cluster 201 items into 128 clusters\n",
      "[0.011, 0.013, 0.003, 0.011, 0.015, 0.007, 0.007, 0.005, 0.033, 0.016, 0.011, 0.007, 0.011, 0.007, 0.009, 0.02, 0.01, 0.004, 0.006, 0.02, 0.013, 0.028, 0.009, 0.004, 0.014, 0.008, 0.006, 0.005, 0.012, 0.006, 0.008, 0.007, 0.006, 0.027, 0.011, 0.007, 0.018, 0.014, 0.012, 0.017, 0.004, 0.004, 0.006, 0.011, 0.009, 0.015, 0.012, 0.003, 0.025, 0.004, 0.009, 0.003, 0.013, 0.008, 0.024, 0.016, 0.008, 0.019, 0.014, 0.015, 0.017, 0.008, 0.008, 0.019, 0.005, 0.017, 0.006, 0.01, 0.013, 0.011, 0.006, 0.008, 0.01, 0.003, 0.008, 0.007, 0.02, 0.014, 0.013, 0.005, 0.007, 0.007, 0.008, 0.008, 0.004, 0.007, 0.004, 0.026, 0.006, 0.008, 0.012, 0.017, 0.009, 0.008, 0.005, 0.006, 0.004, 0.012, 0.005, 0.007, 0.012, 0.013, 0.015, 0.003, 0.017, 0.017, 0.01, 0.017, 0.013, 0.002, 0.011, 0.005, 0.018, 0.014, 0.007, 0.011, 0.005, 0.015, 0.006, 0.014, 0.004, 0.004, 0.007, 0.009, 0.007, 0.024, 0.004, 0.009]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:13:20] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 76.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2516.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:13:20] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:13:20] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:13:20] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 84162.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:13:20] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_text_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_text_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:13:26] #> Loading codec...\n",
      "[Jul 29, 15:13:26] #> Loading IVF...\n",
      "[Jul 29, 15:13:26] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11397.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:13:26] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1542.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: Do they perform error analysis?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2079, 2027, 4685, 7561, 4106, 1029,  102,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:13:26 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'Do they perform error analysis?', 'response': 'No, they do not perform error analysis.', 'doc': '2001.03131', 'q_uid': '133eb4aa4394758be5f41744c60c99901b2bc01c', 'answers': [{'answer': 'No', 'type': 'boolean'}, {'answer': 'No', 'type': 'boolean'}]}\n",
      "Loading searcher for index paper_text_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:13:32] #> Loading codec...\n",
      "[Jul 29, 15:13:32] #> Loading IVF...\n",
      "[Jul 29, 15:13:32] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5282.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:13:33] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1763.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the Random Kitchen Sink approach?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2003, 1996, 6721, 3829, 7752, 3921, 1029,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:13:33 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'What is the Random Kitchen Sink approach?', 'response': 'The Random Kitchen Sink approach is a method for generating random data by combining multiple sources or \"kitchen sinks\".', 'doc': '2001.03131', 'q_uid': 'a778b8204a415b295f73b93623d09599f242f202', 'answers': [{'answer': 'Random Kitchen Sink method uses a kernel function to map data vectors to a space where linear separation is possible.', 'type': 'abstractive'}, {'answer': 'explicitly maps data vectors to a space where linear separation is possible, RKS method provides an approximate kernel function via explicit mapping', 'type': 'extractive'}]}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:13:35] #> Note: Output directory .ragatouille/colbert/indexes/paper_text_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:13:35] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_text_vector_db in 20 seconds...\n",
      "[Jul 29, 15:13:58] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:13:58] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:13:58] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_text_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 4 iterations (0.0014s) to cluster 201 items into 128 clusters\n",
      "[0.011, 0.013, 0.003, 0.011, 0.015, 0.007, 0.007, 0.005, 0.033, 0.016, 0.011, 0.007, 0.011, 0.007, 0.009, 0.02, 0.01, 0.004, 0.006, 0.02, 0.013, 0.028, 0.009, 0.004, 0.014, 0.008, 0.006, 0.005, 0.012, 0.006, 0.008, 0.007, 0.006, 0.027, 0.011, 0.007, 0.018, 0.014, 0.012, 0.017, 0.004, 0.004, 0.006, 0.011, 0.009, 0.015, 0.012, 0.003, 0.025, 0.004, 0.009, 0.003, 0.013, 0.008, 0.024, 0.016, 0.008, 0.019, 0.014, 0.015, 0.017, 0.008, 0.008, 0.019, 0.005, 0.017, 0.006, 0.01, 0.013, 0.011, 0.006, 0.008, 0.01, 0.003, 0.008, 0.007, 0.02, 0.014, 0.013, 0.005, 0.007, 0.007, 0.008, 0.008, 0.004, 0.007, 0.004, 0.026, 0.006, 0.008, 0.012, 0.017, 0.009, 0.008, 0.005, 0.006, 0.004, 0.012, 0.005, 0.007, 0.012, 0.013, 0.015, 0.003, 0.017, 0.017, 0.01, 0.017, 0.013, 0.002, 0.011, 0.005, 0.018, 0.014, 0.007, 0.011, 0.005, 0.015, 0.006, 0.014, 0.004, 0.004, 0.007, 0.009, 0.007, 0.024, 0.004, 0.009]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:13:58] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 65.17it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1953.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:13:58] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:13:58] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:13:58] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 100424.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:13:58] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_text_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_text_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:14:04] #> Loading codec...\n",
      "[Jul 29, 15:14:04] #> Loading IVF...\n",
      "[Jul 29, 15:14:04] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6898.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:14:04] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1880.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: how are multiple answers from multiple reformulated questions aggregated?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2129, 2024, 3674, 6998, 2013, 3674, 5290, 8898, 3980, 9572,\n",
      "        2094, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:14:04 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'how are multiple answers from multiple reformulated questions aggregated?', 'response': 'The answer is: By combining all responses into one list.', 'doc': '1705.07830', 'q_uid': '33d2919f3400cd3c6fbb6960d74187ec80b41cd6', 'answers': [{'answer': 'The selection model selects the best answer from the set $\\\\lbrace a_i\\\\rbrace _{i=1}^N$ observed during the interaction by predicting the difference of the F1 score to the average F1 of all variants.', 'type': 'extractive'}]}\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11189.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.02906.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.07333.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1710.09753.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03788.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09587.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.06378.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.07512.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03762.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1612.09113.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08673.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.08370.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01673.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.12801.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.05437.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1706.00139.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.01433.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.11901.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01320.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.01400.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.06927.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08090.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.10367.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1607.00410.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.05963.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.07481.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03385.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1801.07804.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1503.00841.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.02962.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11047.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1610.04377.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.07228.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05360.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.02492.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03135.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.05241.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.02988.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03925.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.08899.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.01060.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.03902.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.11136.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.09314.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.09029.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.03627.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1710.06700.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.05828.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.11907.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.06813.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.06762.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.09722.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.03125.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.12738.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.07625.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08041.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.07814.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05855.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.02451.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1708.06185.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.02271.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.07791.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.11437.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01252.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.12795.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.01512.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.06424.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.06757.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.05284.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09067.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.01294.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.05036.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.00530.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.07218.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.03738.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.02233.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.10551.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.07976.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.09708.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.10012.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.04433.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.03014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.09684.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08306.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.00722.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03584.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.06701.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.11365.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01093.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06556.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11860.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.10084.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00124.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.00819.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.02070.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.02357.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.12642.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.04553.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.09637.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.06279.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.08559.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.08772.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.12579.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1706.06894.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.08098.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1604.00727.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.01576.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1708.00214.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.02815.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.06671.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08829.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.08188.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.02013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.00547.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.05574.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.04631.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.13109.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.01694.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.06083.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.08868.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1702.06777.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.04032.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.04085.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.09194.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.00854.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.01265.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.03438.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.02380.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.11942.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.05664.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08752.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.00330.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.05411.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.09301.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.04457.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.05711.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09534.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.02334.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.09951.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.03710.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.11180.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01046.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.00995.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.04917.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.06964.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.09633.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.05902.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.02761.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.01183.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.00968.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1702.03274.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09779.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1610.03112.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13717.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.05581.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.05608.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03059.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03634.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.07090.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.07863.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.04625.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06151.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.06200.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.11049.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13375.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1708.09609.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.07513.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1702.01517.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.11346.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.00194.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.03191.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.02083.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.10869.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.13072.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.06118.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.10113.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.06171.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.09586.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1803.05223.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.01341.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.04181.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.02908.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.01413.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.09588.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.06843.pdf\n",
      "=== Start paper_text on qwen2.5-3B ===\n",
      "2025-07-29 15:14:04 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:14:05,187 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.04s/it]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:14:12 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:14:15] #> Note: Output directory .ragatouille/colbert/indexes/paper_text_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:14:15] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_text_vector_db in 20 seconds...\n",
      "[Jul 29, 15:14:38] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:14:38] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:14:38] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_text_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.003s) to cluster 201 items into 128 clusters\n",
      "[0.011, 0.013, 0.003, 0.011, 0.015, 0.007, 0.007, 0.005, 0.033, 0.016, 0.011, 0.007, 0.011, 0.007, 0.009, 0.02, 0.01, 0.004, 0.006, 0.02, 0.013, 0.028, 0.009, 0.004, 0.014, 0.008, 0.006, 0.005, 0.012, 0.006, 0.008, 0.007, 0.006, 0.027, 0.011, 0.007, 0.018, 0.014, 0.012, 0.017, 0.004, 0.004, 0.006, 0.011, 0.009, 0.015, 0.012, 0.003, 0.025, 0.004, 0.009, 0.003, 0.013, 0.008, 0.024, 0.016, 0.008, 0.019, 0.014, 0.015, 0.017, 0.008, 0.008, 0.019, 0.005, 0.017, 0.006, 0.01, 0.013, 0.011, 0.006, 0.008, 0.01, 0.003, 0.008, 0.007, 0.02, 0.014, 0.013, 0.005, 0.007, 0.007, 0.008, 0.008, 0.004, 0.007, 0.004, 0.026, 0.006, 0.008, 0.012, 0.017, 0.009, 0.008, 0.005, 0.006, 0.004, 0.012, 0.005, 0.007, 0.012, 0.013, 0.015, 0.003, 0.017, 0.017, 0.01, 0.017, 0.013, 0.002, 0.011, 0.005, 0.018, 0.014, 0.007, 0.011, 0.005, 0.015, 0.006, 0.014, 0.004, 0.004, 0.007, 0.009, 0.007, 0.024, 0.004, 0.009]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:14:38] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 56.04it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2074.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:14:38] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:14:38] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:14:38] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 57505.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:14:38] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_text_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_text_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:14:44] #> Loading codec...\n",
      "[Jul 29, 15:14:44] #> Loading IVF...\n",
      "[Jul 29, 15:14:44] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5785.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:14:44] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1175.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: Do they perform error analysis?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2079, 2027, 4685, 7561, 4106, 1029,  102,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:14:44 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'Do they perform error analysis?', 'response': 'The answer is: No', 'doc': '2001.03131', 'q_uid': '133eb4aa4394758be5f41744c60c99901b2bc01c', 'answers': [{'answer': 'No', 'type': 'boolean'}, {'answer': 'No', 'type': 'boolean'}]}\n",
      "Loading searcher for index paper_text_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:14:50] #> Loading codec...\n",
      "[Jul 29, 15:14:50] #> Loading IVF...\n",
      "[Jul 29, 15:14:50] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4490.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:14:50] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1902.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the Random Kitchen Sink approach?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2003, 1996, 6721, 3829, 7752, 3921, 1029,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:14:50 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'What is the Random Kitchen Sink approach?', 'response': 'The answer is: A method for generating random inputs used in testing machine learning models', 'doc': '2001.03131', 'q_uid': 'a778b8204a415b295f73b93623d09599f242f202', 'answers': [{'answer': 'Random Kitchen Sink method uses a kernel function to map data vectors to a space where linear separation is possible.', 'type': 'abstractive'}, {'answer': 'explicitly maps data vectors to a space where linear separation is possible, RKS method provides an approximate kernel function via explicit mapping', 'type': 'extractive'}]}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:14:53] #> Note: Output directory .ragatouille/colbert/indexes/paper_text_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:14:53] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_text_vector_db in 20 seconds...\n",
      "[Jul 29, 15:15:16] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:15:16] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:15:16] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_text_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 4 iterations (0.0014s) to cluster 201 items into 128 clusters\n",
      "[0.011, 0.013, 0.003, 0.011, 0.015, 0.007, 0.007, 0.005, 0.033, 0.016, 0.011, 0.007, 0.011, 0.007, 0.009, 0.02, 0.01, 0.004, 0.006, 0.02, 0.013, 0.028, 0.009, 0.004, 0.014, 0.008, 0.006, 0.005, 0.012, 0.006, 0.008, 0.007, 0.006, 0.027, 0.011, 0.007, 0.018, 0.014, 0.012, 0.017, 0.004, 0.004, 0.006, 0.011, 0.009, 0.015, 0.012, 0.003, 0.025, 0.004, 0.009, 0.003, 0.013, 0.008, 0.024, 0.016, 0.008, 0.019, 0.014, 0.015, 0.017, 0.008, 0.008, 0.019, 0.005, 0.017, 0.006, 0.01, 0.013, 0.011, 0.006, 0.008, 0.01, 0.003, 0.008, 0.007, 0.02, 0.014, 0.013, 0.005, 0.007, 0.007, 0.008, 0.008, 0.004, 0.007, 0.004, 0.026, 0.006, 0.008, 0.012, 0.017, 0.009, 0.008, 0.005, 0.006, 0.004, 0.012, 0.005, 0.007, 0.012, 0.013, 0.015, 0.003, 0.017, 0.017, 0.01, 0.017, 0.013, 0.002, 0.011, 0.005, 0.018, 0.014, 0.007, 0.011, 0.005, 0.015, 0.006, 0.014, 0.004, 0.004, 0.007, 0.009, 0.007, 0.024, 0.004, 0.009]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:15:16] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 73.73it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1978.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:15:16] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:15:16] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:15:16] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 159545.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:15:16] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_text_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_text_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:15:22] #> Loading codec...\n",
      "[Jul 29, 15:15:22] #> Loading IVF...\n",
      "[Jul 29, 15:15:22] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6288.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:15:22] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1481.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: how are multiple answers from multiple reformulated questions aggregated?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2129, 2024, 3674, 6998, 2013, 3674, 5290, 8898, 3980, 9572,\n",
      "        2094, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:15:22 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'how are multiple answers from multiple reformulated questions aggregated?', 'response': 'The answer is: not provided in the given context', 'doc': '1705.07830', 'q_uid': '33d2919f3400cd3c6fbb6960d74187ec80b41cd6', 'answers': [{'answer': 'The selection model selects the best answer from the set $\\\\lbrace a_i\\\\rbrace _{i=1}^N$ observed during the interaction by predicting the difference of the F1 score to the average F1 of all variants.', 'type': 'extractive'}]}\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11189.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.02906.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.07333.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1710.09753.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03788.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09587.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.06378.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.07512.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03762.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1612.09113.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08673.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.08370.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01673.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.12801.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.05437.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1706.00139.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.01433.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.11901.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01320.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.01400.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.06927.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08090.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.10367.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1607.00410.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.05963.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.07481.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03385.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1801.07804.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1503.00841.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.02962.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11047.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1610.04377.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.07228.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05360.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.02492.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03135.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.05241.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.02988.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03925.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.08899.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.01060.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.03902.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.11136.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.09314.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.09029.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.03627.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1710.06700.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.05828.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.11907.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.06813.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.06762.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.09722.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.03125.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.12738.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.07625.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08041.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.07814.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05855.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.02451.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1708.06185.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.02271.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.07791.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.11437.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01252.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.12795.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.01512.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.06424.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.06757.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.05284.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09067.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.01294.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.05036.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.00530.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.07218.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.03738.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.02233.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.10551.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.07976.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.09708.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.10012.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.04433.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.03014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.09684.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08306.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.00722.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03584.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.06701.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.11365.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01093.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06556.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11860.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.10084.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00124.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.00819.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.02070.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.02357.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.12642.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.04553.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.09637.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.06279.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.08559.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.08772.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.12579.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1706.06894.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.08098.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1604.00727.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.01576.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1708.00214.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.02815.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.06671.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08829.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.08188.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.02013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.00547.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.05574.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.04631.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.13109.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.01694.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.06083.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.08868.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1702.06777.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.04032.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.04085.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.09194.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.00854.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.01265.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.03438.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.02380.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.11942.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.05664.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08752.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.00330.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.05411.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.09301.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.04457.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.05711.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09534.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.02334.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.09951.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.03710.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.11180.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01046.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.00995.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.04917.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.06964.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.09633.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.05902.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.02761.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.01183.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.00968.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1702.03274.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09779.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1610.03112.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13717.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.05581.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.05608.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03059.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03634.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.07090.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.07863.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.04625.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06151.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.06200.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.11049.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13375.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1708.09609.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.07513.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1702.01517.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.11346.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.00194.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.03191.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.02083.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.10869.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.13072.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.06118.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.10113.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.06171.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.09586.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1803.05223.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.01341.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.04181.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.02908.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.01413.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.09588.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.06843.pdf\n",
      "=== Start paper_text on falcon-e-3B ===\n",
      "2025-07-29 15:15:22 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:15:23,175 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:15:25 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:15:27] #> Note: Output directory .ragatouille/colbert/indexes/paper_text_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:15:27] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_text_vector_db in 20 seconds...\n",
      "[Jul 29, 15:15:50] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:15:50] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:15:50] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_text_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.001s) to cluster 201 items into 128 clusters\n",
      "[0.011, 0.013, 0.003, 0.011, 0.015, 0.007, 0.007, 0.005, 0.033, 0.016, 0.011, 0.007, 0.011, 0.007, 0.009, 0.02, 0.01, 0.004, 0.006, 0.02, 0.013, 0.028, 0.009, 0.004, 0.014, 0.008, 0.006, 0.005, 0.012, 0.006, 0.008, 0.007, 0.006, 0.027, 0.011, 0.007, 0.018, 0.014, 0.012, 0.017, 0.004, 0.004, 0.006, 0.011, 0.009, 0.015, 0.012, 0.003, 0.025, 0.004, 0.009, 0.003, 0.013, 0.008, 0.024, 0.016, 0.008, 0.019, 0.014, 0.015, 0.017, 0.008, 0.008, 0.019, 0.005, 0.017, 0.006, 0.01, 0.013, 0.011, 0.006, 0.008, 0.01, 0.003, 0.008, 0.007, 0.02, 0.014, 0.013, 0.005, 0.007, 0.007, 0.008, 0.008, 0.004, 0.007, 0.004, 0.026, 0.006, 0.008, 0.012, 0.017, 0.009, 0.008, 0.005, 0.006, 0.004, 0.012, 0.005, 0.007, 0.012, 0.013, 0.015, 0.003, 0.017, 0.017, 0.01, 0.017, 0.013, 0.002, 0.011, 0.005, 0.018, 0.014, 0.007, 0.011, 0.005, 0.015, 0.006, 0.014, 0.004, 0.004, 0.007, 0.009, 0.007, 0.024, 0.004, 0.009]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:15:50] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 69.79it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2080.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:15:50] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:15:50] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:15:50] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 162098.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:15:50] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_text_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_text_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:15:56] #> Loading codec...\n",
      "[Jul 29, 15:15:56] #> Loading IVF...\n",
      "[Jul 29, 15:15:56] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5329.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:15:56] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1548.28it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: Do they perform error analysis?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2079, 2027, 4685, 7561, 4106, 1029,  102,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:15:56 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'Do they perform error analysis?', 'response': 'The answer is: Yes, they perform error analysis.', 'doc': '2001.03131', 'q_uid': '133eb4aa4394758be5f41744c60c99901b2bc01c', 'answers': [{'answer': 'No', 'type': 'boolean'}, {'answer': 'No', 'type': 'boolean'}]}\n",
      "Loading searcher for index paper_text_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:16:03] #> Loading codec...\n",
      "[Jul 29, 15:16:03] #> Loading IVF...\n",
      "[Jul 29, 15:16:03] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6078.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:16:03] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1850.97it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What is the Random Kitchen Sink approach?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2003, 1996, 6721, 3829, 7752, 3921, 1029,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:16:03 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'What is the Random Kitchen Sink approach?', 'response': 'The answer is: It is a method that involves using a variety of techniques and approaches to solve problems, often without a clear structure or framework.', 'doc': '2001.03131', 'q_uid': 'a778b8204a415b295f73b93623d09599f242f202', 'answers': [{'answer': 'Random Kitchen Sink method uses a kernel function to map data vectors to a space where linear separation is possible.', 'type': 'abstractive'}, {'answer': 'explicitly maps data vectors to a space where linear separation is possible, RKS method provides an approximate kernel function via explicit mapping', 'type': 'extractive'}]}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:16:08] #> Note: Output directory .ragatouille/colbert/indexes/paper_text_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:16:08] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_text_vector_db in 20 seconds...\n",
      "[Jul 29, 15:16:31] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:16:31] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:16:31] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_text_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 4 iterations (0.0012s) to cluster 201 items into 128 clusters\n",
      "[0.011, 0.013, 0.003, 0.011, 0.015, 0.007, 0.007, 0.005, 0.033, 0.016, 0.011, 0.007, 0.011, 0.007, 0.009, 0.02, 0.01, 0.004, 0.006, 0.02, 0.013, 0.028, 0.009, 0.004, 0.014, 0.008, 0.006, 0.005, 0.012, 0.006, 0.008, 0.007, 0.006, 0.027, 0.011, 0.007, 0.018, 0.014, 0.012, 0.017, 0.004, 0.004, 0.006, 0.011, 0.009, 0.015, 0.012, 0.003, 0.025, 0.004, 0.009, 0.003, 0.013, 0.008, 0.024, 0.016, 0.008, 0.019, 0.014, 0.015, 0.017, 0.008, 0.008, 0.019, 0.005, 0.017, 0.006, 0.01, 0.013, 0.011, 0.006, 0.008, 0.01, 0.003, 0.008, 0.007, 0.02, 0.014, 0.013, 0.005, 0.007, 0.007, 0.008, 0.008, 0.004, 0.007, 0.004, 0.026, 0.006, 0.008, 0.012, 0.017, 0.009, 0.008, 0.005, 0.006, 0.004, 0.012, 0.005, 0.007, 0.012, 0.013, 0.015, 0.003, 0.017, 0.017, 0.01, 0.017, 0.013, 0.002, 0.011, 0.005, 0.018, 0.014, 0.007, 0.011, 0.005, 0.015, 0.006, 0.014, 0.004, 0.004, 0.007, 0.009, 0.007, 0.024, 0.004, 0.009]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:16:31] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 76.21it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2198.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:16:31] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:16:31] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:16:31] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 157856.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:16:31] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_text_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_text_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:16:37] #> Loading codec...\n",
      "[Jul 29, 15:16:37] #> Loading IVF...\n",
      "[Jul 29, 15:16:37] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 9619.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:16:37] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1754.94it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: how are multiple answers from multiple reformulated questions aggregated?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2129, 2024, 3674, 6998, 2013, 3674, 5290, 8898, 3980, 9572,\n",
      "        2094, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:16:37 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'how are multiple answers from multiple reformulated questions aggregated?', 'response': 'The answer is: They are combined into one single answer.', 'doc': '1705.07830', 'q_uid': '33d2919f3400cd3c6fbb6960d74187ec80b41cd6', 'answers': [{'answer': 'The selection model selects the best answer from the set $\\\\lbrace a_i\\\\rbrace _{i=1}^N$ observed during the interaction by predicting the difference of the F1 score to the average F1 of all variants.', 'type': 'extractive'}]}\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11189.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.02906.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.07333.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1710.09753.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03788.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09587.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.06378.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.07512.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03762.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1612.09113.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08673.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.08370.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01673.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.12801.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.05437.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1706.00139.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.01433.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.11901.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01320.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.01400.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.06927.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08090.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.10367.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1607.00410.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.05963.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.07481.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03385.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1801.07804.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1503.00841.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.02962.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11047.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1610.04377.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.07228.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05360.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.02492.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03135.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.05241.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.02988.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03925.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.08899.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.01060.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.03902.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.11136.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.09314.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.09029.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.03627.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1710.06700.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.05828.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.11907.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.06813.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.06762.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.09722.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.03125.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.12738.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.07625.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08041.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.07814.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05855.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.02451.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1708.06185.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.02271.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.07791.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.11437.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01252.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.12795.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.01512.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.06424.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.06757.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.05284.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09067.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.01294.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.05036.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.00530.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.07218.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.03738.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.02233.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.10551.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.07976.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.09708.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.10012.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.04433.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.03014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.09684.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08306.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.00722.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03584.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.06701.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.11365.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01093.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06556.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11860.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.10084.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05016.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00124.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.00819.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.02070.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.02357.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.12642.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.04553.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.09637.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.06279.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.08559.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.08772.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.12579.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1706.06894.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.08098.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1604.00727.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.01576.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1708.00214.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.02815.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.06671.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08829.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.08188.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.02013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.00547.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.05574.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.04631.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.13109.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.01694.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.06083.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.08868.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1702.06777.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.04032.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.04085.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.09194.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.00854.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.01265.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.03438.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.02380.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.11942.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.05664.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08752.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.00330.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.05411.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.09301.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.04457.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.05711.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09534.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.02334.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.09951.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.03710.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.11180.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01046.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.00995.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.04917.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.06964.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.09633.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.05902.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.02761.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.01183.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.00968.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1702.03274.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09779.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1610.03112.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13717.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.05581.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.05608.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03059.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03634.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.07090.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.07863.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.04625.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06151.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.06200.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.11049.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13375.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1708.09609.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.07513.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1702.01517.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.11346.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.00194.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.03191.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.02083.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.10869.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.13072.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.06118.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.10113.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.06171.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.09586.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1803.05223.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.01341.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.04181.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.02908.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.01413.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.09588.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.06843.pdf\n",
      "=== Finish paper_text ===\n",
      "\n",
      "=== Start nq on meno-tiny ===\n",
      "2025-07-29 15:16:38 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:16:38,691 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:16:42 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:16:44] #> Creating directory .ragatouille/colbert/indexes/nq_vector_db \n",
      "\n",
      "\n",
      "[Jul 29, 15:16:47] [0] \t\t #> Encoding 69 passages..\n",
      "[Jul 29, 15:16:47] [0] \t\t avg_doclen_est = 3.82608699798584 \t len(local_sample) = 69\n",
      "[Jul 29, 15:16:47] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/nq_vector_db/plan.json ..\n",
      "Warning: number of training points (251) is less than the minimum recommended (2560)\n",
      "used 3 iterations (0.0029s) to cluster 251 items into 256 clusters\n",
      "[0.001, 0.008, 0.006, 0.004, 0.007, 0.007, 0.016, 0.008, 0.012, 0.008, 0.004, 0.006, 0.007, 0.012, 0.003, 0.008, 0.007, 0.004, 0.006, 0.015, 0.013, 0.012, 0.009, 0.008, 0.006, 0.005, 0.006, 0.01, 0.008, 0.003, 0.017, 0.012, 0.017, 0.003, 0.003, 0.013, 0.003, 0.005, 0.009, 0.007, 0.005, 0.005, 0.01, 0.021, 0.003, 0.003, 0.01, 0.009, 0.013, 0.014, 0.003, 0.012, 0.005, 0.008, 0.005, 0.011, 0.006, 0.005, 0.004, 0.011, 0.008, 0.006, 0.014, 0.018, 0.004, 0.006, 0.016, 0.004, 0.007, 0.017, 0.005, 0.007, 0.009, 0.007, 0.01, 0.012, 0.007, 0.009, 0.012, 0.011, 0.012, 0.014, 0.009, 0.005, 0.003, 0.01, 0.021, 0.008, 0.013, 0.007, 0.015, 0.016, 0.007, 0.016, 0.011, 0.012, 0.015, 0.015, 0.005, 0.013, 0.011, 0.006, 0.006, 0.007, 0.01, 0.006, 0.009, 0.008, 0.005, 0.007, 0.01, 0.012, 0.022, 0.012, 0.015, 0.011, 0.008, 0.01, 0.011, 0.009, 0.004, 0.016, 0.004, 0.015, 0.004, 0.008, 0.005, 0.008]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:16:47] [0] \t\t #> Encoding 69 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 43.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2068.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:16:47] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:16:47] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:16:47] len(emb2pid) = 264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 145948.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:16:47] #> Saved optimized IVF to .ragatouille/colbert/indexes/nq_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:16:54] #> Loading codec...\n",
      "[Jul 29, 15:16:54] #> Loading IVF...\n",
      "[Jul 29, 15:16:54] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5262.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:16:54] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1112.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what episode of black mirror was hannah john kamen in, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2792,  1997,  2304,  5259,  2001,  8410,  2198,\n",
      "        22099,  1999,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:16:54 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'what episode of black mirror was hannah john kamen in', 'response': 'The answer is: Hannah John-Kamen appeared in the episode \"Nosedive\" of Black Mirror.', 'doc': 'Hannah John-Kamen', 'q_uid': -6718102858366318183, 'answers': {'long_answer': \"Year Title Role Notes 2011 Misfits Carly Episode # 3.6 Black Mirror Selma Episode `` Fifteen Million Merits '' 2012 Whitechapel Roxy 2 episodes The Syndicate Young Shop Assistant Episode # 1.2 The Midnight Beast Pizza Girls Episode: `` Someone Called Sam '' The Hour Rosa Maria Ramírez 4 episodes 2014 Death in Paradise Yasmin Blake Series 3; Episode 6 Happy Valley Justine 2015 Cucumber Violet The Ark Nahlab Television film Banana Violet 2015 -- present Killjoys Dutch / Aneela Main role 2016 The Tunnel: Sabotage Rosa Persaud Game of Thrones Ornela Episodes: `` Oathbreaker '', `` Book of the Stranger '' Black Mirror Sonja Episode: `` Playtest ''\", 'short_answer': \"Episode `` Fifteen Million Merits ''\"}}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:16:57] #> Note: Output directory .ragatouille/colbert/indexes/nq_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:16:57] #> Will delete 10 files already at .ragatouille/colbert/indexes/nq_vector_db in 20 seconds...\n",
      "[Jul 29, 15:17:20] [0] \t\t #> Encoding 60 passages..\n",
      "[Jul 29, 15:17:20] [0] \t\t avg_doclen_est = 3.8333332538604736 \t len(local_sample) = 60\n",
      "[Jul 29, 15:17:20] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/nq_vector_db/plan.json ..\n",
      "Warning: number of training points (219) is less than the minimum recommended (1280)\n",
      "used 4 iterations (0.0015s) to cluster 219 items into 128 clusters\n",
      "[0.015, 0.007, 0.007, 0.003, 0.021, 0.01, 0.004, 0.014, 0.006, 0.013, 0.009, 0.01, 0.013, 0.018, 0.011, 0.004, 0.012, 0.007, 0.013, 0.013, 0.004, 0.009, 0.006, 0.009, 0.008, 0.011, 0.017, 0.015, 0.011, 0.009, 0.015, 0.004, 0.008, 0.006, 0.012, 0.02, 0.015, 0.01, 0.01, 0.007, 0.015, 0.014, 0.004, 0.014, 0.01, 0.013, 0.011, 0.006, 0.025, 0.013, 0.013, 0.01, 0.013, 0.01, 0.01, 0.013, 0.005, 0.02, 0.006, 0.011, 0.011, 0.006, 0.01, 0.009, 0.012, 0.008, 0.014, 0.014, 0.011, 0.025, 0.013, 0.009, 0.007, 0.003, 0.006, 0.007, 0.006, 0.019, 0.01, 0.008, 0.014, 0.017, 0.009, 0.018, 0.014, 0.016, 0.022, 0.005, 0.013, 0.01, 0.006, 0.017, 0.009, 0.012, 0.019, 0.009, 0.015, 0.011, 0.005, 0.012, 0.012, 0.017, 0.006, 0.007, 0.018, 0.005, 0.011, 0.016, 0.011, 0.02, 0.011, 0.008, 0.014, 0.016, 0.016, 0.01, 0.005, 0.013, 0.014, 0.009, 0.014, 0.005, 0.019, 0.008, 0.004, 0.007, 0.008, 0.017]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:17:20] [0] \t\t #> Encoding 60 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 62.30it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2522.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:17:20] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:17:20] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:17:20] len(emb2pid) = 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 163232.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:17:20] #> Saved optimized IVF to .ragatouille/colbert/indexes/nq_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:17:26] #> Loading codec...\n",
      "[Jul 29, 15:17:26] #> Loading IVF...\n",
      "[Jul 29, 15:17:26] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4686.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:17:26] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1418.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: where is oklahoma located in the united states, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2073, 2003, 5858, 2284, 1999, 1996, 2142, 2163,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:17:26 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'where is oklahoma located in the united states', 'response': 'The answer is: Oklahoma is located in the central part of the United States.', 'doc': 'Oklahoma', 'q_uid': 3340122335577060793, 'answers': {'long_answer': 'Oklahoma is the 20th - largest state in the United States, covering an area of 69,898 square miles ( 181,030 km ), with 68,667 square miles ( 177,850 km ) of land and 1,281 square miles ( 3,320 km ) of water. It lies partly in the Great Plains near the geographical center of the 48 contiguous states. It is bounded on the east by Arkansas and Missouri, on the north by Kansas, on the northwest by Colorado, on the far west by New Mexico, and on the south and near - west by Texas. Much of its border with Texas lies along the Southern Oklahoma Aulacogen, a failed continental rift. The geologic figure defines the placement of the Red River.', 'short_answer': 'in the Great Plains near the geographical center of the 48 contiguous states.'}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:17:32] #> Loading codec...\n",
      "[Jul 29, 15:17:32] #> Loading IVF...\n",
      "[Jul 29, 15:17:32] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5533.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:17:32] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1686.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what part of the country is oklahoma considered, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2112, 1997, 1996, 2406, 2003, 5858, 2641,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:17:32 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'what part of the country is oklahoma considered', 'response': 'The answer is: a southeastern state of the united states', 'doc': 'Oklahoma', 'q_uid': -4372236156247664542, 'answers': {'long_answer': \"Oklahoma ( / ˌoʊkləˈhoʊmə / ( listen ); Pawnee: Uukuhuúwa, Cayuga: Gahnawiyoˀgeh ) is a state in the South Central region of the United States. It is the 20th-most extensive and the 28th-most populous of the 50 United States. The state 's name is derived from the Choctaw words okla and humma, meaning `` red people. '' It is also known informally by its nickname, `` The Sooner State, '' in reference to the non-Native settlers who staked their claims on land before the official opening date and the Indian Appropriations Act of 1889, which dramatically increased European - American settlement in the Indian Territory. Oklahoma Territory and Indian Territory were merged and Indian was dropped from the name. On November 16, 1907, Oklahoma became the 46th state to enter the union. Its residents are known as Oklahomans, or informally as Okies, and its capital and largest city is Oklahoma City.\", 'short_answer': 'a state in the South Central'}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:17:39] #> Loading codec...\n",
      "[Jul 29, 15:17:39] #> Loading IVF...\n",
      "[Jul 29, 15:17:39] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11683.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:17:39] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1603.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: how many states share a border with oklahoma, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2129, 2116, 2163, 3745, 1037, 3675, 2007, 5858,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:17:39 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'how many states share a border with oklahoma', 'response': 'The answer is: 7', 'doc': 'Oklahoma', 'q_uid': 3749925031204735637, 'answers': {'long_answer': 'Oklahoma is the 20th - largest state in the United States, covering an area of 69,898 square miles ( 181,035 km ), with 68,667 square miles ( 177,847 km ) of land and 1,281 square miles ( 3,188 km ) of water. It lies partly in the Great Plains near the geographical center of the 48 contiguous states. It is bounded on the east by Arkansas and Missouri, on the north by Kansas, on the northwest by Colorado, on the far west by New Mexico, and on the south and near - west by Texas. Much of its border with Texas lies along the Southern Oklahoma Aulacogen, a failed continental rift. The geologic figure defines the placement of the Red River.', 'short_answer': ''}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:17:45] #> Loading codec...\n",
      "[Jul 29, 15:17:45] #> Loading IVF...\n",
      "[Jul 29, 15:17:45] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4733.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:17:45] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1679.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: where is oklahoma located on the map of the united states, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2073, 2003, 5858, 2284, 2006, 1996, 4949, 1997, 1996, 2142,\n",
      "        2163,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:17:45 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'where is oklahoma located on the map of the united states', 'response': 'Oklahoma is located in the central part of the United States.', 'doc': 'Oklahoma', 'q_uid': -8736122236866420014, 'answers': {'long_answer': 'Oklahoma is the 20th - largest state in the United States, covering an area of 69,898 square miles ( 181,030 km ), with 68,667 square miles ( 177,850 km ) of land and 1,281 square miles ( 3,320 km ) of water. It lies partly in the Great Plains near the geographical center of the 48 contiguous states. It is bounded on the east by Arkansas and Missouri, on the north by Kansas, on the northwest by Colorado, on the far west by New Mexico, and on the south and near - west by Texas. Much of its border with Texas lies along the Southern Oklahoma Aulacogen, a failed continental rift. The geologic figure defines the placement of the Red River.', 'short_answer': ''}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:17:51] #> Loading codec...\n",
      "[Jul 29, 15:17:51] #> Loading IVF...\n",
      "[Jul 29, 15:17:51] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6141.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:17:51] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1518.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: when did oklahoma become a state what does the word oklahoma mean, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2043, 2106, 5858, 2468, 1037, 2110, 2054, 2515, 1996, 2773,\n",
      "        5858, 2812,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:17:51 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'when did oklahoma become a state what does the word oklahoma mean', 'response': 'The answer is: 1907', 'doc': 'Oklahoma', 'q_uid': -3485714005907152096, 'answers': {'long_answer': \"Oklahoma ( / ˌoʊkləˈhoʊmə / ( listen ); Pawnee: Uukuhuúwa, Cayuga: Gahnawiyoˀgeh ) is a state in the South Central region of the United States. It is the 20th-most extensive and the 28th-most populous of the 50 United States. The state 's name is derived from the Choctaw words okla and humma, meaning `` red people ''. It is also known informally by its nickname, `` The Sooner State '', in reference to the non-Native settlers who staked their claims on land before the official opening date of lands in the western Oklahoma Territory or before the Indian Appropriations Act of 1889, which dramatically increased European - American settlement in the eastern Indian Territory. Oklahoma Territory and Indian Territory were merged into the State of Oklahoma when it became the 46th state to enter the union on November 16, 1907. Its residents are known as Oklahomans, or informally as Okies, and its capital and largest city is Oklahoma City.\", 'short_answer': ''}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:17:57] #> Loading codec...\n",
      "[Jul 29, 15:17:57] #> Loading IVF...\n",
      "[Jul 29, 15:17:57] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10754.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:17:57] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1567.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: when did oklahoma become part of the united states, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2043, 2106, 5858, 2468, 2112, 1997, 1996, 2142, 2163,  102,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:17:58 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'when did oklahoma become part of the united states', 'response': '6 January 2018', 'doc': 'Oklahoma', 'q_uid': -6235538092288743840, 'answers': {'long_answer': 'Admission to Union November 16, 1907 ( 46th )', 'short_answer': 'November 16, 1907 ('}}\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Just the Way You Are (Bruno Mars song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Karan Brar.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Chicago.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Academic term.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Achaemenid Empire.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Devin Hester.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/American Ninja Warrior (season 9).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of iOS devices.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of UFC records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Nigerian Navy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Isabelle Fuhrman.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jordana Brewster.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Spartan army.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2013 Open Championship.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of awards and nominations received by Game of Thrones.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Kilowatt hour.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Cheyenne Jackson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Indian cricket team in England in 1932.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/California State Assembly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Gregg Sulkin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of awards and nominations received by Bruno Mars.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Greta Garbo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Luka Modrić.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of longest suspension bridge spans.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Will Arnett.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Grayson Russell.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Andy Karl.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of awards and nominations received by Breaking Bad.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Freddy Rodriguez (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Perla Haney-Jardine.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Total Drama: Revenge of the Island.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Hair (musical).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Des Moines, Iowa.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Maisie Williams.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Sam Underwood.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Kristin Davis.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Nebraska Cornhuskers football.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Standard deviation.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Zachery Ty Bryan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Holy Roman Emperor.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Daniel Craig.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Margot Robbie.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Lindsey Stirling.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/AFL Grand Final.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Plitvice Lakes National Park.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/1982 FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Joe Manganiello.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Test cricket records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jameis Winston.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of districts of Nepal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Density of air.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Natural satellite.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/David Harbour.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Georgia Tech Yellow Jackets football.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jennifer Jones.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Laverne Cox.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/New Kids on the Block.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Oleg Salenko.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/The Lazy Song.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of German football champions.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/The Fresh Prince of Bel-Air.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/What Hurts the Most.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Eloise Mumford.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Zachary Gordon.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Kris Boyd.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Secretaries General of OPEC.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Two's complement.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Steel Vengeance.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Taylor Schilling.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2017–18 FC Barcelona season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Richard Madden.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Stone (unit).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Lauren Daigle.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/1972 Miami Dolphins season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2004 World Series.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Mario Kart.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/From the Land of the Moon (film).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Mesut Özil.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Rory Kinnear.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Mazda BT-50.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Adam Pascal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Tom Holland (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of continents by population.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/M*A*S*H (TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Category 4 Atlantic hurricanes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Victoria Justice.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Hawthorn Football Club.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Hawaii.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Dave Bautista.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Marvel Cinematic Universe films.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Kelvin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Elisa Donovan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Scott Clifton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Street & Racing Technology.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Love Island (series 1).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2016 ICC Women's World Twenty20.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Dane DeHaan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Heather Tom.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Peter Bergman.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Robert's Rules of Order.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Prime Minister of Jamaica.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Army–Navy Game.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Mark Addy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Spider-Man in film.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Teri Polo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Patrick J. Adams.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of governors of Madhya Pradesh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Twenty-foot equivalent unit.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Ariana Grande.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Clémence Poésy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Houston.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Yankee Stadium.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Fiddler on the Roof (film).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Victoria Hamilton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Shirley Henderson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Prime Ministers of Nepal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Tupac Shakur.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Safe & Sound (Taylor Swift song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/William Fichtner.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Being Human (UK TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Local governance in Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2002 FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Will Yun Lee.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jonathan Groff.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Chief Ministers of Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Nicholle Tom.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Tony Gwynn.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Tears in Heaven.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/America's Got Talent.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jessica Collins.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Los Angeles Open.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Grade inflation.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Rupert Grint.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Long Day's Journey into Night.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Law & Order: Criminal Intent.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Dungeons & Dragons rulebooks.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Chief Ministers of Nagaland.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Dancing with the Stars (U.S. season 24).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Courtney Ford.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Halley's Comet.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Rebecca Mader.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Seattle.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Demi Lovato.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Smallville.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Skye McCole Bartusiak.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Cillian Murphy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Cricket World Cup awards.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of islands by area.pdf\n",
      "=== Start nq on qwen2.5-1.5B ===\n",
      "2025-07-29 15:17:58 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:17:58,633 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:18:02 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:18:05] #> Note: Output directory .ragatouille/colbert/indexes/nq_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:18:05] #> Will delete 10 files already at .ragatouille/colbert/indexes/nq_vector_db in 20 seconds...\n",
      "[Jul 29, 15:18:28] [0] \t\t #> Encoding 69 passages..\n",
      "[Jul 29, 15:18:28] [0] \t\t avg_doclen_est = 3.82608699798584 \t len(local_sample) = 69\n",
      "[Jul 29, 15:18:28] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/nq_vector_db/plan.json ..\n",
      "Warning: number of training points (251) is less than the minimum recommended (2560)\n",
      "used 3 iterations (0.0011s) to cluster 251 items into 256 clusters\n",
      "[0.001, 0.008, 0.006, 0.004, 0.007, 0.007, 0.016, 0.008, 0.012, 0.008, 0.004, 0.006, 0.007, 0.012, 0.003, 0.008, 0.007, 0.004, 0.006, 0.015, 0.013, 0.012, 0.009, 0.008, 0.006, 0.005, 0.006, 0.01, 0.008, 0.003, 0.017, 0.012, 0.017, 0.003, 0.003, 0.013, 0.003, 0.005, 0.009, 0.007, 0.005, 0.005, 0.01, 0.021, 0.003, 0.003, 0.01, 0.009, 0.013, 0.014, 0.003, 0.012, 0.005, 0.008, 0.005, 0.011, 0.006, 0.005, 0.004, 0.011, 0.008, 0.006, 0.014, 0.018, 0.004, 0.006, 0.016, 0.004, 0.007, 0.017, 0.005, 0.007, 0.009, 0.007, 0.01, 0.012, 0.007, 0.009, 0.012, 0.011, 0.012, 0.014, 0.009, 0.005, 0.003, 0.01, 0.021, 0.008, 0.013, 0.007, 0.015, 0.016, 0.007, 0.016, 0.011, 0.012, 0.015, 0.015, 0.005, 0.013, 0.011, 0.006, 0.006, 0.007, 0.01, 0.006, 0.009, 0.008, 0.005, 0.007, 0.01, 0.012, 0.022, 0.012, 0.015, 0.011, 0.008, 0.01, 0.011, 0.009, 0.004, 0.016, 0.004, 0.015, 0.004, 0.008, 0.005, 0.008]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:18:28] [0] \t\t #> Encoding 69 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 53.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1671.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:18:28] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:18:28] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:18:28] len(emb2pid) = 264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 128499.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:18:28] #> Saved optimized IVF to .ragatouille/colbert/indexes/nq_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:18:34] #> Loading codec...\n",
      "[Jul 29, 15:18:34] #> Loading IVF...\n",
      "[Jul 29, 15:18:34] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6472.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:18:34] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1561.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what episode of black mirror was hannah john kamen in, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2792,  1997,  2304,  5259,  2001,  8410,  2198,\n",
      "        22099,  1999,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:18:34 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'what episode of black mirror was hannah john kamen in', 'response': 'The answer is: Hannah John-Kamen appeared in season 3, episode 5 \"Nosedive\".', 'doc': 'Hannah John-Kamen', 'q_uid': -6718102858366318183, 'answers': {'long_answer': \"Year Title Role Notes 2011 Misfits Carly Episode # 3.6 Black Mirror Selma Episode `` Fifteen Million Merits '' 2012 Whitechapel Roxy 2 episodes The Syndicate Young Shop Assistant Episode # 1.2 The Midnight Beast Pizza Girls Episode: `` Someone Called Sam '' The Hour Rosa Maria Ramírez 4 episodes 2014 Death in Paradise Yasmin Blake Series 3; Episode 6 Happy Valley Justine 2015 Cucumber Violet The Ark Nahlab Television film Banana Violet 2015 -- present Killjoys Dutch / Aneela Main role 2016 The Tunnel: Sabotage Rosa Persaud Game of Thrones Ornela Episodes: `` Oathbreaker '', `` Book of the Stranger '' Black Mirror Sonja Episode: `` Playtest ''\", 'short_answer': \"Episode `` Fifteen Million Merits ''\"}}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:18:37] #> Note: Output directory .ragatouille/colbert/indexes/nq_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:18:37] #> Will delete 10 files already at .ragatouille/colbert/indexes/nq_vector_db in 20 seconds...\n",
      "[Jul 29, 15:19:00] [0] \t\t #> Encoding 60 passages..\n",
      "[Jul 29, 15:19:00] [0] \t\t avg_doclen_est = 3.8333332538604736 \t len(local_sample) = 60\n",
      "[Jul 29, 15:19:00] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/nq_vector_db/plan.json ..\n",
      "Warning: number of training points (219) is less than the minimum recommended (1280)\n",
      "used 4 iterations (0.0016s) to cluster 219 items into 128 clusters\n",
      "[0.015, 0.007, 0.007, 0.003, 0.021, 0.01, 0.004, 0.014, 0.006, 0.013, 0.009, 0.01, 0.013, 0.018, 0.011, 0.004, 0.012, 0.007, 0.013, 0.013, 0.004, 0.009, 0.006, 0.009, 0.008, 0.011, 0.017, 0.015, 0.011, 0.009, 0.015, 0.004, 0.008, 0.006, 0.012, 0.02, 0.015, 0.01, 0.01, 0.007, 0.015, 0.014, 0.004, 0.014, 0.01, 0.013, 0.011, 0.006, 0.025, 0.013, 0.013, 0.01, 0.013, 0.01, 0.01, 0.013, 0.005, 0.02, 0.006, 0.011, 0.011, 0.006, 0.01, 0.009, 0.012, 0.008, 0.014, 0.014, 0.011, 0.025, 0.013, 0.009, 0.007, 0.003, 0.006, 0.007, 0.006, 0.019, 0.01, 0.008, 0.014, 0.017, 0.009, 0.018, 0.014, 0.016, 0.022, 0.005, 0.013, 0.01, 0.006, 0.017, 0.009, 0.012, 0.019, 0.009, 0.015, 0.011, 0.005, 0.012, 0.012, 0.017, 0.006, 0.007, 0.018, 0.005, 0.011, 0.016, 0.011, 0.02, 0.011, 0.008, 0.014, 0.016, 0.016, 0.01, 0.005, 0.013, 0.014, 0.009, 0.014, 0.005, 0.019, 0.008, 0.004, 0.007, 0.008, 0.017]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:19:00] [0] \t\t #> Encoding 60 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 64.19it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1887.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:19:00] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:19:00] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:19:00] len(emb2pid) = 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 107718.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:19:00] #> Saved optimized IVF to .ragatouille/colbert/indexes/nq_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:19:07] #> Loading codec...\n",
      "[Jul 29, 15:19:07] #> Loading IVF...\n",
      "[Jul 29, 15:19:07] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6335.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:19:07] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1155.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: where is oklahoma located in the united states, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2073, 2003, 5858, 2284, 1999, 1996, 2142, 2163,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:19:07 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'where is oklahoma located in the united states', 'response': 'The answer is: Oklahoma is located in the central region of the United States.', 'doc': 'Oklahoma', 'q_uid': 3340122335577060793, 'answers': {'long_answer': 'Oklahoma is the 20th - largest state in the United States, covering an area of 69,898 square miles ( 181,030 km ), with 68,667 square miles ( 177,850 km ) of land and 1,281 square miles ( 3,320 km ) of water. It lies partly in the Great Plains near the geographical center of the 48 contiguous states. It is bounded on the east by Arkansas and Missouri, on the north by Kansas, on the northwest by Colorado, on the far west by New Mexico, and on the south and near - west by Texas. Much of its border with Texas lies along the Southern Oklahoma Aulacogen, a failed continental rift. The geologic figure defines the placement of the Red River.', 'short_answer': 'in the Great Plains near the geographical center of the 48 contiguous states.'}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:19:14] #> Loading codec...\n",
      "[Jul 29, 15:19:14] #> Loading IVF...\n",
      "[Jul 29, 15:19:14] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5065.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:19:14] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1096.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what part of the country is oklahoma considered, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2112, 1997, 1996, 2406, 2003, 5858, 2641,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:19:14 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'what part of the country is oklahoma considered', 'response': 'the southernmost state in the united states', 'doc': 'Oklahoma', 'q_uid': -4372236156247664542, 'answers': {'long_answer': \"Oklahoma ( / ˌoʊkləˈhoʊmə / ( listen ); Pawnee: Uukuhuúwa, Cayuga: Gahnawiyoˀgeh ) is a state in the South Central region of the United States. It is the 20th-most extensive and the 28th-most populous of the 50 United States. The state 's name is derived from the Choctaw words okla and humma, meaning `` red people. '' It is also known informally by its nickname, `` The Sooner State, '' in reference to the non-Native settlers who staked their claims on land before the official opening date and the Indian Appropriations Act of 1889, which dramatically increased European - American settlement in the Indian Territory. Oklahoma Territory and Indian Territory were merged and Indian was dropped from the name. On November 16, 1907, Oklahoma became the 46th state to enter the union. Its residents are known as Oklahomans, or informally as Okies, and its capital and largest city is Oklahoma City.\", 'short_answer': 'a state in the South Central'}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:19:20] #> Loading codec...\n",
      "[Jul 29, 15:19:20] #> Loading IVF...\n",
      "[Jul 29, 15:19:20] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6808.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:19:20] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1745.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: how many states share a border with oklahoma, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2129, 2116, 2163, 3745, 1037, 3675, 2007, 5858,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:19:20 CallLLM\n",
      "{'model': 'qwen2.5-1.5B', 'question': 'how many states share a border with oklahoma', 'response': 'the answer is: 7', 'doc': 'Oklahoma', 'q_uid': 3749925031204735637, 'answers': {'long_answer': 'Oklahoma is the 20th - largest state in the United States, covering an area of 69,898 square miles ( 181,035 km ), with 68,667 square miles ( 177,847 km ) of land and 1,281 square miles ( 3,188 km ) of water. It lies partly in the Great Plains near the geographical center of the 48 contiguous states. It is bounded on the east by Arkansas and Missouri, on the north by Kansas, on the northwest by Colorado, on the far west by New Mexico, and on the south and near - west by Texas. Much of its border with Texas lies along the Southern Oklahoma Aulacogen, a failed continental rift. The geologic figure defines the placement of the Red River.', 'short_answer': ''}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:19:26] #> Loading codec...\n",
      "[Jul 29, 15:19:26] #> Loading IVF...\n",
      "[Jul 29, 15:19:26] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6288.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:19:26] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1695.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: where is oklahoma located on the map of the united states, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2073, 2003, 5858, 2284, 2006, 1996, 4949, 1997, 1996, 2142,\n",
      "        2163,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:19:26 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'where is oklahoma located on the map of the united states', 'response': 'the state of oklahoma is located in the central region of the united states.', 'doc': 'Oklahoma', 'q_uid': -8736122236866420014, 'answers': {'long_answer': 'Oklahoma is the 20th - largest state in the United States, covering an area of 69,898 square miles ( 181,030 km ), with 68,667 square miles ( 177,850 km ) of land and 1,281 square miles ( 3,320 km ) of water. It lies partly in the Great Plains near the geographical center of the 48 contiguous states. It is bounded on the east by Arkansas and Missouri, on the north by Kansas, on the northwest by Colorado, on the far west by New Mexico, and on the south and near - west by Texas. Much of its border with Texas lies along the Southern Oklahoma Aulacogen, a failed continental rift. The geologic figure defines the placement of the Red River.', 'short_answer': ''}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:19:32] #> Loading codec...\n",
      "[Jul 29, 15:19:32] #> Loading IVF...\n",
      "[Jul 29, 15:19:32] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6615.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:19:32] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1763.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: when did oklahoma become a state what does the word oklahoma mean, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2043, 2106, 5858, 2468, 1037, 2110, 2054, 2515, 1996, 2773,\n",
      "        5858, 2812,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:19:32 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'when did oklahoma become a state what does the word oklahoma mean', 'response': 'the answer is: Oklahoma means \"Land of the Morning Calm\"', 'doc': 'Oklahoma', 'q_uid': -3485714005907152096, 'answers': {'long_answer': \"Oklahoma ( / ˌoʊkləˈhoʊmə / ( listen ); Pawnee: Uukuhuúwa, Cayuga: Gahnawiyoˀgeh ) is a state in the South Central region of the United States. It is the 20th-most extensive and the 28th-most populous of the 50 United States. The state 's name is derived from the Choctaw words okla and humma, meaning `` red people ''. It is also known informally by its nickname, `` The Sooner State '', in reference to the non-Native settlers who staked their claims on land before the official opening date of lands in the western Oklahoma Territory or before the Indian Appropriations Act of 1889, which dramatically increased European - American settlement in the eastern Indian Territory. Oklahoma Territory and Indian Territory were merged into the State of Oklahoma when it became the 46th state to enter the union on November 16, 1907. Its residents are known as Oklahomans, or informally as Okies, and its capital and largest city is Oklahoma City.\", 'short_answer': ''}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:19:38] #> Loading codec...\n",
      "[Jul 29, 15:19:38] #> Loading IVF...\n",
      "[Jul 29, 15:19:38] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 9489.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:19:38] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1548.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: when did oklahoma become part of the united states, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2043, 2106, 5858, 2468, 2112, 1997, 1996, 2142, 2163,  102,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:19:38 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'when did oklahoma become part of the united states', 'response': 'The answer is: it became part of the united states on december 24, 1907', 'doc': 'Oklahoma', 'q_uid': -6235538092288743840, 'answers': {'long_answer': 'Admission to Union November 16, 1907 ( 46th )', 'short_answer': 'November 16, 1907 ('}}\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Just the Way You Are (Bruno Mars song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Karan Brar.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Chicago.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Academic term.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Achaemenid Empire.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Devin Hester.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/American Ninja Warrior (season 9).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of iOS devices.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of UFC records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Nigerian Navy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Isabelle Fuhrman.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jordana Brewster.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Spartan army.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2013 Open Championship.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of awards and nominations received by Game of Thrones.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Kilowatt hour.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Cheyenne Jackson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Indian cricket team in England in 1932.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/California State Assembly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Gregg Sulkin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of awards and nominations received by Bruno Mars.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Greta Garbo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Luka Modrić.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of longest suspension bridge spans.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Will Arnett.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Grayson Russell.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Andy Karl.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of awards and nominations received by Breaking Bad.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Freddy Rodriguez (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Perla Haney-Jardine.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Total Drama: Revenge of the Island.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Hair (musical).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Des Moines, Iowa.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Maisie Williams.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Sam Underwood.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Kristin Davis.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Nebraska Cornhuskers football.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Standard deviation.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Zachery Ty Bryan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Holy Roman Emperor.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Daniel Craig.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Margot Robbie.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Lindsey Stirling.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/AFL Grand Final.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Plitvice Lakes National Park.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/1982 FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Joe Manganiello.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Test cricket records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jameis Winston.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of districts of Nepal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Density of air.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Natural satellite.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/David Harbour.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Georgia Tech Yellow Jackets football.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jennifer Jones.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Laverne Cox.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/New Kids on the Block.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Oleg Salenko.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/The Lazy Song.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of German football champions.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/The Fresh Prince of Bel-Air.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/What Hurts the Most.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Eloise Mumford.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Zachary Gordon.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Kris Boyd.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Secretaries General of OPEC.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Two's complement.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Steel Vengeance.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Taylor Schilling.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2017–18 FC Barcelona season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Richard Madden.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Stone (unit).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Lauren Daigle.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/1972 Miami Dolphins season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2004 World Series.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Mario Kart.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/From the Land of the Moon (film).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Mesut Özil.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Rory Kinnear.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Mazda BT-50.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Adam Pascal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Tom Holland (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of continents by population.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/M*A*S*H (TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Category 4 Atlantic hurricanes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Victoria Justice.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Hawthorn Football Club.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Hawaii.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Dave Bautista.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Marvel Cinematic Universe films.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Kelvin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Elisa Donovan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Scott Clifton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Street & Racing Technology.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Love Island (series 1).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2016 ICC Women's World Twenty20.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Dane DeHaan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Heather Tom.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Peter Bergman.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Robert's Rules of Order.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Prime Minister of Jamaica.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Army–Navy Game.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Mark Addy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Spider-Man in film.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Teri Polo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Patrick J. Adams.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of governors of Madhya Pradesh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Twenty-foot equivalent unit.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Ariana Grande.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Clémence Poésy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Houston.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Yankee Stadium.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Fiddler on the Roof (film).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Victoria Hamilton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Shirley Henderson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Prime Ministers of Nepal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Tupac Shakur.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Safe & Sound (Taylor Swift song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/William Fichtner.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Being Human (UK TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Local governance in Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2002 FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Will Yun Lee.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jonathan Groff.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Chief Ministers of Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Nicholle Tom.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Tony Gwynn.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Tears in Heaven.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/America's Got Talent.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jessica Collins.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Los Angeles Open.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Grade inflation.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Rupert Grint.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Long Day's Journey into Night.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Law & Order: Criminal Intent.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Dungeons & Dragons rulebooks.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Chief Ministers of Nagaland.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Dancing with the Stars (U.S. season 24).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Courtney Ford.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Halley's Comet.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Rebecca Mader.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Seattle.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Demi Lovato.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Smallville.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Skye McCole Bartusiak.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Cillian Murphy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Cricket World Cup awards.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of islands by area.pdf\n",
      "=== Start nq on qwen2.5-3B ===\n",
      "2025-07-29 15:19:39 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:19:39,373 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.95s/it]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:19:46 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:19:48] #> Note: Output directory .ragatouille/colbert/indexes/nq_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:19:48] #> Will delete 10 files already at .ragatouille/colbert/indexes/nq_vector_db in 20 seconds...\n",
      "[Jul 29, 15:20:11] [0] \t\t #> Encoding 69 passages..\n",
      "[Jul 29, 15:20:12] [0] \t\t avg_doclen_est = 3.82608699798584 \t len(local_sample) = 69\n",
      "[Jul 29, 15:20:12] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/nq_vector_db/plan.json ..\n",
      "Warning: number of training points (251) is less than the minimum recommended (2560)\n",
      "used 3 iterations (0.0012s) to cluster 251 items into 256 clusters\n",
      "[0.001, 0.008, 0.006, 0.004, 0.007, 0.007, 0.016, 0.008, 0.012, 0.008, 0.004, 0.006, 0.007, 0.012, 0.003, 0.008, 0.007, 0.004, 0.006, 0.015, 0.013, 0.012, 0.009, 0.008, 0.006, 0.005, 0.006, 0.01, 0.008, 0.003, 0.017, 0.012, 0.017, 0.003, 0.003, 0.013, 0.003, 0.005, 0.009, 0.007, 0.005, 0.005, 0.01, 0.021, 0.003, 0.003, 0.01, 0.009, 0.013, 0.014, 0.003, 0.012, 0.005, 0.008, 0.005, 0.011, 0.006, 0.005, 0.004, 0.011, 0.008, 0.006, 0.014, 0.018, 0.004, 0.006, 0.016, 0.004, 0.007, 0.017, 0.005, 0.007, 0.009, 0.007, 0.01, 0.012, 0.007, 0.009, 0.012, 0.011, 0.012, 0.014, 0.009, 0.005, 0.003, 0.01, 0.021, 0.008, 0.013, 0.007, 0.015, 0.016, 0.007, 0.016, 0.011, 0.012, 0.015, 0.015, 0.005, 0.013, 0.011, 0.006, 0.006, 0.007, 0.01, 0.006, 0.009, 0.008, 0.005, 0.007, 0.01, 0.012, 0.022, 0.012, 0.015, 0.011, 0.008, 0.01, 0.011, 0.009, 0.004, 0.016, 0.004, 0.015, 0.004, 0.008, 0.005, 0.008]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:20:12] [0] \t\t #> Encoding 69 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 44.85it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1718.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:20:12] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:20:12] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:20:12] len(emb2pid) = 264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 140947.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:20:12] #> Saved optimized IVF to .ragatouille/colbert/indexes/nq_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:20:18] #> Loading codec...\n",
      "[Jul 29, 15:20:18] #> Loading IVF...\n",
      "[Jul 29, 15:20:18] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7145.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:20:18] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1339.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what episode of black mirror was hannah john kamen in, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2792,  1997,  2304,  5259,  2001,  8410,  2198,\n",
      "        22099,  1999,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:20:18 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'what episode of black mirror was hannah john kamen in', 'response': 'The answer is: \"Nosedive\"', 'doc': 'Hannah John-Kamen', 'q_uid': -6718102858366318183, 'answers': {'long_answer': \"Year Title Role Notes 2011 Misfits Carly Episode # 3.6 Black Mirror Selma Episode `` Fifteen Million Merits '' 2012 Whitechapel Roxy 2 episodes The Syndicate Young Shop Assistant Episode # 1.2 The Midnight Beast Pizza Girls Episode: `` Someone Called Sam '' The Hour Rosa Maria Ramírez 4 episodes 2014 Death in Paradise Yasmin Blake Series 3; Episode 6 Happy Valley Justine 2015 Cucumber Violet The Ark Nahlab Television film Banana Violet 2015 -- present Killjoys Dutch / Aneela Main role 2016 The Tunnel: Sabotage Rosa Persaud Game of Thrones Ornela Episodes: `` Oathbreaker '', `` Book of the Stranger '' Black Mirror Sonja Episode: `` Playtest ''\", 'short_answer': \"Episode `` Fifteen Million Merits ''\"}}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:20:21] #> Note: Output directory .ragatouille/colbert/indexes/nq_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:20:21] #> Will delete 10 files already at .ragatouille/colbert/indexes/nq_vector_db in 20 seconds...\n",
      "[Jul 29, 15:20:44] [0] \t\t #> Encoding 60 passages..\n",
      "[Jul 29, 15:20:44] [0] \t\t avg_doclen_est = 3.8333332538604736 \t len(local_sample) = 60\n",
      "[Jul 29, 15:20:44] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/nq_vector_db/plan.json ..\n",
      "Warning: number of training points (219) is less than the minimum recommended (1280)\n",
      "used 4 iterations (0.0012s) to cluster 219 items into 128 clusters\n",
      "[0.015, 0.007, 0.007, 0.003, 0.021, 0.01, 0.004, 0.014, 0.006, 0.013, 0.009, 0.01, 0.013, 0.018, 0.011, 0.004, 0.012, 0.007, 0.013, 0.013, 0.004, 0.009, 0.006, 0.009, 0.008, 0.011, 0.017, 0.015, 0.011, 0.009, 0.015, 0.004, 0.008, 0.006, 0.012, 0.02, 0.015, 0.01, 0.01, 0.007, 0.015, 0.014, 0.004, 0.014, 0.01, 0.013, 0.011, 0.006, 0.025, 0.013, 0.013, 0.01, 0.013, 0.01, 0.01, 0.013, 0.005, 0.02, 0.006, 0.011, 0.011, 0.006, 0.01, 0.009, 0.012, 0.008, 0.014, 0.014, 0.011, 0.025, 0.013, 0.009, 0.007, 0.003, 0.006, 0.007, 0.006, 0.019, 0.01, 0.008, 0.014, 0.017, 0.009, 0.018, 0.014, 0.016, 0.022, 0.005, 0.013, 0.01, 0.006, 0.017, 0.009, 0.012, 0.019, 0.009, 0.015, 0.011, 0.005, 0.012, 0.012, 0.017, 0.006, 0.007, 0.018, 0.005, 0.011, 0.016, 0.011, 0.02, 0.011, 0.008, 0.014, 0.016, 0.016, 0.01, 0.005, 0.013, 0.014, 0.009, 0.014, 0.005, 0.019, 0.008, 0.004, 0.007, 0.008, 0.017]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:20:44] [0] \t\t #> Encoding 60 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 72.03it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2001.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:20:44] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:20:44] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:20:44] len(emb2pid) = 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 105145.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:20:44] #> Saved optimized IVF to .ragatouille/colbert/indexes/nq_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:20:50] #> Loading codec...\n",
      "[Jul 29, 15:20:50] #> Loading IVF...\n",
      "[Jul 29, 15:20:50] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5419.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:20:50] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1088.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: where is oklahoma located in the united states, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2073, 2003, 5858, 2284, 1999, 1996, 2142, 2163,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:20:50 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'where is oklahoma located in the united states', 'response': 'The answer is: Oklahoma is located in the central region of the United States, primarily in the Great Plains.', 'doc': 'Oklahoma', 'q_uid': 3340122335577060793, 'answers': {'long_answer': 'Oklahoma is the 20th - largest state in the United States, covering an area of 69,898 square miles ( 181,030 km ), with 68,667 square miles ( 177,850 km ) of land and 1,281 square miles ( 3,320 km ) of water. It lies partly in the Great Plains near the geographical center of the 48 contiguous states. It is bounded on the east by Arkansas and Missouri, on the north by Kansas, on the northwest by Colorado, on the far west by New Mexico, and on the south and near - west by Texas. Much of its border with Texas lies along the Southern Oklahoma Aulacogen, a failed continental rift. The geologic figure defines the placement of the Red River.', 'short_answer': 'in the Great Plains near the geographical center of the 48 contiguous states.'}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:20:56] #> Loading codec...\n",
      "[Jul 29, 15:20:56] #> Loading IVF...\n",
      "[Jul 29, 15:20:56] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5115.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:20:56] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1037.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what part of the country is oklahoma considered, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2112, 1997, 1996, 2406, 2003, 5858, 2641,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:20:56 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'what part of the country is oklahoma considered', 'response': 'There is no information provided in the given context to answer the question \"what part of the country is oklahoma considered\".', 'doc': 'Oklahoma', 'q_uid': -4372236156247664542, 'answers': {'long_answer': \"Oklahoma ( / ˌoʊkləˈhoʊmə / ( listen ); Pawnee: Uukuhuúwa, Cayuga: Gahnawiyoˀgeh ) is a state in the South Central region of the United States. It is the 20th-most extensive and the 28th-most populous of the 50 United States. The state 's name is derived from the Choctaw words okla and humma, meaning `` red people. '' It is also known informally by its nickname, `` The Sooner State, '' in reference to the non-Native settlers who staked their claims on land before the official opening date and the Indian Appropriations Act of 1889, which dramatically increased European - American settlement in the Indian Territory. Oklahoma Territory and Indian Territory were merged and Indian was dropped from the name. On November 16, 1907, Oklahoma became the 46th state to enter the union. Its residents are known as Oklahomans, or informally as Okies, and its capital and largest city is Oklahoma City.\", 'short_answer': 'a state in the South Central'}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:21:02] #> Loading codec...\n",
      "[Jul 29, 15:21:02] #> Loading IVF...\n",
      "[Jul 29, 15:21:02] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10754.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:21:02] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1376.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: how many states share a border with oklahoma, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2129, 2116, 2163, 3745, 1037, 3675, 2007, 5858,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:21:03 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'how many states share a border with oklahoma', 'response': 'The answer is: 4', 'doc': 'Oklahoma', 'q_uid': 3749925031204735637, 'answers': {'long_answer': 'Oklahoma is the 20th - largest state in the United States, covering an area of 69,898 square miles ( 181,035 km ), with 68,667 square miles ( 177,847 km ) of land and 1,281 square miles ( 3,188 km ) of water. It lies partly in the Great Plains near the geographical center of the 48 contiguous states. It is bounded on the east by Arkansas and Missouri, on the north by Kansas, on the northwest by Colorado, on the far west by New Mexico, and on the south and near - west by Texas. Much of its border with Texas lies along the Southern Oklahoma Aulacogen, a failed continental rift. The geologic figure defines the placement of the Red River.', 'short_answer': ''}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:21:09] #> Loading codec...\n",
      "[Jul 29, 15:21:09] #> Loading IVF...\n",
      "[Jul 29, 15:21:09] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4578.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:21:09] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1603.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: where is oklahoma located on the map of the united states, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2073, 2003, 5858, 2284, 2006, 1996, 4949, 1997, 1996, 2142,\n",
      "        2163,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:21:09 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'where is oklahoma located on the map of the united states', 'response': 'The answer is: Oklahoma is located in the central region of the United States, situated between Texas to its west and Arkansas to its east. It is bordered by Missouri to the north, Kansas to the northeast, and Louisiana to the southeast.', 'doc': 'Oklahoma', 'q_uid': -8736122236866420014, 'answers': {'long_answer': 'Oklahoma is the 20th - largest state in the United States, covering an area of 69,898 square miles ( 181,030 km ), with 68,667 square miles ( 177,850 km ) of land and 1,281 square miles ( 3,320 km ) of water. It lies partly in the Great Plains near the geographical center of the 48 contiguous states. It is bounded on the east by Arkansas and Missouri, on the north by Kansas, on the northwest by Colorado, on the far west by New Mexico, and on the south and near - west by Texas. Much of its border with Texas lies along the Southern Oklahoma Aulacogen, a failed continental rift. The geologic figure defines the placement of the Red River.', 'short_answer': ''}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:21:17] #> Loading codec...\n",
      "[Jul 29, 15:21:17] #> Loading IVF...\n",
      "[Jul 29, 15:21:17] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4544.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:21:17] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1683.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: when did oklahoma become a state what does the word oklahoma mean, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2043, 2106, 5858, 2468, 1037, 2110, 2054, 2515, 1996, 2773,\n",
      "        5858, 2812,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:21:17 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'when did oklahoma become a state what does the word oklahoma mean', 'response': 'The answer is: Oklahoma became a state on November 16, 1907. The term \"Oklahoma\" means \"people of the south wind.\"', 'doc': 'Oklahoma', 'q_uid': -3485714005907152096, 'answers': {'long_answer': \"Oklahoma ( / ˌoʊkləˈhoʊmə / ( listen ); Pawnee: Uukuhuúwa, Cayuga: Gahnawiyoˀgeh ) is a state in the South Central region of the United States. It is the 20th-most extensive and the 28th-most populous of the 50 United States. The state 's name is derived from the Choctaw words okla and humma, meaning `` red people ''. It is also known informally by its nickname, `` The Sooner State '', in reference to the non-Native settlers who staked their claims on land before the official opening date of lands in the western Oklahoma Territory or before the Indian Appropriations Act of 1889, which dramatically increased European - American settlement in the eastern Indian Territory. Oklahoma Territory and Indian Territory were merged into the State of Oklahoma when it became the 46th state to enter the union on November 16, 1907. Its residents are known as Oklahomans, or informally as Okies, and its capital and largest city is Oklahoma City.\", 'short_answer': ''}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:21:23] #> Loading codec...\n",
      "[Jul 29, 15:21:23] #> Loading IVF...\n",
      "[Jul 29, 15:21:23] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4837.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:21:23] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1231.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: when did oklahoma become part of the united states, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2043, 2106, 5858, 2468, 2112, 1997, 1996, 2142, 2163,  102,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:21:23 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'when did oklahoma become part of the united states', 'response': 'The answer is: Oklahoma became a U.S. state on November 16, 1907.', 'doc': 'Oklahoma', 'q_uid': -6235538092288743840, 'answers': {'long_answer': 'Admission to Union November 16, 1907 ( 46th )', 'short_answer': 'November 16, 1907 ('}}\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Just the Way You Are (Bruno Mars song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Karan Brar.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Chicago.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Academic term.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Achaemenid Empire.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Devin Hester.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/American Ninja Warrior (season 9).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of iOS devices.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of UFC records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Nigerian Navy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Isabelle Fuhrman.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jordana Brewster.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Spartan army.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2013 Open Championship.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of awards and nominations received by Game of Thrones.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Kilowatt hour.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Cheyenne Jackson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Indian cricket team in England in 1932.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/California State Assembly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Gregg Sulkin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of awards and nominations received by Bruno Mars.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Greta Garbo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Luka Modrić.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of longest suspension bridge spans.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Will Arnett.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Grayson Russell.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Andy Karl.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of awards and nominations received by Breaking Bad.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Freddy Rodriguez (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Perla Haney-Jardine.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Total Drama: Revenge of the Island.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Hair (musical).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Des Moines, Iowa.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Maisie Williams.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Sam Underwood.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Kristin Davis.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Nebraska Cornhuskers football.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Standard deviation.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Zachery Ty Bryan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Holy Roman Emperor.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Daniel Craig.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Margot Robbie.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Lindsey Stirling.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/AFL Grand Final.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Plitvice Lakes National Park.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/1982 FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Joe Manganiello.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Test cricket records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jameis Winston.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of districts of Nepal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Density of air.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Natural satellite.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/David Harbour.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Georgia Tech Yellow Jackets football.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jennifer Jones.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Laverne Cox.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/New Kids on the Block.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Oleg Salenko.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/The Lazy Song.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of German football champions.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/The Fresh Prince of Bel-Air.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/What Hurts the Most.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Eloise Mumford.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Zachary Gordon.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Kris Boyd.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Secretaries General of OPEC.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Two's complement.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Steel Vengeance.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Taylor Schilling.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2017–18 FC Barcelona season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Richard Madden.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Stone (unit).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Lauren Daigle.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/1972 Miami Dolphins season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2004 World Series.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Mario Kart.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/From the Land of the Moon (film).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Mesut Özil.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Rory Kinnear.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Mazda BT-50.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Adam Pascal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Tom Holland (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of continents by population.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/M*A*S*H (TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Category 4 Atlantic hurricanes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Victoria Justice.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Hawthorn Football Club.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Hawaii.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Dave Bautista.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Marvel Cinematic Universe films.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Kelvin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Elisa Donovan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Scott Clifton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Street & Racing Technology.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Love Island (series 1).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2016 ICC Women's World Twenty20.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Dane DeHaan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Heather Tom.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Peter Bergman.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Robert's Rules of Order.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Prime Minister of Jamaica.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Army–Navy Game.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Mark Addy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Spider-Man in film.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Teri Polo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Patrick J. Adams.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of governors of Madhya Pradesh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Twenty-foot equivalent unit.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Ariana Grande.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Clémence Poésy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Houston.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Yankee Stadium.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Fiddler on the Roof (film).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Victoria Hamilton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Shirley Henderson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Prime Ministers of Nepal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Tupac Shakur.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Safe & Sound (Taylor Swift song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/William Fichtner.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Being Human (UK TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Local governance in Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2002 FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Will Yun Lee.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jonathan Groff.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Chief Ministers of Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Nicholle Tom.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Tony Gwynn.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Tears in Heaven.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/America's Got Talent.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jessica Collins.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Los Angeles Open.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Grade inflation.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Rupert Grint.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Long Day's Journey into Night.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Law & Order: Criminal Intent.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Dungeons & Dragons rulebooks.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Chief Ministers of Nagaland.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Dancing with the Stars (U.S. season 24).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Courtney Ford.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Halley's Comet.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Rebecca Mader.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Seattle.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Demi Lovato.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Smallville.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Skye McCole Bartusiak.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Cillian Murphy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Cricket World Cup awards.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of islands by area.pdf\n",
      "=== Start nq on falcon-e-3B ===\n",
      "2025-07-29 15:21:24 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:21:24,897 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:21:26 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:21:29] #> Note: Output directory .ragatouille/colbert/indexes/nq_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:21:29] #> Will delete 10 files already at .ragatouille/colbert/indexes/nq_vector_db in 20 seconds...\n",
      "[Jul 29, 15:21:51] [0] \t\t #> Encoding 69 passages..\n",
      "[Jul 29, 15:21:51] [0] \t\t avg_doclen_est = 3.82608699798584 \t len(local_sample) = 69\n",
      "[Jul 29, 15:21:51] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/nq_vector_db/plan.json ..\n",
      "Warning: number of training points (251) is less than the minimum recommended (2560)\n",
      "used 3 iterations (0.0008s) to cluster 251 items into 256 clusters\n",
      "[0.001, 0.008, 0.006, 0.004, 0.007, 0.007, 0.016, 0.008, 0.012, 0.008, 0.004, 0.006, 0.007, 0.012, 0.003, 0.008, 0.007, 0.004, 0.006, 0.015, 0.013, 0.012, 0.009, 0.008, 0.006, 0.005, 0.006, 0.01, 0.008, 0.003, 0.017, 0.012, 0.017, 0.003, 0.003, 0.013, 0.003, 0.005, 0.009, 0.007, 0.005, 0.005, 0.01, 0.021, 0.003, 0.003, 0.01, 0.009, 0.013, 0.014, 0.003, 0.012, 0.005, 0.008, 0.005, 0.011, 0.006, 0.005, 0.004, 0.011, 0.008, 0.006, 0.014, 0.018, 0.004, 0.006, 0.016, 0.004, 0.007, 0.017, 0.005, 0.007, 0.009, 0.007, 0.01, 0.012, 0.007, 0.009, 0.012, 0.011, 0.012, 0.014, 0.009, 0.005, 0.003, 0.01, 0.021, 0.008, 0.013, 0.007, 0.015, 0.016, 0.007, 0.016, 0.011, 0.012, 0.015, 0.015, 0.005, 0.013, 0.011, 0.006, 0.006, 0.007, 0.01, 0.006, 0.009, 0.008, 0.005, 0.007, 0.01, 0.012, 0.022, 0.012, 0.015, 0.011, 0.008, 0.01, 0.011, 0.009, 0.004, 0.016, 0.004, 0.015, 0.004, 0.008, 0.005, 0.008]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:21:51] [0] \t\t #> Encoding 69 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 55.87it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2031.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:21:51] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:21:51] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:21:51] len(emb2pid) = 264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 128947.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:21:51] #> Saved optimized IVF to .ragatouille/colbert/indexes/nq_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:21:57] #> Loading codec...\n",
      "[Jul 29, 15:21:57] #> Loading IVF...\n",
      "[Jul 29, 15:21:57] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6345.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:21:57] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1347.78it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what episode of black mirror was hannah john kamen in, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2792,  1997,  2304,  5259,  2001,  8410,  2198,\n",
      "        22099,  1999,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:21:57 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'what episode of black mirror was hannah john kamen in', 'response': 'The answer is: \"Hannah John Kamen\" is not a character in *Black Mirror*. It seems there might be a typographical error in your question. If you meant to ask about a specific episode of *Black Mirror*, please provide more details so I can give you an accurate response.', 'doc': 'Hannah John-Kamen', 'q_uid': -6718102858366318183, 'answers': {'long_answer': \"Year Title Role Notes 2011 Misfits Carly Episode # 3.6 Black Mirror Selma Episode `` Fifteen Million Merits '' 2012 Whitechapel Roxy 2 episodes The Syndicate Young Shop Assistant Episode # 1.2 The Midnight Beast Pizza Girls Episode: `` Someone Called Sam '' The Hour Rosa Maria Ramírez 4 episodes 2014 Death in Paradise Yasmin Blake Series 3; Episode 6 Happy Valley Justine 2015 Cucumber Violet The Ark Nahlab Television film Banana Violet 2015 -- present Killjoys Dutch / Aneela Main role 2016 The Tunnel: Sabotage Rosa Persaud Game of Thrones Ornela Episodes: `` Oathbreaker '', `` Book of the Stranger '' Black Mirror Sonja Episode: `` Playtest ''\", 'short_answer': \"Episode `` Fifteen Million Merits ''\"}}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:22:04] #> Note: Output directory .ragatouille/colbert/indexes/nq_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:22:04] #> Will delete 10 files already at .ragatouille/colbert/indexes/nq_vector_db in 20 seconds...\n",
      "[Jul 29, 15:22:27] [0] \t\t #> Encoding 60 passages..\n",
      "[Jul 29, 15:22:27] [0] \t\t avg_doclen_est = 3.8333332538604736 \t len(local_sample) = 60\n",
      "[Jul 29, 15:22:27] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/nq_vector_db/plan.json ..\n",
      "Warning: number of training points (219) is less than the minimum recommended (1280)\n",
      "used 4 iterations (0.0011s) to cluster 219 items into 128 clusters\n",
      "[0.015, 0.007, 0.007, 0.003, 0.021, 0.01, 0.004, 0.014, 0.006, 0.013, 0.009, 0.01, 0.013, 0.018, 0.011, 0.004, 0.012, 0.007, 0.013, 0.013, 0.004, 0.009, 0.006, 0.009, 0.008, 0.011, 0.017, 0.015, 0.011, 0.009, 0.015, 0.004, 0.008, 0.006, 0.012, 0.02, 0.015, 0.01, 0.01, 0.007, 0.015, 0.014, 0.004, 0.014, 0.01, 0.013, 0.011, 0.006, 0.025, 0.013, 0.013, 0.01, 0.013, 0.01, 0.01, 0.013, 0.005, 0.02, 0.006, 0.011, 0.011, 0.006, 0.01, 0.009, 0.012, 0.008, 0.014, 0.014, 0.011, 0.025, 0.013, 0.009, 0.007, 0.003, 0.006, 0.007, 0.006, 0.019, 0.01, 0.008, 0.014, 0.017, 0.009, 0.018, 0.014, 0.016, 0.022, 0.005, 0.013, 0.01, 0.006, 0.017, 0.009, 0.012, 0.019, 0.009, 0.015, 0.011, 0.005, 0.012, 0.012, 0.017, 0.006, 0.007, 0.018, 0.005, 0.011, 0.016, 0.011, 0.02, 0.011, 0.008, 0.014, 0.016, 0.016, 0.01, 0.005, 0.013, 0.014, 0.009, 0.014, 0.005, 0.019, 0.008, 0.004, 0.007, 0.008, 0.017]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:22:27] [0] \t\t #> Encoding 60 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 55.79it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1330.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:22:27] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:22:27] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:22:27] len(emb2pid) = 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 138404.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:22:27] #> Saved optimized IVF to .ragatouille/colbert/indexes/nq_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:22:33] #> Loading codec...\n",
      "[Jul 29, 15:22:33] #> Loading IVF...\n",
      "[Jul 29, 15:22:33] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7025.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:22:33] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1568.55it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: where is oklahoma located in the united states, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2073, 2003, 5858, 2284, 1999, 1996, 2142, 2163,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:22:33 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'where is oklahoma located in the united states', 'response': 'The answer is: Oklahoma is located in the central part of the United States, bordered by Texas to the northwest, Kansas to the northeast, Nebraska to the southeast, and Missouri to the southwest.', 'doc': 'Oklahoma', 'q_uid': 3340122335577060793, 'answers': {'long_answer': 'Oklahoma is the 20th - largest state in the United States, covering an area of 69,898 square miles ( 181,030 km ), with 68,667 square miles ( 177,850 km ) of land and 1,281 square miles ( 3,320 km ) of water. It lies partly in the Great Plains near the geographical center of the 48 contiguous states. It is bounded on the east by Arkansas and Missouri, on the north by Kansas, on the northwest by Colorado, on the far west by New Mexico, and on the south and near - west by Texas. Much of its border with Texas lies along the Southern Oklahoma Aulacogen, a failed continental rift. The geologic figure defines the placement of the Red River.', 'short_answer': 'in the Great Plains near the geographical center of the 48 contiguous states.'}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:22:43] #> Loading codec...\n",
      "[Jul 29, 15:22:43] #> Loading IVF...\n",
      "[Jul 29, 15:22:43] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4766.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:22:43] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1485.24it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what part of the country is oklahoma considered, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2112, 1997, 1996, 2406, 2003, 5858, 2641,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:22:43 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'what part of the country is oklahoma considered', 'response': 'The answer is: United States', 'doc': 'Oklahoma', 'q_uid': -4372236156247664542, 'answers': {'long_answer': \"Oklahoma ( / ˌoʊkləˈhoʊmə / ( listen ); Pawnee: Uukuhuúwa, Cayuga: Gahnawiyoˀgeh ) is a state in the South Central region of the United States. It is the 20th-most extensive and the 28th-most populous of the 50 United States. The state 's name is derived from the Choctaw words okla and humma, meaning `` red people. '' It is also known informally by its nickname, `` The Sooner State, '' in reference to the non-Native settlers who staked their claims on land before the official opening date and the Indian Appropriations Act of 1889, which dramatically increased European - American settlement in the Indian Territory. Oklahoma Territory and Indian Territory were merged and Indian was dropped from the name. On November 16, 1907, Oklahoma became the 46th state to enter the union. Its residents are known as Oklahomans, or informally as Okies, and its capital and largest city is Oklahoma City.\", 'short_answer': 'a state in the South Central'}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:22:50] #> Loading codec...\n",
      "[Jul 29, 15:22:50] #> Loading IVF...\n",
      "[Jul 29, 15:22:50] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7530.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:22:50] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1818.08it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: how many states share a border with oklahoma, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2129, 2116, 2163, 3745, 1037, 3675, 2007, 5858,  102,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:22:50 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'how many states share a border with oklahoma', 'response': 'The answer is: 4\\n\\nThe four states that share a border with Oklahoma are Kansas, Missouri, Nebraska, and Texas.', 'doc': 'Oklahoma', 'q_uid': 3749925031204735637, 'answers': {'long_answer': 'Oklahoma is the 20th - largest state in the United States, covering an area of 69,898 square miles ( 181,035 km ), with 68,667 square miles ( 177,847 km ) of land and 1,281 square miles ( 3,188 km ) of water. It lies partly in the Great Plains near the geographical center of the 48 contiguous states. It is bounded on the east by Arkansas and Missouri, on the north by Kansas, on the northwest by Colorado, on the far west by New Mexico, and on the south and near - west by Texas. Much of its border with Texas lies along the Southern Oklahoma Aulacogen, a failed continental rift. The geologic figure defines the placement of the Red River.', 'short_answer': ''}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:22:59] #> Loading codec...\n",
      "[Jul 29, 15:22:59] #> Loading IVF...\n",
      "[Jul 29, 15:22:59] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5336.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:22:59] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1411.75it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: where is oklahoma located on the map of the united states, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2073, 2003, 5858, 2284, 2006, 1996, 4949, 1997, 1996, 2142,\n",
      "        2163,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:22:59 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'where is oklahoma located on the map of the united states', 'response': 'The answer is: Oklahoma is located in the central part of the United States, bordered by Texas to the north, Kansas to the east, Nebraska to the south, and Missouri to the west.', 'doc': 'Oklahoma', 'q_uid': -8736122236866420014, 'answers': {'long_answer': 'Oklahoma is the 20th - largest state in the United States, covering an area of 69,898 square miles ( 181,030 km ), with 68,667 square miles ( 177,850 km ) of land and 1,281 square miles ( 3,320 km ) of water. It lies partly in the Great Plains near the geographical center of the 48 contiguous states. It is bounded on the east by Arkansas and Missouri, on the north by Kansas, on the northwest by Colorado, on the far west by New Mexico, and on the south and near - west by Texas. Much of its border with Texas lies along the Southern Oklahoma Aulacogen, a failed continental rift. The geologic figure defines the placement of the Red River.', 'short_answer': ''}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:23:08] #> Loading codec...\n",
      "[Jul 29, 15:23:08] #> Loading IVF...\n",
      "[Jul 29, 15:23:08] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5737.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:23:08] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1688.53it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: when did oklahoma become a state what does the word oklahoma mean, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2043, 2106, 5858, 2468, 1037, 2110, 2054, 2515, 1996, 2773,\n",
      "        5858, 2812,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:23:08 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'when did oklahoma become a state what does the word oklahoma mean', 'response': 'The answer is: Oklahoma became a state on 14 April 1907. Oklahoma is a state in the United States.', 'doc': 'Oklahoma', 'q_uid': -3485714005907152096, 'answers': {'long_answer': \"Oklahoma ( / ˌoʊkləˈhoʊmə / ( listen ); Pawnee: Uukuhuúwa, Cayuga: Gahnawiyoˀgeh ) is a state in the South Central region of the United States. It is the 20th-most extensive and the 28th-most populous of the 50 United States. The state 's name is derived from the Choctaw words okla and humma, meaning `` red people ''. It is also known informally by its nickname, `` The Sooner State '', in reference to the non-Native settlers who staked their claims on land before the official opening date of lands in the western Oklahoma Territory or before the Indian Appropriations Act of 1889, which dramatically increased European - American settlement in the eastern Indian Territory. Oklahoma Territory and Indian Territory were merged into the State of Oklahoma when it became the 46th state to enter the union on November 16, 1907. Its residents are known as Oklahomans, or informally as Okies, and its capital and largest city is Oklahoma City.\", 'short_answer': ''}}\n",
      "Loading searcher for index nq_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:23:17] #> Loading codec...\n",
      "[Jul 29, 15:23:17] #> Loading IVF...\n",
      "[Jul 29, 15:23:17] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5691.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:23:17] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1609.48it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: when did oklahoma become part of the united states, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2043, 2106, 5858, 2468, 2112, 1997, 1996, 2142, 2163,  102,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:23:17 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'when did oklahoma become part of the united states', 'response': 'The answer is: 1805', 'doc': 'Oklahoma', 'q_uid': -6235538092288743840, 'answers': {'long_answer': 'Admission to Union November 16, 1907 ( 46th )', 'short_answer': 'November 16, 1907 ('}}\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Just the Way You Are (Bruno Mars song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Karan Brar.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Chicago.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Academic term.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Achaemenid Empire.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Devin Hester.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/American Ninja Warrior (season 9).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of iOS devices.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of UFC records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Nigerian Navy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Isabelle Fuhrman.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jordana Brewster.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Spartan army.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2013 Open Championship.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of awards and nominations received by Game of Thrones.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Kilowatt hour.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Cheyenne Jackson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Indian cricket team in England in 1932.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/California State Assembly.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Gregg Sulkin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of awards and nominations received by Bruno Mars.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Greta Garbo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Luka Modrić.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of longest suspension bridge spans.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Will Arnett.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Grayson Russell.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Andy Karl.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of awards and nominations received by Breaking Bad.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Freddy Rodriguez (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Perla Haney-Jardine.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Total Drama: Revenge of the Island.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Hair (musical).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Des Moines, Iowa.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Maisie Williams.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Sam Underwood.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Kristin Davis.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Nebraska Cornhuskers football.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Standard deviation.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Zachery Ty Bryan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Holy Roman Emperor.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Daniel Craig.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Margot Robbie.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Lindsey Stirling.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/AFL Grand Final.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Plitvice Lakes National Park.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/1982 FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Joe Manganiello.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Test cricket records.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jameis Winston.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of districts of Nepal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Density of air.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Natural satellite.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/David Harbour.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Georgia Tech Yellow Jackets football.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jennifer Jones.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Laverne Cox.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/New Kids on the Block.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Oleg Salenko.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/The Lazy Song.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of German football champions.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/The Fresh Prince of Bel-Air.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/What Hurts the Most.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Eloise Mumford.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Zachary Gordon.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Kris Boyd.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Secretaries General of OPEC.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Two's complement.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Steel Vengeance.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Taylor Schilling.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2017–18 FC Barcelona season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Richard Madden.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Stone (unit).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Lauren Daigle.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/1972 Miami Dolphins season.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2004 World Series.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Mario Kart.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/From the Land of the Moon (film).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Mesut Özil.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Rory Kinnear.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Mazda BT-50.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Adam Pascal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Tom Holland (actor).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of continents by population.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/M*A*S*H (TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Category 4 Atlantic hurricanes.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Victoria Justice.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Hawthorn Football Club.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Hawaii.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Dave Bautista.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Marvel Cinematic Universe films.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Kelvin.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Elisa Donovan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Scott Clifton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Street & Racing Technology.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Love Island (series 1).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2016 ICC Women's World Twenty20.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Dane DeHaan.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Heather Tom.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Peter Bergman.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Robert's Rules of Order.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Prime Minister of Jamaica.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Army–Navy Game.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Mark Addy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Spider-Man in film.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Teri Polo.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Patrick J. Adams.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of governors of Madhya Pradesh.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Twenty-foot equivalent unit.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Ariana Grande.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Clémence Poésy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Houston.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Yankee Stadium.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Fiddler on the Roof (film).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Victoria Hamilton.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Shirley Henderson.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Prime Ministers of Nepal.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Tupac Shakur.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Safe & Sound (Taylor Swift song).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/William Fichtner.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Being Human (UK TV series).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Local governance in Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/2002 FIFA World Cup.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Will Yun Lee.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jonathan Groff.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Chief Ministers of Kerala.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Nicholle Tom.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Tony Gwynn.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Tears in Heaven.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/America's Got Talent.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Jessica Collins.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Los Angeles Open.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Grade inflation.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Rupert Grint.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Long Day's Journey into Night.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Law & Order: Criminal Intent.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Dungeons & Dragons rulebooks.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of Chief Ministers of Nagaland.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Dancing with the Stars (U.S. season 24).pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Courtney Ford.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Halley's Comet.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Rebecca Mader.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Seattle.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Demi Lovato.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Smallville.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Skye McCole Bartusiak.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Cillian Murphy.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/Cricket World Cup awards.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/wiki_nq_docs/pdfs/List of islands by area.pdf\n",
      "=== Finish nq ===\n",
      "\n",
      "=== Start paper_tab on meno-tiny ===\n",
      "2025-07-29 15:23:18 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:23:18,303 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:23:22 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:23:24] #> Creating directory .ragatouille/colbert/indexes/paper_tab_vector_db \n",
      "\n",
      "\n",
      "[Jul 29, 15:23:27] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:23:27] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:23:27] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_tab_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.001s) to cluster 201 items into 128 clusters\n",
      "[0.013, 0.014, 0.003, 0.013, 0.016, 0.009, 0.008, 0.006, 0.036, 0.017, 0.011, 0.011, 0.012, 0.009, 0.011, 0.021, 0.01, 0.005, 0.006, 0.02, 0.014, 0.029, 0.013, 0.006, 0.015, 0.01, 0.006, 0.006, 0.015, 0.008, 0.01, 0.007, 0.006, 0.029, 0.012, 0.01, 0.019, 0.016, 0.013, 0.02, 0.004, 0.008, 0.007, 0.011, 0.01, 0.018, 0.013, 0.004, 0.026, 0.005, 0.011, 0.004, 0.013, 0.009, 0.026, 0.016, 0.009, 0.02, 0.015, 0.016, 0.018, 0.008, 0.008, 0.02, 0.005, 0.019, 0.008, 0.011, 0.014, 0.012, 0.008, 0.011, 0.013, 0.006, 0.011, 0.01, 0.027, 0.014, 0.016, 0.008, 0.01, 0.008, 0.008, 0.01, 0.005, 0.008, 0.009, 0.026, 0.006, 0.01, 0.016, 0.018, 0.01, 0.01, 0.005, 0.008, 0.005, 0.014, 0.009, 0.008, 0.014, 0.016, 0.016, 0.003, 0.017, 0.019, 0.011, 0.018, 0.014, 0.004, 0.013, 0.006, 0.019, 0.018, 0.007, 0.012, 0.007, 0.016, 0.006, 0.015, 0.008, 0.006, 0.008, 0.009, 0.009, 0.026, 0.005, 0.011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:23:27] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 66.87it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1818.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:23:27] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:23:27] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:23:27] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 154762.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:23:27] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_tab_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_tab_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:23:33] #> Loading codec...\n",
      "[Jul 29, 15:23:33] #> Loading IVF...\n",
      "[Jul 29, 15:23:33] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5974.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:23:33] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1575.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What baselines did they consider?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054, 26163,  2015,  2106,  2027,  5136,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:23:33 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'What baselines did they consider?', 'response': 'The answer is: The baselines they considered were 1980, 1990, 2000, 2010, and 2020.', 'doc': '1809.01202', 'q_uid': '4cbe5a36b492b99f9f9fea8081fe4ba10a7a0e94', 'answers': [{'answer': 'state-of-the-art PDTB taggers', 'type': 'extractive'}, {'answer': 'Linear SVM, RBF SVM, and Random Forest', 'type': 'abstractive'}]}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:23:36] #> Note: Output directory .ragatouille/colbert/indexes/paper_tab_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:23:36] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_tab_vector_db in 20 seconds...\n",
      "[Jul 29, 15:23:58] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:23:58] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:23:58] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_tab_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 4 iterations (0.0012s) to cluster 201 items into 128 clusters\n",
      "[0.013, 0.014, 0.003, 0.013, 0.016, 0.009, 0.008, 0.006, 0.036, 0.017, 0.011, 0.011, 0.012, 0.009, 0.011, 0.021, 0.01, 0.005, 0.006, 0.02, 0.014, 0.029, 0.013, 0.006, 0.015, 0.01, 0.006, 0.006, 0.015, 0.008, 0.01, 0.007, 0.006, 0.029, 0.012, 0.01, 0.019, 0.016, 0.013, 0.02, 0.004, 0.008, 0.007, 0.011, 0.01, 0.018, 0.013, 0.004, 0.026, 0.005, 0.011, 0.004, 0.013, 0.009, 0.026, 0.016, 0.009, 0.02, 0.015, 0.016, 0.018, 0.008, 0.008, 0.02, 0.005, 0.019, 0.008, 0.011, 0.014, 0.012, 0.008, 0.011, 0.013, 0.006, 0.011, 0.01, 0.027, 0.014, 0.016, 0.008, 0.01, 0.008, 0.008, 0.01, 0.005, 0.008, 0.009, 0.026, 0.006, 0.01, 0.016, 0.018, 0.01, 0.01, 0.005, 0.008, 0.005, 0.014, 0.009, 0.008, 0.014, 0.016, 0.016, 0.003, 0.017, 0.019, 0.011, 0.018, 0.014, 0.004, 0.013, 0.006, 0.019, 0.018, 0.007, 0.012, 0.007, 0.016, 0.006, 0.015, 0.008, 0.006, 0.008, 0.009, 0.009, 0.026, 0.005, 0.011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:23:59] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 67.10it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2437.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:23:59] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:23:59] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:23:59] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 161029.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:23:59] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_tab_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_tab_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:24:05] #> Loading codec...\n",
      "[Jul 29, 15:24:05] #> Loading IVF...\n",
      "[Jul 29, 15:24:05] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6195.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:24:05] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1738.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: Does this approach perform better in the multi-domain or single-domain setting?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2515, 2023, 3921, 4685, 2488, 1999, 1996, 4800, 1011, 5884,\n",
      "        2030, 2309, 1011, 5884, 4292, 1029,  102,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:24:05 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'Does this approach perform better in the multi-domain or single-domain setting?', 'response': 'The answer is: multi-domain', 'doc': '1909.00754', 'q_uid': 'ed7a3e7fc1672f85a768613e7d1b419475950ab4', 'answers': [{'answer': 'single-domain setting', 'type': 'abstractive'}]}\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.10011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.08559.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.03538.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11047.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.08051.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.05280.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03354.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03242.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.08987.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.02086.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1803.09230.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.13066.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.09123.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.01878.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.04866.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.07904.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00175.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03135.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.05467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.08345.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.00189.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.01010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.04642.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.07711.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.12085.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03544.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.04033.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.10161.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.10225.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.11180.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.04330.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01772.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.06757.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.09029.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.12129.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01207.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.05320.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00279.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.12254.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.07555.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.10288.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.05236.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.06937.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.02550.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08673.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.08960.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.06162.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.07789.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.02070.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.08675.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.09194.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.09588.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.04631.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1712.05999.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.08210.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.12196.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.01694.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.07816.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.02286.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.02877.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.06748.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1708.09609.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.06537.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.11769.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.08142.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.01088.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.10361.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.01265.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.05493.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08859.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.04798.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1610.00879.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.09678.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.00864.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.01608.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1812.10479.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.08079.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.10551.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.00825.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08089.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.00514.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.05434.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.02711.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.06424.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1812.01704.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.07734.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.05474.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1712.00991.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.01769.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.06286.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.00137.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.00330.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.04899.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01247.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.10049.pdf\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:24:07] #> Note: Output directory .ragatouille/colbert/indexes/paper_tab_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:24:07] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_tab_vector_db in 20 seconds...\n",
      "[Jul 29, 15:24:30] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:24:30] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:24:30] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_tab_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0014s) to cluster 201 items into 128 clusters\n",
      "[0.021, 0.018, 0.009, 0.019, 0.019, 0.024, 0.011, 0.014, 0.039, 0.022, 0.017, 0.015, 0.014, 0.019, 0.014, 0.029, 0.016, 0.009, 0.009, 0.021, 0.016, 0.036, 0.024, 0.018, 0.018, 0.02, 0.008, 0.009, 0.02, 0.016, 0.012, 0.009, 0.016, 0.034, 0.014, 0.017, 0.034, 0.024, 0.015, 0.027, 0.007, 0.016, 0.015, 0.012, 0.014, 0.024, 0.015, 0.015, 0.041, 0.011, 0.013, 0.012, 0.018, 0.019, 0.037, 0.018, 0.014, 0.025, 0.019, 0.018, 0.025, 0.021, 0.016, 0.026, 0.005, 0.023, 0.012, 0.019, 0.016, 0.017, 0.01, 0.018, 0.022, 0.011, 0.023, 0.017, 0.034, 0.029, 0.019, 0.021, 0.014, 0.016, 0.013, 0.014, 0.006, 0.011, 0.015, 0.028, 0.008, 0.011, 0.02, 0.021, 0.013, 0.013, 0.012, 0.012, 0.015, 0.023, 0.016, 0.012, 0.016, 0.02, 0.02, 0.013, 0.027, 0.023, 0.02, 0.024, 0.017, 0.007, 0.019, 0.008, 0.032, 0.021, 0.009, 0.016, 0.018, 0.024, 0.013, 0.017, 0.011, 0.009, 0.01, 0.02, 0.014, 0.034, 0.009, 0.021]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:24:30] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 68.25it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2646.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:24:30] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:24:30] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:24:30] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 164482.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:24:30] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_tab_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_tab_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:24:36] #> Loading codec...\n",
      "[Jul 29, 15:24:36] #> Loading IVF...\n",
      "[Jul 29, 15:24:36] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6326.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:24:36] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1754.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what language pairs are explored?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2653,  7689,  2024, 10641,  1029,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:24:36 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'what language pairs are explored?', 'response': 'Hindi, English, Kannada, Telugu, Assamese, Bengali and Malayalam', 'doc': '1912.01214', 'q_uid': '5eda469a8a77f028d0c5f1acd296111085614537', 'answers': [{'answer': 'De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru', 'type': 'abstractive'}, {'answer': 'French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation', 'type': 'extractive'}]}\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1712.03547.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.00968.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.12260.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.06675.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.06670.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.03106.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.12738.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.09393.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.05241.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.11645.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.00939.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.08949.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13375.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1610.07809.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09484.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.03764.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.13109.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01383.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06264.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.13215.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.07481.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.00540.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1609.00559.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03788.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.08050.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.11204.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.07723.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1710.09340.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.09795.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.11402.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.10810.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1807.07961.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.10644.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1607.06025.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.14497.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.02279.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.05574.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.08868.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1802.06024.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.03459.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.08899.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.09666.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.11235.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.07464.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.11432.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00361.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01984.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.10869.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.05058.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.06036.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.07683.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.10367.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.03449.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.08960.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03310.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00430.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13695.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.10503.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.05918.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.06566.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.02906.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03814.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.03430.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.00912.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.04642.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.12579.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.03044.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.00110.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.03288.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.06743.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06267.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1612.05270.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06379.pdf\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:24:39] #> Note: Output directory .ragatouille/colbert/indexes/paper_tab_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:24:39] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_tab_vector_db in 20 seconds...\n",
      "[Jul 29, 15:25:01] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:25:01] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:25:01] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_tab_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.001s) to cluster 201 items into 128 clusters\n",
      "[0.013, 0.014, 0.003, 0.013, 0.016, 0.009, 0.008, 0.006, 0.037, 0.017, 0.011, 0.011, 0.012, 0.009, 0.012, 0.021, 0.01, 0.005, 0.006, 0.02, 0.014, 0.029, 0.013, 0.006, 0.015, 0.01, 0.006, 0.006, 0.015, 0.008, 0.01, 0.007, 0.006, 0.03, 0.012, 0.01, 0.019, 0.016, 0.013, 0.02, 0.005, 0.008, 0.007, 0.011, 0.01, 0.018, 0.014, 0.004, 0.026, 0.005, 0.011, 0.004, 0.013, 0.009, 0.026, 0.016, 0.009, 0.02, 0.015, 0.016, 0.018, 0.008, 0.008, 0.02, 0.005, 0.02, 0.009, 0.012, 0.014, 0.013, 0.008, 0.012, 0.013, 0.006, 0.011, 0.01, 0.027, 0.014, 0.016, 0.008, 0.01, 0.008, 0.008, 0.01, 0.005, 0.008, 0.01, 0.026, 0.006, 0.01, 0.016, 0.018, 0.01, 0.01, 0.005, 0.008, 0.005, 0.014, 0.009, 0.008, 0.014, 0.016, 0.016, 0.003, 0.017, 0.019, 0.011, 0.018, 0.014, 0.004, 0.013, 0.006, 0.019, 0.019, 0.007, 0.012, 0.007, 0.016, 0.006, 0.015, 0.009, 0.006, 0.008, 0.009, 0.009, 0.026, 0.005, 0.011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:25:01] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 79.05it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2811.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:25:01] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:25:01] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:25:01] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 128684.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:25:01] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_tab_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_tab_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:25:08] #> Loading codec...\n",
      "[Jul 29, 15:25:08] #> Loading IVF...\n",
      "[Jul 29, 15:25:08] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5084.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:25:08] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1869.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What accuracy does the proposed system achieve?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054, 10640,  2515,  1996,  3818,  2291,  6162,  1029,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:25:08 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'meno-tiny', 'question': 'What accuracy does the proposed system achieve?', 'response': 'The answer is: 100%', 'doc': '1801.05147', 'q_uid': 'ef4dba073d24042f24886580ae77add5326f2130', 'answers': [{'answer': 'F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ', 'type': 'abstractive'}, {'answer': 'F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)', 'type': 'abstractive'}]}\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.05970.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05246.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03597.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.05907.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.09369.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.04721.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.09920.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.04952.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.01799.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.02492.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.02262.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.00530.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.10084.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.05828.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.02013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.06492.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09587.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.01214.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08976.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1712.03556.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.00069.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.00185.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.02821.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.00172.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11687.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.01541.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13714.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1702.03342.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.12795.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.04269.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.02507.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.02480.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.04513.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01359.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.11951.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.04511.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.05829.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03891.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.00663.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.09314.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.05153.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.04002.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.14537.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.07245.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.00672.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.03060.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.03569.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.08298.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01673.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1812.06864.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08824.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.10525.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.00079.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.07195.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.03710.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.08385.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11365.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.10217.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.00108.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.11901.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00694.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1706.08032.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.12218.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00512.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.05413.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11546.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.11221.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05855.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01664.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.08139.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.03382.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.00563.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.09755.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.00106.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.07090.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.06044.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09270.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08041.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06083.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.06592.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.02100.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.10806.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.01680.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.01081.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.01980.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.09103.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.07044.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.00652.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00105.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.03014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.07228.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.09722.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.05377.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01958.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00578.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.00458.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.05154.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.12885.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.07996.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.04181.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.11910.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11297.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.10254.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.06644.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.11563.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.09774.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08962.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.11346.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.06888.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.05584.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.10435.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.05752.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.04960.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03405.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1612.08205.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1812.06705.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.02257.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.10500.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.06194.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.03214.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.03866.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03744.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1604.00400.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.03457.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1710.06700.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.02339.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.06538.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00252.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.05572.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06151.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.07333.pdf\n",
      "=== Start paper_tab on qwen2.5-1.5B ===\n",
      "2025-07-29 15:25:08 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:25:09,179 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:25:13 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:25:15] #> Note: Output directory .ragatouille/colbert/indexes/paper_tab_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:25:15] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_tab_vector_db in 20 seconds...\n",
      "[Jul 29, 15:25:38] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:25:38] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:25:38] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_tab_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0009s) to cluster 201 items into 128 clusters\n",
      "[0.013, 0.014, 0.003, 0.013, 0.016, 0.009, 0.008, 0.006, 0.036, 0.017, 0.011, 0.011, 0.012, 0.009, 0.011, 0.021, 0.01, 0.005, 0.006, 0.02, 0.014, 0.029, 0.013, 0.006, 0.015, 0.01, 0.006, 0.006, 0.015, 0.008, 0.01, 0.007, 0.006, 0.029, 0.012, 0.01, 0.019, 0.016, 0.013, 0.02, 0.004, 0.008, 0.007, 0.011, 0.01, 0.018, 0.013, 0.004, 0.026, 0.005, 0.011, 0.004, 0.013, 0.009, 0.026, 0.016, 0.009, 0.02, 0.015, 0.016, 0.018, 0.008, 0.008, 0.02, 0.005, 0.019, 0.008, 0.011, 0.014, 0.012, 0.008, 0.011, 0.013, 0.006, 0.011, 0.01, 0.027, 0.014, 0.016, 0.008, 0.01, 0.008, 0.008, 0.01, 0.005, 0.008, 0.009, 0.026, 0.006, 0.01, 0.016, 0.018, 0.01, 0.01, 0.005, 0.008, 0.005, 0.014, 0.009, 0.008, 0.014, 0.016, 0.016, 0.003, 0.017, 0.019, 0.011, 0.018, 0.014, 0.004, 0.013, 0.006, 0.019, 0.018, 0.007, 0.012, 0.007, 0.016, 0.006, 0.015, 0.008, 0.006, 0.008, 0.009, 0.009, 0.026, 0.005, 0.011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:25:38] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 65.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2155.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:25:38] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:25:38] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:25:38] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 158696.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:25:38] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_tab_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_tab_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:25:44] #> Loading codec...\n",
      "[Jul 29, 15:25:44] #> Loading IVF...\n",
      "[Jul 29, 15:25:44] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5256.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:25:44] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1208.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What baselines did they consider?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054, 26163,  2015,  2106,  2027,  5136,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:25:44 CallLLM\n",
      "{'model': 'qwen2.5-1.5B', 'question': 'What baselines did they consider?', 'response': 'The answer is: None', 'doc': '1809.01202', 'q_uid': '4cbe5a36b492b99f9f9fea8081fe4ba10a7a0e94', 'answers': [{'answer': 'state-of-the-art PDTB taggers', 'type': 'extractive'}, {'answer': 'Linear SVM, RBF SVM, and Random Forest', 'type': 'abstractive'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:25:46] #> Note: Output directory .ragatouille/colbert/indexes/paper_tab_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:25:46] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_tab_vector_db in 20 seconds...\n",
      "[Jul 29, 15:26:09] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:26:09] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:26:09] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_tab_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 4 iterations (0.0013s) to cluster 201 items into 128 clusters\n",
      "[0.013, 0.014, 0.003, 0.013, 0.016, 0.009, 0.008, 0.006, 0.036, 0.017, 0.011, 0.011, 0.012, 0.009, 0.011, 0.021, 0.01, 0.005, 0.006, 0.02, 0.014, 0.029, 0.013, 0.006, 0.015, 0.01, 0.006, 0.006, 0.015, 0.008, 0.01, 0.007, 0.006, 0.029, 0.012, 0.01, 0.019, 0.016, 0.013, 0.02, 0.004, 0.008, 0.007, 0.011, 0.01, 0.018, 0.013, 0.004, 0.026, 0.005, 0.011, 0.004, 0.013, 0.009, 0.026, 0.016, 0.009, 0.02, 0.015, 0.016, 0.018, 0.008, 0.008, 0.02, 0.005, 0.019, 0.008, 0.011, 0.014, 0.012, 0.008, 0.011, 0.013, 0.006, 0.011, 0.01, 0.027, 0.014, 0.016, 0.008, 0.01, 0.008, 0.008, 0.01, 0.005, 0.008, 0.009, 0.026, 0.006, 0.01, 0.016, 0.018, 0.01, 0.01, 0.005, 0.008, 0.005, 0.014, 0.009, 0.008, 0.014, 0.016, 0.016, 0.003, 0.017, 0.019, 0.011, 0.018, 0.014, 0.004, 0.013, 0.006, 0.019, 0.018, 0.007, 0.012, 0.007, 0.016, 0.006, 0.015, 0.008, 0.006, 0.008, 0.009, 0.009, 0.026, 0.005, 0.011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:26:09] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 74.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2581.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:26:09] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:26:09] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:26:09] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 155750.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:26:09] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_tab_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_tab_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:26:16] #> Loading codec...\n",
      "[Jul 29, 15:26:16] #> Loading IVF...\n",
      "[Jul 29, 15:26:16] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4760.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:26:16] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1307.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: Does this approach perform better in the multi-domain or single-domain setting?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2515, 2023, 3921, 4685, 2488, 1999, 1996, 4800, 1011, 5884,\n",
      "        2030, 2309, 1011, 5884, 4292, 1029,  102,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:26:16 CallLLM\n",
      "{'model': 'qwen2.5-1.5B', 'question': 'Does this approach perform better in the multi-domain or single-domain setting?', 'response': 'The answer is: Multi-domain', 'doc': '1909.00754', 'q_uid': 'ed7a3e7fc1672f85a768613e7d1b419475950ab4', 'answers': [{'answer': 'single-domain setting', 'type': 'abstractive'}]}\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.10011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.08559.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.03538.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11047.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.08051.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.05280.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03354.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03242.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.08987.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.02086.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1803.09230.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.13066.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.09123.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.01878.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.04866.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.07904.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00175.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03135.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.05467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.08345.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.00189.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.01010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.04642.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.07711.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.12085.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03544.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.04033.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.10161.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.10225.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.11180.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.04330.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01772.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.06757.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.09029.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.12129.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01207.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.05320.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00279.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.12254.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.07555.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.10288.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.05236.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.06937.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.02550.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08673.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.08960.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.06162.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.07789.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.02070.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.08675.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.09194.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.09588.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.04631.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1712.05999.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.08210.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.12196.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.01694.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.07816.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.02286.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.02877.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.06748.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1708.09609.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.06537.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.11769.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.08142.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.01088.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.10361.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.01265.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.05493.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08859.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.04798.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1610.00879.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.09678.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.00864.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.01608.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1812.10479.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.08079.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.10551.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.00825.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08089.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.00514.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.05434.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.02711.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.06424.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1812.01704.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.07734.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.05474.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1712.00991.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.01769.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.06286.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.00137.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.00330.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.04899.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01247.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.10049.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:26:18] #> Note: Output directory .ragatouille/colbert/indexes/paper_tab_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:26:18] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_tab_vector_db in 20 seconds...\n",
      "[Jul 29, 15:26:42] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:26:42] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:26:42] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_tab_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.001s) to cluster 201 items into 128 clusters\n",
      "[0.021, 0.018, 0.009, 0.019, 0.019, 0.024, 0.011, 0.014, 0.039, 0.022, 0.017, 0.015, 0.014, 0.019, 0.014, 0.029, 0.016, 0.009, 0.009, 0.021, 0.016, 0.036, 0.024, 0.018, 0.018, 0.02, 0.008, 0.009, 0.02, 0.016, 0.012, 0.009, 0.016, 0.034, 0.014, 0.017, 0.034, 0.024, 0.015, 0.027, 0.007, 0.016, 0.015, 0.012, 0.014, 0.024, 0.015, 0.015, 0.041, 0.011, 0.013, 0.012, 0.018, 0.019, 0.037, 0.018, 0.014, 0.025, 0.019, 0.018, 0.025, 0.021, 0.016, 0.026, 0.005, 0.023, 0.012, 0.019, 0.016, 0.017, 0.01, 0.018, 0.022, 0.011, 0.023, 0.017, 0.034, 0.029, 0.019, 0.021, 0.014, 0.016, 0.013, 0.014, 0.006, 0.011, 0.015, 0.028, 0.008, 0.011, 0.02, 0.021, 0.013, 0.013, 0.012, 0.012, 0.015, 0.023, 0.016, 0.012, 0.016, 0.02, 0.02, 0.013, 0.027, 0.023, 0.02, 0.024, 0.017, 0.007, 0.019, 0.008, 0.032, 0.021, 0.009, 0.016, 0.018, 0.024, 0.013, 0.017, 0.011, 0.009, 0.01, 0.02, 0.014, 0.034, 0.009, 0.021]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:26:42] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 70.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2686.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:26:42] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:26:42] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:26:42] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 122629.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:26:42] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_tab_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_tab_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:26:49] #> Loading codec...\n",
      "[Jul 29, 15:26:49] #> Loading IVF...\n",
      "[Jul 29, 15:26:49] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5761.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:26:49] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1678.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what language pairs are explored?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2653,  7689,  2024, 10641,  1029,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:26:49 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'what language pairs are explored?', 'response': 'English, Hindi, Tamil, Telugu, Kannada, Marathi, Gujarati, Urdu, Oriya, Bengali, Punjabi, Malayalam, Konkani, Sanskrit', 'doc': '1912.01214', 'q_uid': '5eda469a8a77f028d0c5f1acd296111085614537', 'answers': [{'answer': 'De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru', 'type': 'abstractive'}, {'answer': 'French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation', 'type': 'extractive'}]}\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1712.03547.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.00968.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.12260.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.06675.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.06670.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.03106.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.12738.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.09393.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.05241.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.11645.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.00939.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.08949.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13375.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1610.07809.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09484.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.03764.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.13109.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01383.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06264.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.13215.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.07481.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.00540.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1609.00559.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03788.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.08050.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.11204.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.07723.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1710.09340.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.09795.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.11402.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.10810.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1807.07961.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.10644.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1607.06025.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.14497.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.02279.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.05574.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.08868.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1802.06024.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.03459.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.08899.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.09666.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.11235.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.07464.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.11432.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00361.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01984.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.10869.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.05058.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.06036.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.07683.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.10367.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.03449.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.08960.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03310.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00430.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13695.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.10503.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.05918.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.06566.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.02906.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03814.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.03430.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.00912.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.04642.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.12579.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.03044.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.00110.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.03288.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.06743.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06267.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1612.05270.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06379.pdf\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:26:52] #> Note: Output directory .ragatouille/colbert/indexes/paper_tab_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:26:52] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_tab_vector_db in 20 seconds...\n",
      "[Jul 29, 15:27:15] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:27:15] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:27:15] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_tab_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0016s) to cluster 201 items into 128 clusters\n",
      "[0.013, 0.014, 0.003, 0.013, 0.016, 0.009, 0.008, 0.006, 0.037, 0.017, 0.011, 0.011, 0.012, 0.009, 0.012, 0.021, 0.01, 0.005, 0.006, 0.02, 0.014, 0.029, 0.013, 0.006, 0.015, 0.01, 0.006, 0.006, 0.015, 0.008, 0.01, 0.007, 0.006, 0.03, 0.012, 0.01, 0.019, 0.016, 0.013, 0.02, 0.005, 0.008, 0.007, 0.011, 0.01, 0.018, 0.014, 0.004, 0.026, 0.005, 0.011, 0.004, 0.013, 0.009, 0.026, 0.016, 0.009, 0.02, 0.015, 0.016, 0.018, 0.008, 0.008, 0.02, 0.005, 0.02, 0.009, 0.012, 0.014, 0.013, 0.008, 0.012, 0.013, 0.006, 0.011, 0.01, 0.027, 0.014, 0.016, 0.008, 0.01, 0.008, 0.008, 0.01, 0.005, 0.008, 0.01, 0.026, 0.006, 0.01, 0.016, 0.018, 0.01, 0.01, 0.005, 0.008, 0.005, 0.014, 0.009, 0.008, 0.014, 0.016, 0.016, 0.003, 0.017, 0.019, 0.011, 0.018, 0.014, 0.004, 0.013, 0.006, 0.019, 0.019, 0.007, 0.012, 0.007, 0.016, 0.006, 0.015, 0.009, 0.006, 0.008, 0.009, 0.009, 0.026, 0.005, 0.011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:27:15] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 73.75it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2987.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:27:15] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:27:15] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:27:15] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 160691.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:27:15] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_tab_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_tab_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:27:21] #> Loading codec...\n",
      "[Jul 29, 15:27:21] #> Loading IVF...\n",
      "[Jul 29, 15:27:21] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6574.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:27:21] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1646.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What accuracy does the proposed system achieve?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054, 10640,  2515,  1996,  3818,  2291,  6162,  1029,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:27:21 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-1.5B', 'question': 'What accuracy does the proposed system achieve?', 'response': 'The proposed system achieves an accuracy of 98%.', 'doc': '1801.05147', 'q_uid': 'ef4dba073d24042f24886580ae77add5326f2130', 'answers': [{'answer': 'F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ', 'type': 'abstractive'}, {'answer': 'F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)', 'type': 'abstractive'}]}\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.05970.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05246.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03597.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.05907.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.09369.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.04721.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.09920.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.04952.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.01799.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.02492.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.02262.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.00530.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.10084.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.05828.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.02013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.06492.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09587.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.01214.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08976.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1712.03556.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.00069.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.00185.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.02821.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.00172.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11687.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.01541.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13714.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1702.03342.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.12795.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.04269.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.02507.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.02480.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.04513.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01359.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.11951.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.04511.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.05829.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03891.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.00663.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.09314.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.05153.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.04002.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.14537.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.07245.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.00672.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.03060.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.03569.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.08298.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01673.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1812.06864.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08824.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.10525.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.00079.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.07195.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.03710.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.08385.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11365.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.10217.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.00108.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.11901.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00694.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1706.08032.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.12218.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00512.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.05413.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11546.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.11221.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05855.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01664.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.08139.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.03382.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.00563.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.09755.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.00106.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.07090.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.06044.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09270.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08041.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06083.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.06592.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.02100.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.10806.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.01680.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.01081.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.01980.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.09103.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.07044.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.00652.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00105.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.03014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.07228.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.09722.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.05377.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01958.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00578.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.00458.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.05154.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.12885.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.07996.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.04181.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.11910.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11297.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.10254.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.06644.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.11563.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.09774.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08962.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.11346.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.06888.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.05584.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.10435.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.05752.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.04960.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03405.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1612.08205.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1812.06705.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.02257.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.10500.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.06194.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.03214.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.03866.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03744.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1604.00400.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.03457.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1710.06700.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.02339.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.06538.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00252.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.05572.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06151.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.07333.pdf\n",
      "=== Start paper_tab on qwen2.5-3B ===\n",
      "2025-07-29 15:27:21 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:27:21,888 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.96s/it]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:27:28 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:27:31] #> Note: Output directory .ragatouille/colbert/indexes/paper_tab_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:27:31] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_tab_vector_db in 20 seconds...\n",
      "[Jul 29, 15:27:54] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:27:54] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:27:54] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_tab_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.001s) to cluster 201 items into 128 clusters\n",
      "[0.013, 0.014, 0.003, 0.013, 0.016, 0.009, 0.008, 0.006, 0.036, 0.017, 0.011, 0.011, 0.012, 0.009, 0.011, 0.021, 0.01, 0.005, 0.006, 0.02, 0.014, 0.029, 0.013, 0.006, 0.015, 0.01, 0.006, 0.006, 0.015, 0.008, 0.01, 0.007, 0.006, 0.029, 0.012, 0.01, 0.019, 0.016, 0.013, 0.02, 0.004, 0.008, 0.007, 0.011, 0.01, 0.018, 0.013, 0.004, 0.026, 0.005, 0.011, 0.004, 0.013, 0.009, 0.026, 0.016, 0.009, 0.02, 0.015, 0.016, 0.018, 0.008, 0.008, 0.02, 0.005, 0.019, 0.008, 0.011, 0.014, 0.012, 0.008, 0.011, 0.013, 0.006, 0.011, 0.01, 0.027, 0.014, 0.016, 0.008, 0.01, 0.008, 0.008, 0.01, 0.005, 0.008, 0.009, 0.026, 0.006, 0.01, 0.016, 0.018, 0.01, 0.01, 0.005, 0.008, 0.005, 0.014, 0.009, 0.008, 0.014, 0.016, 0.016, 0.003, 0.017, 0.019, 0.011, 0.018, 0.014, 0.004, 0.013, 0.006, 0.019, 0.018, 0.007, 0.012, 0.007, 0.016, 0.006, 0.015, 0.008, 0.006, 0.008, 0.009, 0.009, 0.026, 0.005, 0.011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:27:54] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 77.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2709.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:27:54] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:27:54] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:27:54] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 148676.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:27:54] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_tab_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_tab_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:28:00] #> Loading codec...\n",
      "[Jul 29, 15:28:00] #> Loading IVF...\n",
      "[Jul 29, 15:28:00] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6017.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:28:00] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1437.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What baselines did they consider?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054, 26163,  2015,  2106,  2027,  5136,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:28:00 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'What baselines did they consider?', 'response': 'The answer is: None provided', 'doc': '1809.01202', 'q_uid': '4cbe5a36b492b99f9f9fea8081fe4ba10a7a0e94', 'answers': [{'answer': 'state-of-the-art PDTB taggers', 'type': 'extractive'}, {'answer': 'Linear SVM, RBF SVM, and Random Forest', 'type': 'abstractive'}]}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:28:03] #> Note: Output directory .ragatouille/colbert/indexes/paper_tab_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:28:03] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_tab_vector_db in 20 seconds...\n",
      "[Jul 29, 15:28:26] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:28:26] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:28:26] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_tab_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 4 iterations (0.0016s) to cluster 201 items into 128 clusters\n",
      "[0.013, 0.014, 0.003, 0.013, 0.016, 0.009, 0.008, 0.006, 0.036, 0.017, 0.011, 0.011, 0.012, 0.009, 0.011, 0.021, 0.01, 0.005, 0.006, 0.02, 0.014, 0.029, 0.013, 0.006, 0.015, 0.01, 0.006, 0.006, 0.015, 0.008, 0.01, 0.007, 0.006, 0.029, 0.012, 0.01, 0.019, 0.016, 0.013, 0.02, 0.004, 0.008, 0.007, 0.011, 0.01, 0.018, 0.013, 0.004, 0.026, 0.005, 0.011, 0.004, 0.013, 0.009, 0.026, 0.016, 0.009, 0.02, 0.015, 0.016, 0.018, 0.008, 0.008, 0.02, 0.005, 0.019, 0.008, 0.011, 0.014, 0.012, 0.008, 0.011, 0.013, 0.006, 0.011, 0.01, 0.027, 0.014, 0.016, 0.008, 0.01, 0.008, 0.008, 0.01, 0.005, 0.008, 0.009, 0.026, 0.006, 0.01, 0.016, 0.018, 0.01, 0.01, 0.005, 0.008, 0.005, 0.014, 0.009, 0.008, 0.014, 0.016, 0.016, 0.003, 0.017, 0.019, 0.011, 0.018, 0.014, 0.004, 0.013, 0.006, 0.019, 0.018, 0.007, 0.012, 0.007, 0.016, 0.006, 0.015, 0.008, 0.006, 0.008, 0.009, 0.009, 0.026, 0.005, 0.011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:28:26] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 54.30it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1907.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:28:26] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:28:26] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:28:26] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 151444.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:28:26] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_tab_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_tab_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:28:32] #> Loading codec...\n",
      "[Jul 29, 15:28:32] #> Loading IVF...\n",
      "[Jul 29, 15:28:32] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6250.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:28:32] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1099.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: Does this approach perform better in the multi-domain or single-domain setting?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2515, 2023, 3921, 4685, 2488, 1999, 1996, 4800, 1011, 5884,\n",
      "        2030, 2309, 1011, 5884, 4292, 1029,  102,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:28:32 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'Does this approach perform better in the multi-domain or single-domain setting?', 'response': 'The answer is: not specified', 'doc': '1909.00754', 'q_uid': 'ed7a3e7fc1672f85a768613e7d1b419475950ab4', 'answers': [{'answer': 'single-domain setting', 'type': 'abstractive'}]}\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.10011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.08559.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.03538.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11047.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.08051.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.05280.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03354.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03242.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.08987.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.02086.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1803.09230.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.13066.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.09123.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.01878.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.04866.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.07904.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00175.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03135.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.05467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.08345.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.00189.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.01010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.04642.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.07711.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.12085.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03544.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.04033.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.10161.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.10225.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.11180.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.04330.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01772.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.06757.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.09029.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.12129.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01207.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.05320.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00279.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.12254.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.07555.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.10288.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.05236.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.06937.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.02550.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08673.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.08960.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.06162.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.07789.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.02070.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.08675.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.09194.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.09588.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.04631.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1712.05999.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.08210.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.12196.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.01694.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.07816.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.02286.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.02877.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.06748.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1708.09609.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.06537.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.11769.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.08142.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.01088.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.10361.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.01265.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.05493.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08859.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.04798.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1610.00879.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.09678.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.00864.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.01608.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1812.10479.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.08079.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.10551.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.00825.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08089.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.00514.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.05434.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.02711.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.06424.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1812.01704.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.07734.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.05474.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1712.00991.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.01769.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.06286.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.00137.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.00330.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.04899.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01247.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.10049.pdf\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:28:35] #> Note: Output directory .ragatouille/colbert/indexes/paper_tab_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:28:35] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_tab_vector_db in 20 seconds...\n",
      "[Jul 29, 15:28:58] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:28:58] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:28:58] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_tab_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0012s) to cluster 201 items into 128 clusters\n",
      "[0.021, 0.018, 0.009, 0.019, 0.019, 0.024, 0.011, 0.014, 0.039, 0.022, 0.017, 0.015, 0.014, 0.019, 0.014, 0.029, 0.016, 0.009, 0.009, 0.021, 0.016, 0.036, 0.024, 0.018, 0.018, 0.02, 0.008, 0.009, 0.02, 0.016, 0.012, 0.009, 0.016, 0.034, 0.014, 0.017, 0.034, 0.024, 0.015, 0.027, 0.007, 0.016, 0.015, 0.012, 0.014, 0.024, 0.015, 0.015, 0.041, 0.011, 0.013, 0.012, 0.018, 0.019, 0.037, 0.018, 0.014, 0.025, 0.019, 0.018, 0.025, 0.021, 0.016, 0.026, 0.005, 0.023, 0.012, 0.019, 0.016, 0.017, 0.01, 0.018, 0.022, 0.011, 0.023, 0.017, 0.034, 0.029, 0.019, 0.021, 0.014, 0.016, 0.013, 0.014, 0.006, 0.011, 0.015, 0.028, 0.008, 0.011, 0.02, 0.021, 0.013, 0.013, 0.012, 0.012, 0.015, 0.023, 0.016, 0.012, 0.016, 0.02, 0.02, 0.013, 0.027, 0.023, 0.02, 0.024, 0.017, 0.007, 0.019, 0.008, 0.032, 0.021, 0.009, 0.016, 0.018, 0.024, 0.013, 0.017, 0.011, 0.009, 0.01, 0.02, 0.014, 0.034, 0.009, 0.021]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:28:58] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 63.09it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2851.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:28:58] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:28:58] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:28:58] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 157856.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:28:58] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_tab_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_tab_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:29:05] #> Loading codec...\n",
      "[Jul 29, 15:29:05] #> Loading IVF...\n",
      "[Jul 29, 15:29:05] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6413.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:29:05] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1637.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what language pairs are explored?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2653,  7689,  2024, 10641,  1029,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:29:05 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'what language pairs are explored?', 'response': 'The answer is: not specified', 'doc': '1912.01214', 'q_uid': '5eda469a8a77f028d0c5f1acd296111085614537', 'answers': [{'answer': 'De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru', 'type': 'abstractive'}, {'answer': 'French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation', 'type': 'extractive'}]}\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1712.03547.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.00968.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.12260.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.06675.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.06670.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.03106.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.12738.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.09393.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.05241.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.11645.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.00939.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.08949.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13375.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1610.07809.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09484.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.03764.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.13109.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01383.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06264.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.13215.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.07481.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.00540.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1609.00559.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03788.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.08050.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.11204.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.07723.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1710.09340.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.09795.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.11402.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.10810.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1807.07961.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.10644.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1607.06025.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.14497.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.02279.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.05574.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.08868.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1802.06024.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.03459.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.08899.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.09666.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.11235.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.07464.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.11432.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00361.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01984.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.10869.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.05058.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.06036.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.07683.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.10367.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.03449.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.08960.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03310.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00430.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13695.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.10503.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.05918.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.06566.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.02906.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03814.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.03430.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.00912.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.04642.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.12579.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.03044.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.00110.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.03288.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.06743.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06267.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1612.05270.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06379.pdf\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:29:08] #> Note: Output directory .ragatouille/colbert/indexes/paper_tab_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:29:08] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_tab_vector_db in 20 seconds...\n",
      "[Jul 29, 15:29:30] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:29:30] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:29:30] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_tab_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0009s) to cluster 201 items into 128 clusters\n",
      "[0.013, 0.014, 0.003, 0.013, 0.016, 0.009, 0.008, 0.006, 0.037, 0.017, 0.011, 0.011, 0.012, 0.009, 0.012, 0.021, 0.01, 0.005, 0.006, 0.02, 0.014, 0.029, 0.013, 0.006, 0.015, 0.01, 0.006, 0.006, 0.015, 0.008, 0.01, 0.007, 0.006, 0.03, 0.012, 0.01, 0.019, 0.016, 0.013, 0.02, 0.005, 0.008, 0.007, 0.011, 0.01, 0.018, 0.014, 0.004, 0.026, 0.005, 0.011, 0.004, 0.013, 0.009, 0.026, 0.016, 0.009, 0.02, 0.015, 0.016, 0.018, 0.008, 0.008, 0.02, 0.005, 0.02, 0.009, 0.012, 0.014, 0.013, 0.008, 0.012, 0.013, 0.006, 0.011, 0.01, 0.027, 0.014, 0.016, 0.008, 0.01, 0.008, 0.008, 0.01, 0.005, 0.008, 0.01, 0.026, 0.006, 0.01, 0.016, 0.018, 0.01, 0.01, 0.005, 0.008, 0.005, 0.014, 0.009, 0.008, 0.014, 0.016, 0.016, 0.003, 0.017, 0.019, 0.011, 0.018, 0.014, 0.004, 0.013, 0.006, 0.019, 0.019, 0.007, 0.012, 0.007, 0.016, 0.006, 0.015, 0.009, 0.006, 0.008, 0.009, 0.009, 0.026, 0.005, 0.011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:29:30] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 66.17it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1535.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:29:30] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:29:30] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:29:30] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 156203.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:29:30] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_tab_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_tab_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:29:36] #> Loading codec...\n",
      "[Jul 29, 15:29:36] #> Loading IVF...\n",
      "[Jul 29, 15:29:36] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6442.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:29:36] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1109.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What accuracy does the proposed system achieve?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054, 10640,  2515,  1996,  3818,  2291,  6162,  1029,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:29:36 CallLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5-3B', 'question': 'What accuracy does the proposed system achieve?', 'response': 'The answer is: not specified', 'doc': '1801.05147', 'q_uid': 'ef4dba073d24042f24886580ae77add5326f2130', 'answers': [{'answer': 'F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ', 'type': 'abstractive'}, {'answer': 'F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)', 'type': 'abstractive'}]}\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.05970.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05246.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03597.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.05907.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.09369.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.04721.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.09920.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.04952.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.01799.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.02492.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.02262.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.00530.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.10084.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.05828.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.02013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.06492.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09587.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.01214.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08976.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1712.03556.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.00069.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.00185.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.02821.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.00172.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11687.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.01541.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13714.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1702.03342.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.12795.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.04269.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.02507.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.02480.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.04513.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01359.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.11951.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.04511.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.05829.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03891.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.00663.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.09314.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.05153.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.04002.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.14537.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.07245.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.00672.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.03060.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.03569.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.08298.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01673.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1812.06864.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08824.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.10525.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.00079.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.07195.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.03710.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.08385.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11365.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.10217.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.00108.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.11901.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00694.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1706.08032.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.12218.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00512.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.05413.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11546.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.11221.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05855.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01664.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.08139.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.03382.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.00563.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.09755.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.00106.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.07090.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.06044.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09270.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08041.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06083.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.06592.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.02100.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.10806.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.01680.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.01081.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.01980.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.09103.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.07044.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.00652.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00105.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.03014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.07228.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.09722.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.05377.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01958.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00578.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.00458.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.05154.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.12885.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.07996.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.04181.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.11910.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11297.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.10254.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.06644.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.11563.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.09774.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08962.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.11346.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.06888.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.05584.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.10435.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.05752.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.04960.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03405.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1612.08205.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1812.06705.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.02257.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.10500.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.06194.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.03214.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.03866.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03744.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1604.00400.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.03457.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1710.06700.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.02339.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.06538.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00252.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.05572.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06151.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.07333.pdf\n",
      "=== Start paper_tab on falcon-e-3B ===\n",
      "2025-07-29 15:29:36 ====== Init LLM =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:29:37,361 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29 15:29:39 ====== LLM Service Started =======\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:29:41] #> Note: Output directory .ragatouille/colbert/indexes/paper_tab_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:29:41] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_tab_vector_db in 20 seconds...\n",
      "[Jul 29, 15:30:04] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:30:04] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:30:04] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_tab_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0008s) to cluster 201 items into 128 clusters\n",
      "[0.013, 0.014, 0.003, 0.013, 0.016, 0.009, 0.008, 0.006, 0.036, 0.017, 0.011, 0.011, 0.012, 0.009, 0.011, 0.021, 0.01, 0.005, 0.006, 0.02, 0.014, 0.029, 0.013, 0.006, 0.015, 0.01, 0.006, 0.006, 0.015, 0.008, 0.01, 0.007, 0.006, 0.029, 0.012, 0.01, 0.019, 0.016, 0.013, 0.02, 0.004, 0.008, 0.007, 0.011, 0.01, 0.018, 0.013, 0.004, 0.026, 0.005, 0.011, 0.004, 0.013, 0.009, 0.026, 0.016, 0.009, 0.02, 0.015, 0.016, 0.018, 0.008, 0.008, 0.02, 0.005, 0.019, 0.008, 0.011, 0.014, 0.012, 0.008, 0.011, 0.013, 0.006, 0.011, 0.01, 0.027, 0.014, 0.016, 0.008, 0.01, 0.008, 0.008, 0.01, 0.005, 0.008, 0.009, 0.026, 0.006, 0.01, 0.016, 0.018, 0.01, 0.01, 0.005, 0.008, 0.005, 0.014, 0.009, 0.008, 0.014, 0.016, 0.016, 0.003, 0.017, 0.019, 0.011, 0.018, 0.014, 0.004, 0.013, 0.006, 0.019, 0.018, 0.007, 0.012, 0.007, 0.016, 0.006, 0.015, 0.008, 0.006, 0.008, 0.009, 0.009, 0.026, 0.005, 0.011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:30:05] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 69.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 3048.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:30:05] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:30:05] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:30:05] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 166111.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:30:05] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_tab_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_tab_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:30:11] #> Loading codec...\n",
      "[Jul 29, 15:30:11] #> Loading IVF...\n",
      "[Jul 29, 15:30:11] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5447.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:30:11] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1104.93it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What baselines did they consider?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054, 26163,  2015,  2106,  2027,  5136,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:30:11 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'What baselines did they consider?', 'response': 'The answer is: 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000, 21000, 22000, 23000, 24000, 25000, 26000, 27000, 28000, 29000, 30000, 31000, 32000, 33000, 34000, 35000, 36000, 37000, 3', 'doc': '1809.01202', 'q_uid': '4cbe5a36b492b99f9f9fea8081fe4ba10a7a0e94', 'answers': [{'answer': 'state-of-the-art PDTB taggers', 'type': 'extractive'}, {'answer': 'Linear SVM, RBF SVM, and Random Forest', 'type': 'abstractive'}]}\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:30:32] #> Note: Output directory .ragatouille/colbert/indexes/paper_tab_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:30:32] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_tab_vector_db in 20 seconds...\n",
      "[Jul 29, 15:30:55] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:30:55] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:30:55] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_tab_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 4 iterations (0.0011s) to cluster 201 items into 128 clusters\n",
      "[0.013, 0.014, 0.003, 0.013, 0.016, 0.009, 0.008, 0.006, 0.036, 0.017, 0.011, 0.011, 0.012, 0.009, 0.011, 0.021, 0.01, 0.005, 0.006, 0.02, 0.014, 0.029, 0.013, 0.006, 0.015, 0.01, 0.006, 0.006, 0.015, 0.008, 0.01, 0.007, 0.006, 0.029, 0.012, 0.01, 0.019, 0.016, 0.013, 0.02, 0.004, 0.008, 0.007, 0.011, 0.01, 0.018, 0.013, 0.004, 0.026, 0.005, 0.011, 0.004, 0.013, 0.009, 0.026, 0.016, 0.009, 0.02, 0.015, 0.016, 0.018, 0.008, 0.008, 0.02, 0.005, 0.019, 0.008, 0.011, 0.014, 0.012, 0.008, 0.011, 0.013, 0.006, 0.011, 0.01, 0.027, 0.014, 0.016, 0.008, 0.01, 0.008, 0.008, 0.01, 0.005, 0.008, 0.009, 0.026, 0.006, 0.01, 0.016, 0.018, 0.01, 0.01, 0.005, 0.008, 0.005, 0.014, 0.009, 0.008, 0.014, 0.016, 0.016, 0.003, 0.017, 0.019, 0.011, 0.018, 0.014, 0.004, 0.013, 0.006, 0.019, 0.018, 0.007, 0.012, 0.007, 0.016, 0.006, 0.015, 0.008, 0.006, 0.008, 0.009, 0.009, 0.026, 0.005, 0.011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:30:55] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 68.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1312.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:30:55] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:30:55] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:30:55] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 157996.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:30:55] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_tab_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_tab_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:31:01] #> Loading codec...\n",
      "[Jul 29, 15:31:01] #> Loading IVF...\n",
      "[Jul 29, 15:31:01] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6462.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:31:01] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1640.32it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: Does this approach perform better in the multi-domain or single-domain setting?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2515, 2023, 3921, 4685, 2488, 1999, 1996, 4800, 1011, 5884,\n",
      "        2030, 2309, 1011, 5884, 4292, 1029,  102,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:31:01 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'Does this approach perform better in the multi-domain or single-domain setting?', 'response': 'The answer is: single-domain', 'doc': '1909.00754', 'q_uid': 'ed7a3e7fc1672f85a768613e7d1b419475950ab4', 'answers': [{'answer': 'single-domain setting', 'type': 'abstractive'}]}\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.10011.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.08559.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.03538.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11047.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.08051.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.05280.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03354.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03242.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.08987.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.02086.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1803.09230.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.13066.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.09123.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.01878.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.04866.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.07904.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00175.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03135.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.05467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.08345.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.00189.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.01010.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.04642.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.07711.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.12085.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03544.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.04033.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.10161.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.10225.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.11180.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.04330.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01772.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1608.06757.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.09029.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.12129.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01207.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.05320.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00279.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.12254.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.07555.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.10288.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.05236.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.06937.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.02550.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08673.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.08960.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.06162.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.07789.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.02070.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.08675.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.09194.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.09588.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1606.04631.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00015.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1712.05999.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.08210.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.12196.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.01694.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.07816.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.02286.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.02877.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.06748.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1708.09609.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.06537.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.11769.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.08142.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.01088.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.10361.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.01265.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.05493.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08859.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.04798.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1610.00879.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.09678.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.00864.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.01608.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1812.10479.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.08079.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.10551.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.00825.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08089.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.00514.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.05434.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.02711.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.06424.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1812.01704.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.07734.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.05474.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1712.00991.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.01769.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.06286.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.00137.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.00330.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.04899.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01247.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.10049.pdf\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:31:04] #> Note: Output directory .ragatouille/colbert/indexes/paper_tab_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:31:04] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_tab_vector_db in 20 seconds...\n",
      "[Jul 29, 15:31:27] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:31:27] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:31:27] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_tab_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0015s) to cluster 201 items into 128 clusters\n",
      "[0.021, 0.018, 0.009, 0.019, 0.019, 0.024, 0.011, 0.014, 0.039, 0.022, 0.017, 0.015, 0.014, 0.019, 0.014, 0.029, 0.016, 0.009, 0.009, 0.021, 0.016, 0.036, 0.024, 0.018, 0.018, 0.02, 0.008, 0.009, 0.02, 0.016, 0.012, 0.009, 0.016, 0.034, 0.014, 0.017, 0.034, 0.024, 0.015, 0.027, 0.007, 0.016, 0.015, 0.012, 0.014, 0.024, 0.015, 0.015, 0.041, 0.011, 0.013, 0.012, 0.018, 0.019, 0.037, 0.018, 0.014, 0.025, 0.019, 0.018, 0.025, 0.021, 0.016, 0.026, 0.005, 0.023, 0.012, 0.019, 0.016, 0.017, 0.01, 0.018, 0.022, 0.011, 0.023, 0.017, 0.034, 0.029, 0.019, 0.021, 0.014, 0.016, 0.013, 0.014, 0.006, 0.011, 0.015, 0.028, 0.008, 0.011, 0.02, 0.021, 0.013, 0.013, 0.012, 0.012, 0.015, 0.023, 0.016, 0.012, 0.016, 0.02, 0.02, 0.013, 0.027, 0.023, 0.02, 0.024, 0.017, 0.007, 0.019, 0.008, 0.032, 0.021, 0.009, 0.016, 0.018, 0.024, 0.013, 0.017, 0.011, 0.009, 0.01, 0.02, 0.014, 0.034, 0.009, 0.021]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:31:27] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 63.17it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2489.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:31:27] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:31:27] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:31:27] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 112480.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:31:27] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_tab_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_tab_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:31:33] #> Loading codec...\n",
      "[Jul 29, 15:31:33] #> Loading IVF...\n",
      "[Jul 29, 15:31:33] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12633.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:31:33] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1555.75it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: what language pairs are explored?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2653,  7689,  2024, 10641,  1029,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:31:33 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'what language pairs are explored?', 'response': 'The answer is: Hindi-English, Kannada-English, Telugu-English, Assamese-English, Bengali-English, Malayalam-English', 'doc': '1912.01214', 'q_uid': '5eda469a8a77f028d0c5f1acd296111085614537', 'answers': [{'answer': 'De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru', 'type': 'abstractive'}, {'answer': 'French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation', 'type': 'extractive'}]}\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1712.03547.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.00968.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.12260.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.06675.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.06670.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.03106.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.12738.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.09393.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.05241.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.11645.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.00939.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.08949.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13375.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1610.07809.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09484.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.03764.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.13109.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01383.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06264.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.13215.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.07481.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.00540.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1609.00559.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03788.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.08050.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.11204.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.07723.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1710.09340.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.09795.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.11402.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.10810.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1807.07961.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.10644.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1607.06025.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.14497.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.02279.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.05574.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.08868.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1802.06024.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.03459.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.08899.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.09666.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.11235.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.07464.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.11432.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00361.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01984.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.10869.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.05058.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.06036.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.07683.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.10367.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.03449.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.08960.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03310.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00430.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13695.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.10503.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.05918.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.06566.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1811.02906.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03814.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.03430.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.00912.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.04642.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.12579.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.03044.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.00110.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.03288.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.06743.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06267.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1612.05270.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06379.pdf\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 29, 15:31:38] #> Note: Output directory .ragatouille/colbert/indexes/paper_tab_vector_db already exists\n",
      "\n",
      "\n",
      "[Jul 29, 15:31:38] #> Will delete 10 files already at .ragatouille/colbert/indexes/paper_tab_vector_db in 20 seconds...\n",
      "[Jul 29, 15:32:01] [0] \t\t #> Encoding 55 passages..\n",
      "[Jul 29, 15:32:01] [0] \t\t avg_doclen_est = 3.8363635540008545 \t len(local_sample) = 55\n",
      "[Jul 29, 15:32:01] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/paper_tab_vector_db/plan.json ..\n",
      "Warning: number of training points (201) is less than the minimum recommended (1280)\n",
      "used 3 iterations (0.0011s) to cluster 201 items into 128 clusters\n",
      "[0.013, 0.014, 0.003, 0.013, 0.016, 0.009, 0.008, 0.006, 0.037, 0.017, 0.011, 0.011, 0.012, 0.009, 0.012, 0.021, 0.01, 0.005, 0.006, 0.02, 0.014, 0.029, 0.013, 0.006, 0.015, 0.01, 0.006, 0.006, 0.015, 0.008, 0.01, 0.007, 0.006, 0.03, 0.012, 0.01, 0.019, 0.016, 0.013, 0.02, 0.005, 0.008, 0.007, 0.011, 0.01, 0.018, 0.014, 0.004, 0.026, 0.005, 0.011, 0.004, 0.013, 0.009, 0.026, 0.016, 0.009, 0.02, 0.015, 0.016, 0.018, 0.008, 0.008, 0.02, 0.005, 0.02, 0.009, 0.012, 0.014, 0.013, 0.008, 0.012, 0.013, 0.006, 0.011, 0.01, 0.027, 0.014, 0.016, 0.008, 0.01, 0.008, 0.008, 0.01, 0.005, 0.008, 0.01, 0.026, 0.006, 0.01, 0.016, 0.018, 0.01, 0.01, 0.005, 0.008, 0.005, 0.014, 0.009, 0.008, 0.014, 0.016, 0.016, 0.003, 0.017, 0.019, 0.011, 0.018, 0.014, 0.004, 0.013, 0.006, 0.019, 0.019, 0.007, 0.012, 0.007, 0.016, 0.006, 0.015, 0.009, 0.006, 0.008, 0.009, 0.009, 0.026, 0.005, 0.011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:32:01] [0] \t\t #> Encoding 55 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 61.63it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2606.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:32:01] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 29, 15:32:01] #> Building the emb2pid mapping..\n",
      "[Jul 29, 15:32:01] len(emb2pid) = 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 151830.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:32:01] #> Saved optimized IVF to .ragatouille/colbert/indexes/paper_tab_vector_db/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index paper_tab_vector_db for the first time... This may take a few seconds\n",
      "[Jul 29, 15:32:07] #> Loading codec...\n",
      "[Jul 29, 15:32:07] #> Loading IVF...\n",
      "[Jul 29, 15:32:07] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4877.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 29, 15:32:07] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1577.40it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: What accuracy does the proposed system achieve?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054, 10640,  2515,  1996,  3818,  2291,  6162,  1029,\n",
      "          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "2025-07-29 15:32:07 CallLLM\n",
      "{'model': 'falcon-e-3B', 'question': 'What accuracy does the proposed system achieve?', 'response': 'The answer is: 90% accuracy', 'doc': '1801.05147', 'q_uid': 'ef4dba073d24042f24886580ae77add5326f2130', 'answers': [{'answer': 'F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ', 'type': 'abstractive'}, {'answer': 'F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)', 'type': 'abstractive'}]}\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.05970.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05246.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.03597.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.05907.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.09369.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.04721.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1808.09920.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.04952.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.01799.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.02492.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.02262.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.00530.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.10084.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.05828.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.02013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.06492.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09587.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.01214.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08976.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1712.03556.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.00069.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.00185.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.02821.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.00172.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11687.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.01541.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.13714.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1702.03342.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.12795.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.04269.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.02507.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.02480.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.04513.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01359.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.11951.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.04511.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.05829.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03891.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.00663.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.09314.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.05153.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.04002.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.14537.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.07245.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.00672.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1907.03060.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1707.03569.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.08298.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.01673.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1812.06864.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08824.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1902.10525.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.00079.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.07195.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1805.03710.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.08385.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11365.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.10217.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1705.00108.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.11901.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00694.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1706.08032.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.12218.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00512.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1709.05413.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.11546.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.11221.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.05855.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.01664.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.08139.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1611.03382.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1905.00563.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.09755.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1711.00106.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1703.07090.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.06044.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.09270.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.08041.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06083.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.06592.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.03467.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.02100.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.10806.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.01680.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1906.01081.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.01980.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1806.09103.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1603.07044.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.00652.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00105.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.03014.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.07228.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1903.09722.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.05377.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01958.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.01013.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00578.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.00458.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.05154.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.12885.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.07996.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.04181.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.11910.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.11297.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.10254.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2002.06644.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2003.11563.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1810.09774.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1911.08962.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1804.11346.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2001.06888.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.05584.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.10435.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.05752.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1809.04960.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.03405.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1612.08205.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1812.06705.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.02257.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1904.10500.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.06194.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.03214.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1901.03866.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/2004.03744.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1604.00400.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1912.03457.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1710.06700.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1910.02339.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1701.06538.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1909.00252.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1704.05572.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1908.06151.pdf\n",
      "PDF file not found at: dataset/src_doc_files_example/paper_docs/1605.07333.pdf\n",
      "=== Finish paper_tab ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from uda.utils import retrieve as rt\n",
    "from uda.utils import preprocess as pre\n",
    "import pandas as pd\n",
    "from uda.utils import llm\n",
    "from uda.utils import inference\n",
    "import json\n",
    "\n",
    "for DATASET_NAME in DATASET_NAME_LIST:\n",
    "    for LLM_MODEL in LLM_LIST:\n",
    "        print(f\"=== Start {DATASET_NAME} on {LLM_MODEL} ===\")\n",
    "        res_file = os.path.join(res_dir, f\"{DATASET_NAME}_{LLM_MODEL}_{RT_MODEL}.jsonl\")\n",
    "\n",
    "        # If use the local LLM, initialize the model\n",
    "        if LLM_MODEL in LOCAL_LLM_DICT:\n",
    "            llm_name = LOCAL_LLM_DICT[LLM_MODEL]\n",
    "            llm_service = inference.LLM(llm_name)\n",
    "            llm_service.init_llm()\n",
    "\n",
    "        # Load the benchmark data\n",
    "        bench_json_file = pre.meta_data[DATASET_NAME][\"bench_json_file\"]\n",
    "        with open(bench_json_file, \"r\") as f:\n",
    "            bench_data = json.load(f)\n",
    "\n",
    "        # Run experiments on the demo docs\n",
    "        doc_list = list(bench_data.keys())\n",
    "        for doc in doc_list:\n",
    "            pdf_path = pre.get_example_pdf_path(DATASET_NAME, doc)\n",
    "            if pdf_path is None:\n",
    "                continue\n",
    "            # Prepare the index for the document\n",
    "            collection_name = f\"{DATASET_NAME}_vector_db\"\n",
    "            collection = rt.prepare_collection(pdf_path, collection_name, RT_MODEL)\n",
    "            for qa_item in bench_data[doc]:\n",
    "                question = qa_item[\"question\"]\n",
    "                # Retrieve the contexts\n",
    "                contexts = rt.get_contexts(collection, question, RT_MODEL)\n",
    "                context_text = '\\n'.join(contexts)\n",
    "                # Create the prompt\n",
    "                llm_message = llm.make_prompt(question, context_text, DATASET_NAME, LLM_MODEL)\n",
    "                # Generate the answer\n",
    "                if LLM_MODEL in LOCAL_LLM_DICT:\n",
    "                    response = llm_service.infer(llm_message)\n",
    "                elif LLM_MODEL == \"gpt4\":\n",
    "                    # Set up with your own GPT4 service using environment variables\n",
    "                    response = llm.call_gpt(messages=llm_message)\n",
    "                    if response is None:\n",
    "                        print(\"Make sure your gpt4 service is set up correctly.\")\n",
    "                        raise Exception(\"GPT4 service\")\n",
    "\n",
    "                # log the results\n",
    "                res_dict = {\"model\": LLM_MODEL, \"question\": question, \"response\": response, \"doc\": doc, \"q_uid\": qa_item[\"q_uid\"], \"answers\": qa_item[\"answers\"]}\n",
    "                print(res_dict)\n",
    "                with open(res_file, \"a\") as f:\n",
    "                    f.write(json.dumps(res_dict) + \"\\n\")\n",
    "            rt.reset_collection(collection_name, RT_MODEL)\n",
    "\n",
    "    print(f\"=== Finish {DATASET_NAME} ===\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the end-to-end results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Answer F1': 0.19444444444444442, 'Missing predictions': 0}\n"
     ]
    }
   ],
   "source": [
    "dataset_name=\"feta\"\n",
    "llm_model=\"meno-tiny\"\n",
    "rt_model=\"colbert\"\n",
    "res_file_name=f\"experiment/e2e/res/{dataset_name}_{llm_model}_{rt_model}.jsonl\"\n",
    "\n",
    "from uda.eval.my_eval import eval_from_file\n",
    "eval_from_file(dataset_name, res_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "meno-tiny\n",
      "========\n",
      "fin:\n",
      "Exact-match accuracy: 0.00\n",
      "feta:\n",
      "{'Answer F1': 0.19444444444444442, 'Missing predictions': 0}\n",
      "tat:\n",
      "Numerical F1 score: 2.83\n",
      "paper_text:\n",
      "{'Answer F1': 0.452991452991453, 'Missing predictions': 0}\n",
      "nq:\n",
      "{'Answer F1': 0.11717384458198757, 'Missing predictions': 0}\n",
      "paper_tab:\n",
      "{'Answer F1': 0.04554079696394687, 'Missing predictions': 0}\n",
      "\n",
      "========\n",
      "qwen2.5-1.5B\n",
      "========\n",
      "fin:\n",
      "Exact-match accuracy: 0.00\n",
      "feta:\n",
      "{'Answer F1': 0.2562162162162162, 'Missing predictions': 0}\n",
      "tat:\n",
      "Numerical F1 score: 2.67\n",
      "paper_text:\n",
      "{'Answer F1': 0.4892857142857143, 'Missing predictions': 0}\n",
      "nq:\n",
      "{'Answer F1': 0.1848040472576633, 'Missing predictions': 0}\n",
      "paper_tab:\n",
      "{'Answer F1': 0.022727272727272728, 'Missing predictions': 0}\n",
      "\n",
      "========\n",
      "qwen2.5-3B\n",
      "========\n",
      "fin:\n",
      "Exact-match accuracy: 0.00\n",
      "feta:\n",
      "{'Answer F1': 0.2843980343980344, 'Missing predictions': 0}\n",
      "tat:\n",
      "Numerical F1 score: 0.00\n",
      "paper_text:\n",
      "{'Answer F1': 0.37931034482758624, 'Missing predictions': 0}\n",
      "nq:\n",
      "{'Answer F1': 0.21613524555259797, 'Missing predictions': 0}\n",
      "paper_tab:\n",
      "{'Answer F1': 0.0, 'Missing predictions': 0}\n",
      "\n",
      "========\n",
      "falcon-e-3B\n",
      "========\n",
      "fin:\n",
      "Exact-match accuracy: 0.00\n",
      "feta:\n",
      "{'Answer F1': 0.3216374269005848, 'Missing predictions': 0}\n",
      "tat:\n",
      "Numerical F1 score: 3.92\n",
      "paper_text:\n",
      "{'Answer F1': 0.07346491228070175, 'Missing predictions': 0}\n",
      "nq:\n",
      "{'Answer F1': 0.1260916075851141, 'Missing predictions': 0}\n",
      "paper_tab:\n",
      "{'Answer F1': 0.16666666666666666, 'Missing predictions': 0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for llm_model in LOCAL_LLM_DICT:\n",
    "    print('========')\n",
    "    print(llm_model)\n",
    "    print('========')\n",
    "    for dataset_name in DATASET_NAME_LIST:\n",
    "        res_file_name=f\"experiment/e2e/res/{dataset_name}_{llm_model}_{rt_model}.jsonl\"\n",
    "        print(dataset_name + ':')\n",
    "        eval_from_file(dataset_name, res_file_name)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
